2020-03-21 12:54:08,854 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 12:54:08,860 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 12:54:09,014 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 12:54:09,079 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 12:54:09,202 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 12:54:09,340 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 12:54:09,505 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 12:54:09,508 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 12:54:09,511 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 12:54:09,539 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 12:54:09,542 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 12:54:09,542 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 12:54:09,554 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 12:54:09,555 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 12:54:09,555 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 12:54:09,556 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 12:54:09,636 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 12:54:09,784 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 12:54:09,784 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 12:54:09,793 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 12:54:09,799 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 12:54:09,800 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 12:54:09,802 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 12:54:09,802 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 12:54:09,803 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 12:54:09,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 12:54:09,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 12:54:09,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 12:54:09,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 12:54:09,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 12:54:09,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 12:54:09,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 12:54:09,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:54:09,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:54:09,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:54:09,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 12:54:09,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 12:54:09,863 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 12:54:09,863 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 12:54:09,871 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 12:54:09,872 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 12:54:09,872 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 12:54:09,872 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:54:09,872 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 12:54:09,872 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 12:54:09,873 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 12:54:09,873 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:54:09,873 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 12:54:09,873 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 12:54:09,874 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 12:54:09,974 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:54:09,995 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 12:54:10,233 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 12:54:10,234 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:54:10,234 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 12:54:10,366 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:54:10,378 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 12:54:10,403 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 12:54:10,403 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:54:10,403 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 12:54:10,534 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:54:10,536 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 12:54:10,542 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 12:54:10,543 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:54:10,543 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 12:54:10,552 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 12:54:10,665 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 12:54:10,669 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 12:54:10,673 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 12:54:10,677 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 12:54:10,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 12:54:10,681 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 12:54:10,681 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 12:54:10,996 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 12:54:10,997 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 12:54:10,997 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 12:54:11,011 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 12:54:11,292 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:54:11,293 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 12:54:11,293 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:54:12,036 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 12:54:12,036 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 12:54:12,113 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 12:54:12,113 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 12:54:12,115 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 12:54:12,115 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:54:12,115 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 12:54:33,372 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-21 12:54:33,380 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 12:54:33,381 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 12:54:33,482 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-21 12:54:33,484 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-21 12:54:33,484 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-21 12:54:33,485 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 12:54:33,485 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-21 12:54:33,485 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 12:54:33,485 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-21 12:54:33,487 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-21 12:54:33,487 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-21 12:54:33,490 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-21 12:54:33,491 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 12:54:33,491 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-21 12:54:33,501 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-21 12:54:33,501 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 12:54:33,501 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-21 12:54:33,501 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-21 12:54:33,503 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 12:54:33,504 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-21 12:54:33,504 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 12:54:33,504 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 12:54:33,504 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 12:54:33,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-21 12:54:33,507 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-21 12:54:33,508 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-21 12:54:33,508 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 12:54:33,510 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-21 12:54:33,510 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-21 12:56:50,996 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 12:56:51,001 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 12:56:51,156 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 12:56:51,222 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 12:56:51,251 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 12:56:51,460 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 12:56:51,596 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 12:56:51,598 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 12:56:51,600 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 12:56:51,617 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 12:56:51,618 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 12:56:51,618 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 12:56:51,626 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 12:56:51,626 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 12:56:51,626 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 12:56:51,627 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 12:56:51,658 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 12:56:51,688 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 12:56:51,689 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 12:56:51,695 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 12:56:51,699 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 12:56:51,700 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 12:56:51,701 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 12:56:51,702 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 12:56:51,702 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 12:56:51,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 12:56:51,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 12:56:51,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 12:56:51,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 12:56:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 12:56:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 12:56:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 12:56:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:56:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:56:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 12:56:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 12:56:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 12:56:51,742 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 12:56:51,742 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 12:56:51,749 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 12:56:51,749 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 12:56:51,749 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 12:56:51,749 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:56:51,750 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 12:56:51,750 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 12:56:51,750 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 12:56:51,750 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:56:51,750 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 12:56:51,750 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 12:56:51,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 12:56:51,827 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:56:51,834 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 12:56:51,931 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 12:56:51,931 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:56:51,931 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 12:56:52,009 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:56:52,012 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 12:56:52,018 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 12:56:52,018 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:56:52,018 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 12:56:52,113 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 12:56:52,114 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 12:56:52,117 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 12:56:52,117 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:56:52,117 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 12:56:52,130 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 12:56:52,228 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 12:56:52,233 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 12:56:52,239 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 12:56:52,245 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 12:56:52,247 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 12:56:52,247 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 12:56:52,247 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 12:56:52,248 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 12:56:52,248 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 12:56:52,248 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 12:56:52,250 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 12:56:52,250 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 12:56:52,461 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 12:56:52,462 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 12:56:52,462 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 12:56:52,477 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 12:56:52,593 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:56:52,593 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 12:56:52,593 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 12:56:53,342 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 12:56:53,343 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 12:56:53,424 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 12:56:53,425 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 12:56:53,427 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 12:56:53,427 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 12:56:53,427 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 12:56:54,412 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-21 12:56:54,413 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 34479 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:34479
2020-03-21 12:56:54,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:34479 Node Transitioned from NEW to RUNNING
2020-03-21 12:56:54,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:34479 clusterResource: <memory:8192, vCores:8>
2020-03-21 13:06:51,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-21 13:14:48,190 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-21 13:14:49,170 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-21 13:14:49,170 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0001
2020-03-21 13:14:49,170 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0001
2020-03-21 13:14:49,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0001 State change from NEW to NEW_SAVING on event=START
2020-03-21 13:14:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0001
2020-03-21 13:14:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 13:14:49,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 13:14:49,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0001 from user: xidian, in queue: default
2020-03-21 13:14:49,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 13:14:49,247 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0001_000001
2020-03-21 13:14:49,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from NEW to SUBMITTED
2020-03-21 13:14:49,254 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:14:49,254 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:14:49,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0001 from user: xidian activated in queue: default
2020-03-21 13:14:49,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@54ff8639, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:14:49,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0001_000001 to scheduler from user xidian in queue default
2020-03-21 13:14:49,256 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 13:14:49,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:14:49,740 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0001	CONTAINERID=container_1584766611743_0001_01_000001
2020-03-21 13:14:49,740 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:14:49,740 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0001_000001 container=Container: [ContainerId: container_1584766611743_0001_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:14:49,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:14:49,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:14:49,751 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0001_01_000001
2020-03-21 13:14:49,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:14:49,757 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0001_000001
2020-03-21 13:14:49,759 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0001 AttemptId: appattempt_1584766611743_0001_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0001_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:14:49,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:14:49,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:14:49,811 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0001_000001
2020-03-21 13:14:49,827 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0001_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0001_000001
2020-03-21 13:14:49,827 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:14:49,828 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0001_000001
2020-03-21 13:14:49,830 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0001_000001
2020-03-21 13:14:50,040 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0001_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0001_000001
2020-03-21 13:14:50,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 13:14:50,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:14:52,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:14:52,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:14:52,736 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0001	CONTAINERID=container_1584766611743_0001_01_000001
2020-03-21 13:14:52,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:14:52,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:14:52,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0001_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:14:52,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:14:52,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:14:52,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0001_000001 released container container_1584766611743_0001_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:14:52,739 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0001_000001 with final state: FAILED, and exit status: -1
2020-03-21 13:14:52,739 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:14:52,739 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0001_000001
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0001_000001
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000001 State change from FINAL_SAVING to FAILED
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0001_000002
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0001_000001 is done. finalState=FAILED
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from NEW to SUBMITTED
2020-03-21 13:14:52,740 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0001 requests cleared
2020-03-21 13:14:52,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:14:52,741 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:14:52,741 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:14:52,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0001 from user: xidian activated in queue: default
2020-03-21 13:14:52,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7d94b761, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:14:52,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0001_000002 to scheduler from user xidian in queue default
2020-03-21 13:14:52,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 13:14:53,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:14:53,737 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0001	CONTAINERID=container_1584766611743_0001_02_000001
2020-03-21 13:14:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:14:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0001_000002 container=Container: [ContainerId: container_1584766611743_0001_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:14:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:14:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:14:53,740 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0001_02_000001
2020-03-21 13:14:53,743 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:14:53,744 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0001_000002
2020-03-21 13:14:53,744 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0001 AttemptId: appattempt_1584766611743_0001_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0001_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:14:53,744 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:14:53,744 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:14:53,746 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0001_000002
2020-03-21 13:14:53,750 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0001_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0001_000002
2020-03-21 13:14:53,751 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0001_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:14:53,751 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0001_000002
2020-03-21 13:14:53,751 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0001_000002
2020-03-21 13:14:53,759 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0001_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0001_000002
2020-03-21 13:14:53,759 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 13:14:54,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0001_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0001_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0001	CONTAINERID=container_1584766611743_0001_02_000001
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0001_000002 with final state: FAILED, and exit status: -1
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0001_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0001_000002
2020-03-21 13:14:55,894 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0001_000002
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0001_000002 State change from FINAL_SAVING to FAILED
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0001_000002 released container container_1584766611743_0001_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 13:14:55,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0001 with final state: FAILED
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0001 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0001
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0001_000002 is done. finalState=FAILED
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0001 failed 2 times due to AM Container for appattempt_1584766611743_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0001 requests cleared
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:14:55,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0001 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 13:14:55,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 13:14:55,897 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0001 failed 2 times due to AM Container for appattempt_1584766611743_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1584766611743_0001
2020-03-21 13:14:55,898 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0001,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0001,appMasterHost=N/A,startTime=1584767689169,finishTime=1584767695895,finalStatus=FAILED,memorySeconds=10552,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 13:17:42,568 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0002
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0002 State change from NEW to NEW_SAVING on event=START
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0002
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0002
2020-03-21 13:17:43,355 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0002 from user: xidian, in queue: default
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0002_000001
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from NEW to SUBMITTED
2020-03-21 13:17:43,356 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:17:43,356 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0002 from user: xidian activated in queue: default
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@71de54b8, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:17:43,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0002_000001 to scheduler from user xidian in queue default
2020-03-21 13:17:43,357 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 13:17:44,119 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:17:44,119 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0002	CONTAINERID=container_1584766611743_0002_01_000001
2020-03-21 13:17:44,119 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:17:44,120 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0002_000001 container=Container: [ContainerId: container_1584766611743_0002_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:17:44,120 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:17:44,120 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:17:44,121 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0002_01_000001
2020-03-21 13:17:44,127 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:17:44,127 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0002_000001
2020-03-21 13:17:44,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0002 AttemptId: appattempt_1584766611743_0002_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0002_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:17:44,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:17:44,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:17:44,129 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0002_000001
2020-03-21 13:17:44,133 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0002_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0002_000001
2020-03-21 13:17:44,133 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:17:44,134 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0002_000001
2020-03-21 13:17:44,134 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0002_000001
2020-03-21 13:17:44,144 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0002_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0002_000001
2020-03-21 13:17:44,144 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 13:17:45,120 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0002	CONTAINERID=container_1584766611743_0002_01_000001
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0002_000001 with final state: FAILED, and exit status: 126
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0002_000001
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0002_000001
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0002_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:17:46,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0002_000001 released container container_1584766611743_0002_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0002_000002
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from NEW to SUBMITTED
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0002_000001 is done. finalState=FAILED
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0002 requests cleared
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:17:46,407 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:17:46,407 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0002 from user: xidian activated in queue: default
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@2929ca5d, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:17:46,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0002_000002 to scheduler from user xidian in queue default
2020-03-21 13:17:46,408 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 13:17:47,408 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:17:47,408 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0002	CONTAINERID=container_1584766611743_0002_02_000001
2020-03-21 13:17:47,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:17:47,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0002_000002 container=Container: [ContainerId: container_1584766611743_0002_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:17:47,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:17:47,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:17:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0002_02_000001
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0002_000002
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0002 AttemptId: appattempt_1584766611743_0002_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0002_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:17:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0002_000002
2020-03-21 13:17:47,416 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0002_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0002_000002
2020-03-21 13:17:47,416 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:17:47,416 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0002_000002
2020-03-21 13:17:47,416 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0002_000002
2020-03-21 13:17:47,422 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0002_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0002_000002
2020-03-21 13:17:47,422 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 13:17:48,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:17:49,641 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0002	CONTAINERID=container_1584766611743_0002_02_000001
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0002_000002 with final state: FAILED, and exit status: 126
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0002_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0002_000002
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0002_000002
2020-03-21 13:17:49,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0002_000002 released container container_1584766611743_0002_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0002 with final state: FAILED
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0002
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0002_000002 is done. finalState=FAILED
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0002 failed 2 times due to AM Container for appattempt_1584766611743_0002_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0002_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0002_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0002 requests cleared
2020-03-21 13:17:49,643 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 13:17:49,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:17:49,644 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0002 failed 2 times due to AM Container for appattempt_1584766611743_0002_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0002_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0002_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0002
2020-03-21 13:17:49,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 13:17:49,644 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0002,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0002,appMasterHost=N/A,startTime=1584767863355,finishTime=1584767869643,finalStatus=FAILED,memorySeconds=9256,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 13:20:48,627 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user xidian
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0003
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0003
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0003
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0003 State change from NEW to NEW_SAVING on event=START
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0003 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 13:20:49,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0003 from user: xidian, in queue: default
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from NEW to SUBMITTED
2020-03-21 13:20:49,410 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:20:49,410 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0003 from user: xidian activated in queue: default
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1906f0fd, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:20:49,410 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0003_000001 to scheduler from user xidian in queue default
2020-03-21 13:20:49,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0003	CONTAINERID=container_1584766611743_0003_01_000001
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0003_000001 container=Container: [ContainerId: container_1584766611743_0003_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:20:49,902 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0003_01_000001
2020-03-21 13:20:49,903 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:20:49,903 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,903 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0003 AttemptId: appattempt_1584766611743_0003_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0003_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:20:49,903 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:20:49,903 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:20:49,904 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0003_000001
2020-03-21 13:20:49,905 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0003_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,905 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0003_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:20:49,905 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,905 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,912 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0003_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0003_000001
2020-03-21 13:20:49,912 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 13:20:50,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:20:52,167 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:20:52,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0003_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:20:52,167 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0003	CONTAINERID=container_1584766611743_0003_01_000001
2020-03-21 13:20:52,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0003_000001 with final state: FAILED, and exit status: 126
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0003_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0003_000001
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0003_000001
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000001 State change from FINAL_SAVING to FAILED
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0003_000001 released container container_1584766611743_0003_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:20:52,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0003_000001 is done. finalState=FAILED
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0003_000002
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0003 requests cleared
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from NEW to SUBMITTED
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:20:52,169 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:20:52,169 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0003 from user: xidian activated in queue: default
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@5125db2, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0003_000002 to scheduler from user xidian in queue default
2020-03-21 13:20:52,169 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 13:20:53,169 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 13:20:53,169 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0003	CONTAINERID=container_1584766611743_0003_02_000001
2020-03-21 13:20:53,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0003_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 13:20:53,170 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0003_000002 container=Container: [ContainerId: container_1584766611743_0003_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 13:20:53,170 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 13:20:53,171 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 13:20:53,173 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0003_02_000001
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0003_000002
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0003 AttemptId: appattempt_1584766611743_0003_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0003_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 13:20:53,175 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0003_000002
2020-03-21 13:20:53,176 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0003_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0003_000002
2020-03-21 13:20:53,176 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0003_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 13:20:53,176 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0003_000002
2020-03-21 13:20:53,176 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0003_000002
2020-03-21 13:20:53,182 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0003_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0003_000002
2020-03-21 13:20:53,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 13:20:54,172 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0003_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0003_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0003	CONTAINERID=container_1584766611743_0003_02_000001
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0003_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0003_000002 with final state: FAILED, and exit status: 126
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0003_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0003_000002 released container container_1584766611743_0003_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0003_000002
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0003_000002
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0003_000002 State change from FINAL_SAVING to FAILED
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0003 with final state: FAILED
2020-03-21 13:20:55,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0003 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0003
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0003_000002 is done. finalState=FAILED
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0003 requests cleared
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0003 failed 2 times due to AM Container for appattempt_1584766611743_0003_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0003Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0003_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0003_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0003 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0003 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 13:20:55,370 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0003 failed 2 times due to AM Container for appattempt_1584766611743_0003_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0003Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0003_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0003_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0003
2020-03-21 13:20:55,370 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0003,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0003,appMasterHost=N/A,startTime=1584768049408,finishTime=1584768055369,finalStatus=FAILED,memorySeconds=9143,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 14:59:54,249 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-03-21 14:59:55,026 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user xidian
2020-03-21 14:59:55,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0004
2020-03-21 14:59:55,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0004
2020-03-21 14:59:55,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0004 State change from NEW to NEW_SAVING on event=START
2020-03-21 14:59:55,026 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0004
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0004 from user: xidian, in queue: default
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from NEW to SUBMITTED
2020-03-21 14:59:55,027 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 14:59:55,027 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0004 from user: xidian activated in queue: default
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6eab23c, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 14:59:55,027 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0004_000001 to scheduler from user xidian in queue default
2020-03-21 14:59:55,028 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 14:59:55,766 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 14:59:55,766 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0004	CONTAINERID=container_1584766611743_0004_01_000001
2020-03-21 14:59:55,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 14:59:55,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0004_000001 container=Container: [ContainerId: container_1584766611743_0004_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 14:59:55,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 14:59:55,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 14:59:55,768 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0004_01_000001
2020-03-21 14:59:55,770 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 14:59:55,771 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,771 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0004 AttemptId: appattempt_1584766611743_0004_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0004_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 14:59:55,771 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 14:59:55,771 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 14:59:55,772 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0004_000001
2020-03-21 14:59:55,776 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0004_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,777 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0004_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 14:59:55,777 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,777 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,799 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0004_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0004_000001
2020-03-21 14:59:55,799 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 14:59:56,768 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0004_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0004	CONTAINERID=container_1584766611743_0004_01_000001
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0004_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0004_000001 with final state: FAILED, and exit status: 126
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 14:59:58,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0004_000001 released container container_1584766611743_0004_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0004_000001
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0004_000001
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000001 State change from FINAL_SAVING to FAILED
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0004_000002
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0004_000001 is done. finalState=FAILED
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from NEW to SUBMITTED
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0004 requests cleared
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 14:59:58,093 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 14:59:58,093 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0004 from user: xidian activated in queue: default
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6176fb9e, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0004_000002 to scheduler from user xidian in queue default
2020-03-21 14:59:58,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0004	CONTAINERID=container_1584766611743_0004_02_000001
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0004_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0004_000002 container=Container: [ContainerId: container_1584766611743_0004_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 14:59:59,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 14:59:59,100 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0004_02_000001
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0004_000002
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0004 AttemptId: appattempt_1584766611743_0004_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0004_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 14:59:59,103 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0004_000002
2020-03-21 14:59:59,104 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0004_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0004_000002
2020-03-21 14:59:59,104 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0004_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 14:59:59,105 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0004_000002
2020-03-21 14:59:59,105 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0004_000002
2020-03-21 14:59:59,111 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0004_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0004_000002
2020-03-21 14:59:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 15:00:00,098 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 15:00:01,308 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0004_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0004_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0004	CONTAINERID=container_1584766611743_0004_02_000001
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0004_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0004_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0004_000002 released container container_1584766611743_0004_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0004_000002 with final state: FAILED, and exit status: 126
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0004_000002
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0004_000002
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0004_000002 State change from FINAL_SAVING to FAILED
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 15:00:01,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0004 with final state: FAILED
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0004 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0004
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0004_000002 is done. finalState=FAILED
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0004 failed 2 times due to AM Container for appattempt_1584766611743_0004_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0004Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0004_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0004_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0004 requests cleared
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0004 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 15:00:01,310 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0004 failed 2 times due to AM Container for appattempt_1584766611743_0004_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0004Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0004_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0004_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0004
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0004 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 15:00:01,310 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0004,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0004,appMasterHost=N/A,startTime=1584773995026,finishTime=1584774001309,finalStatus=FAILED,memorySeconds=9301,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 15:54:12,394 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2020-03-21 15:54:13,160 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user xidian
2020-03-21 15:54:13,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0005
2020-03-21 15:54:13,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0005 State change from NEW to NEW_SAVING on event=START
2020-03-21 15:54:13,160 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0005
2020-03-21 15:54:13,160 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0005
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0005 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0005 from user: xidian, in queue: default
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from NEW to SUBMITTED
2020-03-21 15:54:13,161 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 15:54:13,161 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0005 from user: xidian activated in queue: default
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4f596e55, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 15:54:13,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0005_000001 to scheduler from user xidian in queue default
2020-03-21 15:54:13,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0005	CONTAINERID=container_1584766611743_0005_01_000001
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0005_000001 container=Container: [ContainerId: container_1584766611743_0005_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 15:54:13,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 15:54:13,224 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0005_01_000001
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0005 AttemptId: appattempt_1584766611743_0005_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0005_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 15:54:13,225 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0005_000001
2020-03-21 15:54:13,227 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0005_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,227 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0005_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 15:54:13,227 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,227 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,235 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0005_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0005_000001
2020-03-21 15:54:13,236 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 15:54:14,224 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0005_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0005	CONTAINERID=container_1584766611743_0005_01_000001
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0005_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 15:54:15,491 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0005_000001 with final state: FAILED, and exit status: 126
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0005_000001 released container container_1584766611743_0005_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0005_000001
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0005_000001
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000001 State change from FINAL_SAVING to FAILED
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0005_000001 is done. finalState=FAILED
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0005_000002
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0005 requests cleared
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from NEW to SUBMITTED
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 15:54:15,492 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 15:54:15,492 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0005 from user: xidian activated in queue: default
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@583145c1, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 15:54:15,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0005_000002 to scheduler from user xidian in queue default
2020-03-21 15:54:15,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0005	CONTAINERID=container_1584766611743_0005_02_000001
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0005_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0005_000002 container=Container: [ContainerId: container_1584766611743_0005_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 15:54:16,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 15:54:16,495 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0005_02_000001
2020-03-21 15:54:16,497 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 15:54:16,498 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0005_000002
2020-03-21 15:54:16,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0005 AttemptId: appattempt_1584766611743_0005_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0005_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 15:54:16,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 15:54:16,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 15:54:16,499 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0005_000002
2020-03-21 15:54:16,503 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0005_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0005_000002
2020-03-21 15:54:16,503 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0005_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 15:54:16,503 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0005_000002
2020-03-21 15:54:16,503 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0005_000002
2020-03-21 15:54:16,514 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0005_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0005_000002
2020-03-21 15:54:16,514 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 15:54:17,496 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0005_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0005_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0005	CONTAINERID=container_1584766611743_0005_02_000001
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0005_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0005_000002 with final state: FAILED, and exit status: 126
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0005_000002
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0005_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0005_000002
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0005_000002 State change from FINAL_SAVING to FAILED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0005_000002 released container container_1584766611743_0005_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0005 with final state: FAILED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0005 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0005
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0005_000002 is done. finalState=FAILED
2020-03-21 15:54:18,719 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0005 failed 2 times due to AM Container for appattempt_1584766611743_0005_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0005Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0005_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0005_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 15:54:18,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0005 requests cleared
2020-03-21 15:54:18,720 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0005 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 15:54:18,720 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0005 failed 2 times due to AM Container for appattempt_1584766611743_0005_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0005Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0005_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0005_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0005
2020-03-21 15:54:18,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 15:54:18,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0005 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 15:54:18,720 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0005,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0005,appMasterHost=N/A,startTime=1584777253160,finishTime=1584777258719,finalStatus=FAILED,memorySeconds=9202,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 16:12:38,253 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 6
2020-03-21 16:12:40,461 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 6 submitted by user xidian
2020-03-21 16:12:40,461 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0006
2020-03-21 16:12:40,461 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0006
2020-03-21 16:12:40,461 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0006 State change from NEW to NEW_SAVING on event=START
2020-03-21 16:12:40,462 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0006
2020-03-21 16:12:40,462 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0006 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 16:12:40,463 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0006 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 16:12:40,463 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0006 from user: xidian, in queue: default
2020-03-21 16:12:40,463 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0006 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 16:12:40,464 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,464 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from NEW to SUBMITTED
2020-03-21 16:12:40,464 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:12:40,464 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:12:40,464 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0006 from user: xidian activated in queue: default
2020-03-21 16:12:40,464 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0006 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@b9967a9, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 16:12:40,464 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0006_000001 to scheduler from user xidian in queue default
2020-03-21 16:12:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0006	CONTAINERID=container_1584766611743_0006_01_000001
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0006_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0006_000001 container=Container: [ContainerId: container_1584766611743_0006_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 16:12:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 16:12:40,739 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0006_01_000001
2020-03-21 16:12:40,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 16:12:40,741 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0006 AttemptId: appattempt_1584766611743_0006_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0006_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 16:12:40,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 16:12:40,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 16:12:40,742 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0006_000001
2020-03-21 16:12:40,746 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0006_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,746 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0006_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 16:12:40,746 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,746 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,761 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0006_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0006_000001
2020-03-21 16:12:40,761 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 16:12:41,739 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 16:12:43,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0006_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0006	CONTAINERID=container_1584766611743_0006_01_000001
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0006_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0006_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0006_000001 released container container_1584766611743_0006_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 16:12:43,278 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0006_000001 with final state: FAILED, and exit status: 126
2020-03-21 16:12:43,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 16:12:43,279 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0006_000001
2020-03-21 16:12:43,279 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0006_000001
2020-03-21 16:12:43,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000001 State change from FINAL_SAVING to FAILED
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0006_000001 is done. finalState=FAILED
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0006_000002
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from NEW to SUBMITTED
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0006 requests cleared
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0006 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 16:12:43,280 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:12:43,280 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0006 from user: xidian activated in queue: default
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0006 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@5de5d74f, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 16:12:43,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0006_000002 to scheduler from user xidian in queue default
2020-03-21 16:12:43,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 16:12:44,276 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 16:12:44,276 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0006	CONTAINERID=container_1584766611743_0006_02_000001
2020-03-21 16:12:44,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0006_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 16:12:44,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0006_000002 container=Container: [ContainerId: container_1584766611743_0006_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 16:12:44,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 16:12:44,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 16:12:44,277 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0006_02_000001
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0006_000002
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0006 AttemptId: appattempt_1584766611743_0006_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0006_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 16:12:44,279 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0006_000002
2020-03-21 16:12:44,282 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0006_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0006_000002
2020-03-21 16:12:44,282 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0006_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 16:12:44,282 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0006_000002
2020-03-21 16:12:44,282 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0006_000002
2020-03-21 16:12:44,296 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0006_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0006_000002
2020-03-21 16:12:44,296 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 16:12:45,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 16:12:46,550 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0006_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0006_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0006	CONTAINERID=container_1584766611743_0006_02_000001
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0006_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0006_000002 with final state: FAILED, and exit status: 126
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0006_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0006_000002
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0006_000002
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0006_000002 released container container_1584766611743_0006_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0006_000002 State change from FINAL_SAVING to FAILED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0006 with final state: FAILED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0006 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0006_000002 is done. finalState=FAILED
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0006
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0006 requests cleared
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0006 failed 2 times due to AM Container for appattempt_1584766611743_0006_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0006Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0006_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0006_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0006 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 16:12:46,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0006 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 16:12:46,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0006 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 16:12:46,552 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0006 failed 2 times due to AM Container for appattempt_1584766611743_0006_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0006Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0006_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0006_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0006
2020-03-21 16:12:46,552 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0006,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0006,appMasterHost=N/A,startTime=1584778360461,finishTime=1584778366551,finalStatus=FAILED,memorySeconds=9856,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 16:31:01,187 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 7
2020-03-21 16:31:02,021 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 7 submitted by user xidian
2020-03-21 16:31:02,021 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0007
2020-03-21 16:31:02,021 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0007
2020-03-21 16:31:02,021 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0007 State change from NEW to NEW_SAVING on event=START
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0007
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0007 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0007 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0007 from user: xidian, in queue: default
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0007 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from NEW to SUBMITTED
2020-03-21 16:31:02,022 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:31:02,022 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0007 from user: xidian activated in queue: default
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0007 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@59ca3160, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 16:31:02,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0007_000001 to scheduler from user xidian in queue default
2020-03-21 16:31:02,023 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0007	CONTAINERID=container_1584766611743_0007_01_000001
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0007_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0007_000001 container=Container: [ContainerId: container_1584766611743_0007_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 16:31:02,649 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 16:31:02,650 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0007_01_000001
2020-03-21 16:31:02,652 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 16:31:02,652 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,653 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0007 AttemptId: appattempt_1584766611743_0007_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0007_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 16:31:02,653 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 16:31:02,653 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 16:31:02,654 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0007_000001
2020-03-21 16:31:02,657 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0007_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,657 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0007_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 16:31:02,657 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,657 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,666 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0007_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0007_000001
2020-03-21 16:31:02,666 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 16:31:03,649 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0007_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0007	CONTAINERID=container_1584766611743_0007_01_000001
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0007_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0007_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0007_000001 with final state: FAILED, and exit status: 126
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 16:31:04,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0007_000001 released container container_1584766611743_0007_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0007_000001
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0007_000001
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000001 State change from FINAL_SAVING to FAILED
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0007_000002
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0007_000001 is done. finalState=FAILED
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from NEW to SUBMITTED
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0007 requests cleared
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0007 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 16:31:04,905 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:31:04,905 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0007 from user: xidian activated in queue: default
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0007 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@b0768d5, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0007_000002 to scheduler from user xidian in queue default
2020-03-21 16:31:04,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 16:31:05,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 16:31:05,906 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0007	CONTAINERID=container_1584766611743_0007_02_000001
2020-03-21 16:31:05,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0007_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 16:31:05,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0007_000002 container=Container: [ContainerId: container_1584766611743_0007_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 16:31:05,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 16:31:05,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 16:31:05,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0007_02_000001
2020-03-21 16:31:05,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 16:31:05,909 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0007_000002
2020-03-21 16:31:05,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0007 AttemptId: appattempt_1584766611743_0007_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0007_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 16:31:05,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 16:31:05,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 16:31:05,911 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0007_000002
2020-03-21 16:31:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0007_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0007_000002
2020-03-21 16:31:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0007_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 16:31:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0007_000002
2020-03-21 16:31:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0007_000002
2020-03-21 16:31:05,925 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0007_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0007_000002
2020-03-21 16:31:05,925 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 16:31:06,907 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0007_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0007_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0007	CONTAINERID=container_1584766611743_0007_02_000001
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0007_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0007_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0007_000002 with final state: FAILED, and exit status: 126
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 16:31:08,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0007_000002 released container container_1584766611743_0007_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0007_000002
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0007_000002
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0007_000002 State change from FINAL_SAVING to FAILED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0007 with final state: FAILED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0007 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0007
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0007_000002 is done. finalState=FAILED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0007 failed 2 times due to AM Container for appattempt_1584766611743_0007_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0007Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0007_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0007_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0007 requests cleared
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0007 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0007 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 16:31:08,111 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0007 failed 2 times due to AM Container for appattempt_1584766611743_0007_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0007Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0007_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0007_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0007
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0007 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 16:31:08,111 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0007,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0007,appMasterHost=N/A,startTime=1584779462021,finishTime=1584779468111,finalStatus=FAILED,memorySeconds=9135,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 19:57:55,570 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 8
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 8 submitted by user xidian
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584766611743_0008
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584766611743_0008
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0008 State change from NEW to NEW_SAVING on event=START
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584766611743_0008
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0008 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584766611743_0008 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 19:57:56,393 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584766611743_0008 from user: xidian, in queue: default
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0008 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from NEW to SUBMITTED
2020-03-21 19:57:56,394 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 19:57:56,394 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0008 from user: xidian activated in queue: default
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0008 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4be3f233, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 19:57:56,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0008_000001 to scheduler from user xidian in queue default
2020-03-21 19:57:56,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0008	CONTAINERID=container_1584766611743_0008_01_000001
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0008_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0008_000001 container=Container: [ContainerId: container_1584766611743_0008_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 19:57:56,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 19:57:56,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0008_01_000001
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0008 AttemptId: appattempt_1584766611743_0008_000001 MasterContainer: Container: [ContainerId: container_1584766611743_0008_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 19:57:56,852 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0008_000001
2020-03-21 19:57:56,854 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0008_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,854 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0008_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 19:57:56,854 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,854 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,863 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0008_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0008_000001
2020-03-21 19:57:56,863 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 19:57:57,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0008_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0008	CONTAINERID=container_1584766611743_0008_01_000001
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0008_01_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0008_01_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0008_000001 with final state: FAILED, and exit status: 126
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 19:57:59,190 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0008_000001
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0008_000001
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000001 State change from FINAL_SAVING to FAILED
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0008_000001 released container container_1584766611743_0008_01_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0008_000001 is done. finalState=FAILED
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0008 requests cleared
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0008 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584766611743_0008_000002
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from NEW to SUBMITTED
2020-03-21 19:57:59,191 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 19:57:59,191 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584766611743_0008 from user: xidian activated in queue: default
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584766611743_0008 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@38cf1baf, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 19:57:59,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584766611743_0008_000002 to scheduler from user xidian in queue default
2020-03-21 19:57:59,192 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from SUBMITTED to SCHEDULED
2020-03-21 19:58:00,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 19:58:00,191 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0008	CONTAINERID=container_1584766611743_0008_02_000001
2020-03-21 19:58:00,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584766611743_0008_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 19:58:00,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584766611743_0008_000002 container=Container: [ContainerId: container_1584766611743_0008_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 19:58:00,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 19:58:00,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 19:58:00,192 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34479 for container : container_1584766611743_0008_02_000001
2020-03-21 19:58:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 19:58:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584766611743_0008_000002
2020-03-21 19:58:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584766611743_0008 AttemptId: appattempt_1584766611743_0008_000002 MasterContainer: Container: [ContainerId: container_1584766611743_0008_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ]
2020-03-21 19:58:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 19:58:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 19:58:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584766611743_0008_000002
2020-03-21 19:58:00,202 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584766611743_0008_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0008_000002
2020-03-21 19:58:00,202 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584766611743_0008_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 19:58:00,202 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584766611743_0008_000002
2020-03-21 19:58:00,202 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584766611743_0008_000002
2020-03-21 19:58:00,220 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584766611743_0008_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] for AM appattempt_1584766611743_0008_000002
2020-03-21 19:58:00,220 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from ALLOCATED to LAUNCHED
2020-03-21 19:58:01,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584766611743_0008_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584766611743_0008_02_000001 in state: COMPLETED event:FINISHED
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584766611743_0008	CONTAINERID=container_1584766611743_0008_02_000001
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584766611743_0008_02_000001 of capacity <memory:2048, vCores:1> on host dell:34479, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584766611743_0008_000002 with final state: FAILED, and exit status: 126
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584766611743_0008_02_000001, NodeId: dell:34479, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34479 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584766611743_0008_000002
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584766611743_0008_000002
2020-03-21 19:58:02,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584766611743_0008_000002 released container container_1584766611743_0008_02_000001 on node: host: dell:34479 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584766611743_0008_000002 State change from FINAL_SAVING to FAILED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584766611743_0008 with final state: FAILED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0008 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584766611743_0008
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584766611743_0008_000002 is done. finalState=FAILED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1584766611743_0008 failed 2 times due to AM Container for appattempt_1584766611743_0008_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0008Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0008_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0008_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584766611743_0008 requests cleared
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584766611743_0008 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-21 19:58:02,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584766611743_0008 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 19:58:02,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584766611743_0008 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 19:58:02,425 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1584766611743_0008 failed 2 times due to AM Container for appattempt_1584766611743_0008_000002 exited with  exitCode: 126
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1584766611743_0008Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch: 
ExitCodeException exitCode=126: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/container_1584766611743_0008_02_000001/json: dial unix /var/run/docker.sock: connect: permission denied
/usr/bin/docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create?name=container_1584766611743_0008_02_000001: dial unix /var/run/docker.sock: connect: permission denied.
See '/usr/bin/docker run --help'.

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor.launchContainer(DockerContainerExecutor.java:247)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 126
Failing this attempt. Failing the application.	APPID=application_1584766611743_0008
2020-03-21 19:58:02,425 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584766611743_0008,name=word count,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1584766611743_0008,appMasterHost=N/A,startTime=1584791876393,finishTime=1584791882424,finalStatus=FAILED,memorySeconds=9361,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 20:05:55,441 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-21 20:05:55,443 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:05:55,443 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:05:55,544 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-21 20:05:55,548 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-21 20:05:55,548 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:05:55,549 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-21 20:05:55,551 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-21 20:05:55,551 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:05:55,552 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-21 20:05:55,552 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-21 20:05:55,555 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-21 20:05:55,569 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-21 20:05:55,569 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:05:55,569 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-21 20:05:55,574 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:05:55,574 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-21 20:05:55,577 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-21 20:05:55,574 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-21 20:05:55,581 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:05:55,582 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-21 20:05:55,582 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:05:55,582 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:05:55,582 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:05:55,583 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-21 20:05:55,586 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-21 20:05:55,586 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-21 20:05:55,586 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:05:55,587 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-21 20:05:55,587 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-21 20:06:27,437 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 20:06:27,443 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 20:06:27,596 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 20:06:27,655 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 20:06:27,684 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 20:06:27,802 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 20:06:27,926 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 20:06:27,928 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 20:06:27,931 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 20:06:27,949 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 20:06:27,950 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 20:06:27,950 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 20:06:27,958 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 20:06:27,958 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 20:06:27,959 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 20:06:27,959 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 20:06:27,991 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 20:06:28,028 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 20:06:28,028 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 20:06:28,036 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 20:06:28,040 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 20:06:28,041 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 20:06:28,043 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 20:06:28,043 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 20:06:28,044 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 20:06:28,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 20:06:28,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 20:06:28,072 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 20:06:28,072 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 20:06:28,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 20:06:28,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 20:06:28,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 20:06:28,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:06:28,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:06:28,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:06:28,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 20:06:28,079 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 20:06:28,084 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 20:06:28,084 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 20:06:28,091 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 20:06:28,091 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 20:06:28,092 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 20:06:28,092 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:06:28,092 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 20:06:28,092 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:06:28,093 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:06:28,093 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:06:28,093 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 20:06:28,093 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:06:28,094 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 20:06:28,169 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:06:28,178 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 20:06:28,276 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 20:06:28,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:06:28,276 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 20:06:28,358 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:06:28,361 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 20:06:28,367 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 20:06:28,367 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:06:28,367 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 20:06:28,453 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:06:28,453 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 20:06:28,457 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 20:06:28,457 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:06:28,457 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 20:06:28,478 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 20:06:28,559 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 20:06:28,565 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 20:06:28,580 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 20:06:28,585 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 20:06:28,587 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 20:06:28,587 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 20:06:28,587 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 20:06:28,588 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 20:06:28,588 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 20:06:28,588 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 20:06:28,590 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 20:06:28,590 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 20:06:28,794 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 20:06:28,796 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 20:06:28,796 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 20:06:28,811 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 20:06:28,914 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:06:28,914 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:06:28,914 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:06:29,652 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:06:29,652 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 20:06:29,733 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 20:06:29,733 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 20:06:29,736 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 20:06:29,736 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:06:29,736 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 20:06:30,711 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-21 20:06:30,712 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 34301 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:34301
2020-03-21 20:06:30,714 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:34301 Node Transitioned from NEW to RUNNING
2020-03-21 20:06:30,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:34301 clusterResource: <memory:8192, vCores:8>
2020-03-21 20:08:31,338 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-21 20:08:31,339 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:08:31,340 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:08:31,441 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-21 20:08:31,445 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-21 20:08:31,445 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-21 20:08:31,445 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:08:31,445 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:08:31,446 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-21 20:08:31,446 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-21 20:08:31,446 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-21 20:08:31,447 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-21 20:08:31,451 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-21 20:08:31,451 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-21 20:08:31,453 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-21 20:08:31,454 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:08:31,455 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-21 20:08:31,456 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:08:31,455 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-21 20:08:31,458 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:08:31,459 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:08:31,459 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-21 20:08:31,459 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:08:31,459 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:08:31,460 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-21 20:08:31,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-21 20:08:31,463 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-21 20:08:31,463 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:08:31,463 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-21 20:08:31,463 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-21 20:09:27,086 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 20:09:27,091 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 20:09:27,249 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 20:09:27,306 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 20:09:27,336 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 20:09:27,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 20:09:27,736 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 20:09:27,738 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 20:09:27,741 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 20:09:27,759 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 20:09:27,760 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 20:09:27,760 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 20:09:27,768 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 20:09:27,769 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 20:09:27,769 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 20:09:27,769 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 20:09:27,800 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 20:09:27,837 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 20:09:27,837 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 20:09:27,845 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 20:09:27,850 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 20:09:27,851 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 20:09:27,852 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 20:09:27,853 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 20:09:27,854 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 20:09:27,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 20:09:27,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 20:09:27,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 20:09:27,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 20:09:27,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 20:09:27,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 20:09:27,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 20:09:27,896 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 20:09:27,896 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 20:09:27,903 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 20:09:27,903 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 20:09:27,903 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 20:09:27,903 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:09:27,904 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 20:09:27,904 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:09:27,904 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:09:27,904 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:09:27,904 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 20:09:27,904 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:09:27,905 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 20:09:27,981 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:09:27,988 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 20:09:28,089 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 20:09:28,089 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:09:28,091 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 20:09:28,161 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:09:28,164 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 20:09:28,173 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 20:09:28,173 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 20:09:28,173 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:09:28,274 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:09:28,275 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 20:09:28,279 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 20:09:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:09:28,280 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 20:09:28,320 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 20:09:28,389 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 20:09:28,393 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 20:09:28,397 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 20:09:28,402 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 20:09:28,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 20:09:28,408 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 20:09:28,408 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 20:09:28,613 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 20:09:28,614 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 20:09:28,614 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 20:09:28,638 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 20:09:28,775 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:09:28,775 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:09:28,775 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:09:29,398 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:09:29,398 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 20:09:29,474 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 20:09:29,475 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 20:09:29,478 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 20:09:29,480 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:09:29,481 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 20:09:30,280 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-21 20:09:30,281 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 45321 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:45321
2020-03-21 20:09:30,284 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:45321 Node Transitioned from NEW to RUNNING
2020-03-21 20:09:30,287 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:45321 clusterResource: <memory:8192, vCores:8>
2020-03-21 20:19:27,854 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-21 20:25:47,731 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-21 20:25:47,733 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:25:47,733 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:25:47,834 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-21 20:25:47,838 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-21 20:25:47,838 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-21 20:25:47,839 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:25:47,840 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-21 20:25:47,840 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:25:47,840 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-21 20:25:47,867 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-21 20:25:47,867 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-21 20:25:47,870 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-21 20:25:47,870 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-21 20:25:47,873 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-21 20:25:47,873 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:25:47,873 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-21 20:25:47,873 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:25:47,874 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-21 20:25:47,875 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:25:47,876 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:25:47,877 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:25:47,876 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-21 20:25:47,876 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:25:47,879 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-21 20:25:47,881 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-21 20:25:47,882 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-21 20:25:47,882 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:25:47,883 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-21 20:25:47,883 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-21 20:26:21,451 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 20:26:21,456 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 20:26:21,606 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 20:26:21,663 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 20:26:21,704 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 20:26:21,823 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 20:26:21,933 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 20:26:21,936 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 20:26:21,940 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 20:26:21,960 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 20:26:21,961 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 20:26:21,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 20:26:21,971 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 20:26:21,971 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 20:26:21,971 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 20:26:21,972 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 20:26:22,008 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 20:26:22,049 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 20:26:22,049 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 20:26:22,056 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 20:26:22,059 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 20:26:22,060 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 20:26:22,061 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 20:26:22,062 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 20:26:22,063 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 20:26:22,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 20:26:22,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 20:26:22,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 20:26:22,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 20:26:22,098 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 20:26:22,098 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 20:26:22,099 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 20:26:22,105 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 20:26:22,105 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 20:26:22,111 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 20:26:22,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 20:26:22,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 20:26:22,111 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:26:22,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 20:26:22,111 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:26:22,112 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:26:22,112 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:26:22,112 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 20:26:22,112 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:26:22,113 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 20:26:22,185 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:26:22,195 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 20:26:22,296 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 20:26:22,296 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:26:22,296 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 20:26:22,370 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:26:22,373 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 20:26:22,378 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 20:26:22,378 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:26:22,379 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 20:26:22,466 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:26:22,467 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 20:26:22,470 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 20:26:22,470 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:26:22,471 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 20:26:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 20:26:22,571 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 20:26:22,576 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 20:26:22,580 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 20:26:22,587 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 20:26:22,589 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 20:26:22,589 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 20:26:22,590 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 20:26:22,590 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 20:26:22,590 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 20:26:22,590 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 20:26:22,593 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 20:26:22,593 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 20:26:22,805 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 20:26:22,806 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 20:26:22,806 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 20:26:22,825 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 20:26:22,931 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:26:22,932 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:26:22,932 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:26:23,635 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:26:23,635 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 20:26:23,710 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 20:26:23,710 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 20:26:23,713 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 20:26:23,713 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:26:23,713 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 20:26:24,679 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-21 20:26:24,680 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 41697 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:41697
2020-03-21 20:26:24,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:41697 Node Transitioned from NEW to RUNNING
2020-03-21 20:26:24,685 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:41697 clusterResource: <memory:8192, vCores:8>
2020-03-21 20:26:48,195 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-21 20:26:48,197 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:26:48,197 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:26:48,298 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-21 20:26:48,301 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-21 20:26:48,301 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-21 20:26:48,303 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:26:48,303 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-21 20:26:48,304 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-21 20:26:48,305 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-21 20:26:48,305 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:26:48,305 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-21 20:26:48,308 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-21 20:26:48,308 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-21 20:26:48,310 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:26:48,310 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-21 20:26:48,311 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-21 20:26:48,311 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-21 20:26:48,311 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-21 20:26:48,314 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:26:48,316 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:26:48,316 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-21 20:26:48,316 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-21 20:26:48,321 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-21 20:26:48,316 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-21 20:26:48,328 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-21 20:26:48,328 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-21 20:26:48,328 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-21 20:26:48,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-21 20:26:48,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-21 20:27:31,660 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-21 20:27:31,666 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-21 20:27:31,823 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-21 20:27:31,881 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-21 20:27:31,910 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-21 20:27:32,030 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-21 20:27:32,148 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-21 20:27:32,150 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-21 20:27:32,152 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-21 20:27:32,169 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-21 20:27:32,170 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-21 20:27:32,170 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-21 20:27:32,178 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-21 20:27:32,178 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-21 20:27:32,179 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-21 20:27:32,179 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-21 20:27:32,210 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-21 20:27:32,243 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-21 20:27:32,243 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-21 20:27:32,249 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-21 20:27:32,253 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-21 20:27:32,254 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-21 20:27:32,255 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-21 20:27:32,256 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-21 20:27:32,257 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-21 20:27:32,283 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-21 20:27:32,283 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-21 20:27:32,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-21 20:27:32,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-21 20:27:32,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-21 20:27:32,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-21 20:27:32,291 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-21 20:27:32,291 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:27:32,291 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:27:32,292 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-21 20:27:32,292 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-21 20:27:32,292 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-21 20:27:32,297 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-21 20:27:32,298 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-21 20:27:32,304 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-21 20:27:32,304 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-21 20:27:32,305 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-21 20:27:32,305 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:27:32,305 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-21 20:27:32,305 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:27:32,306 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:27:32,306 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:27:32,306 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-21 20:27:32,306 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-21 20:27:32,307 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-21 20:27:32,398 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:27:32,420 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-21 20:27:32,524 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-21 20:27:32,524 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:27:32,524 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-21 20:27:32,605 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:27:32,609 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-21 20:27:32,615 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-21 20:27:32,616 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:27:32,616 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-21 20:27:32,716 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-21 20:27:32,717 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-21 20:27:32,720 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-21 20:27:32,720 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:27:32,720 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-21 20:27:32,740 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-21 20:27:32,826 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-21 20:27:32,832 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-21 20:27:32,842 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-21 20:27:32,856 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-21 20:27:32,860 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-21 20:27:32,860 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-21 20:27:32,860 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-21 20:27:32,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-21 20:27:32,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-21 20:27:32,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-21 20:27:32,864 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-21 20:27:32,864 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-21 20:27:33,073 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-21 20:27:33,075 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-21 20:27:33,075 INFO org.mortbay.log: jetty-6.1.26
2020-03-21 20:27:33,092 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-21 20:27:33,203 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:27:33,203 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-21 20:27:33,203 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-21 20:27:33,916 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-21 20:27:33,916 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-21 20:27:33,998 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-21 20:27:33,998 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-21 20:27:34,000 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-21 20:27:34,000 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-21 20:27:34,000 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-21 20:27:34,933 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-21 20:27:34,935 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 42225 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:42225
2020-03-21 20:27:34,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:42225 Node Transitioned from NEW to RUNNING
2020-03-21 20:27:34,940 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:42225 clusterResource: <memory:8192, vCores:8>
2020-03-21 20:30:15,484 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-21 20:30:16,323 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-21 20:30:16,323 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584793652298_0001
2020-03-21 20:30:16,324 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584793652298_0001
2020-03-21 20:30:16,329 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from NEW to NEW_SAVING on event=START
2020-03-21 20:30:16,329 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584793652298_0001
2020-03-21 20:30:16,330 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 20:30:16,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584793652298_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 20:30:16,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584793652298_0001 from user: xidian, in queue: default
2020-03-21 20:30:16,336 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 20:30:16,354 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,355 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from NEW to SUBMITTED
2020-03-21 20:30:16,362 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:30:16,362 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:30:16,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584793652298_0001 from user: xidian activated in queue: default
2020-03-21 20:30:16,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584793652298_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@49e6b770, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 20:30:16,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584793652298_0001_000001 to scheduler from user xidian in queue default
2020-03-21 20:30:16,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 20:30:16,422 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:16,422 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000001
2020-03-21 20:30:16,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 20:30:16,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:30:16,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:30:16,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:16,432 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0001_01_000001
2020-03-21 20:30:16,440 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:16,441 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,444 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584793652298_0001 AttemptId: appattempt_1584793652298_0001_000001 MasterContainer: Container: [ContainerId: container_1584793652298_0001_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ]
2020-03-21 20:30:16,450 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 20:30:16,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 20:30:16,452 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584793652298_0001_000001
2020-03-21 20:30:16,516 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584793652298_0001_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,516 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584793652298_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 20:30:16,517 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,519 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,686 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584793652298_0001_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0001_000001
2020-03-21 20:30:16,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 20:30:17,433 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:21,236 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584793652298_0001_000001 (auth:SIMPLE)
2020-03-21 20:30:21,242 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584793652298_0001_000001
2020-03-21 20:30:21,242 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584793652298_0001	APPATTEMPTID=appattempt_1584793652298_0001_000001
2020-03-21 20:30:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from LAUNCHED to RUNNING
2020-03-21 20:30:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-21 20:30:22,441 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:22,441 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000002
2020-03-21 20:30:22,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:30:22,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-21 20:30:22,442 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:30:22,442 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:23,295 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0001_01_000002
2020-03-21 20:30:23,298 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:23,443 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:24,312 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0001
2020-03-21 20:30:27,452 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:27,452 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000003
2020-03-21 20:30:27,452 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-21 20:30:27,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:30:27,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-21 20:30:27,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:28,329 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:28,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:28,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:28,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000002 in state: COMPLETED event:FINISHED
2020-03-21 20:30:28,381 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000002
2020-03-21 20:30:28,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-21 20:30:28,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-21 20:30:28,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:28,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:28,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:30:28,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000002 on node: host: dell:42225 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-21 20:30:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0001
2020-03-21 20:30:30,516 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:30,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000003 in state: COMPLETED event:FINISHED
2020-03-21 20:30:30,516 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000003
2020-03-21 20:30:30,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:30:30,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:30:30,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:30,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:30,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:30:30,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000003 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:30:33,527 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:33,527 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000004
2020-03-21 20:30:33,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:30:33,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:30:33,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:30:33,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:34,376 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:34,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:35,383 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0001
2020-03-21 20:30:36,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000004 in state: COMPLETED event:FINISHED
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000004
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:30:36,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000004 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:30:39,530 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:39,530 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000005
2020-03-21 20:30:39,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:30:39,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:30:39,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:30:39,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:40,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:40,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:41,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0001
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000005 in state: COMPLETED event:FINISHED
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000005
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:30:42,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000005 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:30:44,436 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [dell], blacklistRemovals: []
2020-03-21 20:30:45,443 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [], blacklistRemovals: [dell]
2020-03-21 20:30:45,566 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:30:45,566 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000006
2020-03-21 20:30:45,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0001_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:30:45,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0001_000001 container=Container: [ContainerId: container_1584793652298_0001_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:30:45,568 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:30:45,568 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:30:46,568 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:30:47,457 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0001
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000006 in state: COMPLETED event:FINISHED
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000006
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:30:48,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000006 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:30:49,966 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584793652298_0001_000001 with final state: FINISHING, and exit status: -1000
2020-03-21 20:30:49,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from RUNNING to FINAL_SAVING
2020-03-21 20:30:49,969 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584793652298_0001 with final state: FINISHING
2020-03-21 20:30:49,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-21 20:30:49,970 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584793652298_0001
2020-03-21 20:30:49,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from FINAL_SAVING to FINISHING
2020-03-21 20:30:49,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-21 20:30:50,977 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584793652298_0001 unregistered successfully. 
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584793652298_0001_000001
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0001	CONTAINERID=container_1584793652298_0001_01_000001
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 20:30:59,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0001_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584793652298_0001_000001
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0001_000001 released container container_1584793652298_0001_01_000001 on node: host: dell:42225 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 20:30:59,095 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0001_000001 State change from FINISHING to FINISHED
2020-03-21 20:30:59,096 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-21 20:30:59,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584793652298_0001_000001 is done. finalState=FINISHED
2020-03-21 20:30:59,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584793652298_0001 requests cleared
2020-03-21 20:30:59,097 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584793652298_0001_000001
2020-03-21 20:30:59,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584793652298_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 20:30:59,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584793652298_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 20:30:59,097 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584793652298_0001
2020-03-21 20:30:59,099 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584793652298_0001,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584793652298_0001/,appMasterHost=dell,startTime=1584793816322,finishTime=1584793849969,finalStatus=FAILED,memorySeconds=105879,vcoreSeconds=58,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 20:37:32,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-21 20:41:27,523 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-21 20:41:30,056 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-21 20:41:30,056 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584793652298_0002
2020-03-21 20:41:30,056 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584793652298_0002
2020-03-21 20:41:30,056 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from NEW to NEW_SAVING on event=START
2020-03-21 20:41:30,057 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584793652298_0002
2020-03-21 20:41:30,057 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 20:41:30,057 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584793652298_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584793652298_0002 from user: xidian, in queue: default
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from NEW to SUBMITTED
2020-03-21 20:41:30,058 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:41:30,058 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584793652298_0002 from user: xidian activated in queue: default
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584793652298_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@2ff0633e, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 20:41:30,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584793652298_0002_000001 to scheduler from user xidian in queue default
2020-03-21 20:41:30,059 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000001
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:41:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0002_01_000001
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584793652298_0002 AttemptId: appattempt_1584793652298_0002_000001 MasterContainer: Container: [ContainerId: container_1584793652298_0002_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ]
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 20:41:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584793652298_0002_000001
2020-03-21 20:41:30,276 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584793652298_0002_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,276 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584793652298_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 20:41:30,276 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,276 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,283 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584793652298_0002_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0002_000001
2020-03-21 20:41:30,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 20:41:31,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:41:34,098 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584793652298_0002_000001 (auth:SIMPLE)
2020-03-21 20:41:34,100 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584793652298_0002_000001
2020-03-21 20:41:34,100 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584793652298_0002	APPATTEMPTID=appattempt_1584793652298_0002_000001
2020-03-21 20:41:34,100 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from LAUNCHED to RUNNING
2020-03-21 20:41:34,100 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-21 20:41:35,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:41:35,279 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000002
2020-03-21 20:41:35,279 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:41:35,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-21 20:41:35,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:41:35,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0002_01_000002
2020-03-21 20:41:36,138 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:41:36,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:41:37,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0002
2020-03-21 20:41:42,288 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:41:42,288 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000003
2020-03-21 20:41:42,288 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-21 20:41:42,288 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:41:42,288 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-21 20:41:42,289 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000002 in state: COMPLETED event:FINISHED
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000002
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-21 20:41:42,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-21 20:41:42,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:42,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:41:42,531 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000002 on node: host: dell:42225 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-21 20:41:43,173 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:41:43,531 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:41:44,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0002
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000003 in state: COMPLETED event:FINISHED
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000003
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:41:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000003 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:41:48,341 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:41:48,341 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000004
2020-03-21 20:41:48,341 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:41:48,341 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:41:48,342 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:41:48,342 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:49,208 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:41:49,343 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:41:50,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0002
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000004 in state: COMPLETED event:FINISHED
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000004
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:41:51,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000004 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:41:54,366 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:41:54,366 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000005
2020-03-21 20:41:54,366 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:41:54,366 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:41:54,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:41:54,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:55,239 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:41:55,366 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:41:56,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0002
2020-03-21 20:41:57,403 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:41:57,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000005 in state: COMPLETED event:FINISHED
2020-03-21 20:41:57,403 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000005
2020-03-21 20:41:57,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:41:57,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:41:57,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:41:57,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:41:57,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:41:57,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000005 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:41:59,253 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [dell], blacklistRemovals: []
2020-03-21 20:42:00,260 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [], blacklistRemovals: [dell]
2020-03-21 20:42:00,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:42:00,411 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000006
2020-03-21 20:42:00,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:42:00,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0002_000001 container=Container: [ContainerId: container_1584793652298_0002_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:42:00,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:42:00,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:42:01,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:42:01,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:42:02,266 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0002
2020-03-21 20:42:03,434 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:42:03,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000006 in state: COMPLETED event:FINISHED
2020-03-21 20:42:03,434 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000006
2020-03-21 20:42:03,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:42:03,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:42:03,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:42:03,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:42:03,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:42:03,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000006 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:42:04,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584793652298_0002_000001 with final state: FINISHING, and exit status: -1000
2020-03-21 20:42:04,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from RUNNING to FINAL_SAVING
2020-03-21 20:42:04,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584793652298_0002 with final state: FINISHING
2020-03-21 20:42:04,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-21 20:42:04,738 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from FINAL_SAVING to FINISHING
2020-03-21 20:42:04,738 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584793652298_0002
2020-03-21 20:42:04,738 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-21 20:42:05,743 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584793652298_0002 unregistered successfully. 
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584793652298_0002_000001
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0002	CONTAINERID=container_1584793652298_0002_01_000001
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584793652298_0002_000001
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0002_000001 State change from FINISHING to FINISHED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584793652298_0002
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0002_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0002_000001 released container container_1584793652298_0002_01_000001 on node: host: dell:42225 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584793652298_0002_000001 is done. finalState=FINISHED
2020-03-21 20:42:14,519 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584793652298_0002,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584793652298_0002/,appMasterHost=dell,startTime=1584794490056,finishTime=1584794524737,finalStatus=FAILED,memorySeconds=110457,vcoreSeconds=63,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 20:42:14,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584793652298_0002 requests cleared
2020-03-21 20:42:14,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584793652298_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 20:42:14,520 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584793652298_0002_000001
2020-03-21 20:42:14,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584793652298_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 20:44:44,864 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user xidian
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584793652298_0003
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584793652298_0003
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from NEW to NEW_SAVING on event=START
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584793652298_0003
2020-03-21 20:44:47,052 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584793652298_0003 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584793652298_0003 from user: xidian, in queue: default
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from NEW to SUBMITTED
2020-03-21 20:44:47,053 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:44:47,053 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584793652298_0003 from user: xidian activated in queue: default
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584793652298_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4120231b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 20:44:47,053 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584793652298_0003_000001 to scheduler from user xidian in queue default
2020-03-21 20:44:47,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 20:44:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:44:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000001
2020-03-21 20:44:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 20:44:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:44:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:44:47,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:44:47,731 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0003_01_000001
2020-03-21 20:44:47,734 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:44:47,735 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,735 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584793652298_0003 AttemptId: appattempt_1584793652298_0003_000001 MasterContainer: Container: [ContainerId: container_1584793652298_0003_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ]
2020-03-21 20:44:47,735 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 20:44:47,735 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 20:44:47,736 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584793652298_0003_000001
2020-03-21 20:44:47,740 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584793652298_0003_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,740 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584793652298_0003_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 20:44:47,741 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,741 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,748 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584793652298_0003_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0003_000001
2020-03-21 20:44:47,748 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 20:44:48,731 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:44:51,805 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584793652298_0003_000001 (auth:SIMPLE)
2020-03-21 20:44:51,807 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584793652298_0003_000001
2020-03-21 20:44:51,807 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584793652298_0003	APPATTEMPTID=appattempt_1584793652298_0003_000001
2020-03-21 20:44:51,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from LAUNCHED to RUNNING
2020-03-21 20:44:51,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000002
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:44:53,738 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:44:53,841 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0003_01_000002
2020-03-21 20:44:53,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:44:54,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:44:54,851 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0003
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000003
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-21 20:44:58,743 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000002 in state: COMPLETED event:FINISHED
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000002
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:44:58,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000002 on node: host: dell:42225 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-21 20:44:58,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:44:59,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:44:59,882 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0003
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000003 in state: COMPLETED event:FINISHED
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000003
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:45:01,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000003 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000004
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:45:04,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:04,907 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:45:05,018 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:45:05,913 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0003
2020-03-21 20:45:07,074 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:45:07,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000004 in state: COMPLETED event:FINISHED
2020-03-21 20:45:07,074 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000004
2020-03-21 20:45:07,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000004 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:45:07,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:45:07,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000004, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:45:07,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:07,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:45:07,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000004 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:45:10,080 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:45:10,080 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000005
2020-03-21 20:45:10,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:45:10,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:45:10,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:45:10,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:10,939 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:45:11,082 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:45:11,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0003
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000005 in state: COMPLETED event:FINISHED
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000005
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000005 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000005, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:45:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000005 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:45:14,960 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [dell], blacklistRemovals: []
2020-03-21 20:45:15,966 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: blacklist are updated in Scheduler.blacklistAdditions: [], blacklistRemovals: [dell]
2020-03-21 20:45:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:45:16,088 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000006
2020-03-21 20:45:16,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0003_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:45:16,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0003_000001 container=Container: [ContainerId: container_1584793652298_0003_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:45:16,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:45:16,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:16,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:45:17,089 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:45:17,977 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0003
2020-03-21 20:45:19,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000006 in state: COMPLETED event:FINISHED
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000006
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000006 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000006, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:45:19,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000006 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:45:20,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584793652298_0003_000001 with final state: FINISHING, and exit status: -1000
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from RUNNING to FINAL_SAVING
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584793652298_0003 with final state: FINISHING
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584793652298_0003
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from FINAL_SAVING to FINISHING
2020-03-21 20:45:20,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-21 20:45:21,346 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584793652298_0003 unregistered successfully. 
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584793652298_0003_000001
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0003_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584793652298_0003_000001
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0003	CONTAINERID=container_1584793652298_0003_01_000001
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0003_000001 State change from FINISHING to FINISHED
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584793652298_0003
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0003_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0003_000001 released container container_1584793652298_0003_01_000001 on node: host: dell:42225 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 20:45:29,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584793652298_0003,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584793652298_0003/,appMasterHost=dell,startTime=1584794687052,finishTime=1584794720346,finalStatus=FAILED,memorySeconds=102195,vcoreSeconds=57,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 20:45:29,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584793652298_0003_000001 is done. finalState=FINISHED
2020-03-21 20:45:29,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584793652298_0003 requests cleared
2020-03-21 20:45:29,413 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584793652298_0003_000001
2020-03-21 20:45:29,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584793652298_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 20:45:29,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584793652298_0003 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 20:47:02,349 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user xidian
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584793652298_0004
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584793652298_0004
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from NEW to NEW_SAVING on event=START
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584793652298_0004
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584793652298_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-21 20:47:03,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584793652298_0004 from user: xidian, in queue: default
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from NEW to SUBMITTED
2020-03-21 20:47:03,096 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:47:03,096 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584793652298_0004 from user: xidian activated in queue: default
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584793652298_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6eb0292c, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584793652298_0004_000001 to scheduler from user xidian in queue default
2020-03-21 20:47:03,096 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from SUBMITTED to SCHEDULED
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000001
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0004_000001 container=Container: [ContainerId: container_1584793652298_0004_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:47:03,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0004_01_000001
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584793652298_0004 AttemptId: appattempt_1584793652298_0004_000001 MasterContainer: Container: [ContainerId: container_1584793652298_0004_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ]
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-21 20:47:03,536 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-21 20:47:03,537 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584793652298_0004_000001
2020-03-21 20:47:03,538 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584793652298_0004_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,538 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584793652298_0004_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-21 20:47:03,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,548 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584793652298_0004_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] for AM appattempt_1584793652298_0004_000001
2020-03-21 20:47:03,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from ALLOCATED to LAUNCHED
2020-03-21 20:47:04,537 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:47:07,858 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584793652298_0004_000001 (auth:SIMPLE)
2020-03-21 20:47:07,861 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584793652298_0004_000001
2020-03-21 20:47:07,861 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584793652298_0004	APPATTEMPTID=appattempt_1584793652298_0004_000001
2020-03-21 20:47:07,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from LAUNCHED to RUNNING
2020-03-21 20:47:07,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-21 20:47:09,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:47:09,543 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000002
2020-03-21 20:47:09,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-21 20:47:09,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0004_000001 container=Container: [ContainerId: container_1584793652298_0004_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-21 20:47:09,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:47:09,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:09,897 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:42225 for container : container_1584793652298_0004_01_000002
2020-03-21 20:47:09,897 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:47:10,545 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:47:10,910 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0004
2020-03-21 20:47:15,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-21 20:47:15,551 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000003
2020-03-21 20:47:15,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584793652298_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-21 20:47:15,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584793652298_0004_000001 container=Container: [ContainerId: container_1584793652298_0004_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-21 20:47:15,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-21 20:47:15,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:15,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:47:15,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0004_01_000002 in state: COMPLETED event:FINISHED
2020-03-21 20:47:15,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000002
2020-03-21 20:47:15,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-21 20:47:15,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-21 20:47:15,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0004_01_000002, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-21 20:47:15,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:15,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-21 20:47:15,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0004_000001 released container container_1584793652298_0004_01_000002 on node: host: dell:42225 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-21 20:47:15,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-21 20:47:16,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-21 20:47:16,944 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584793652298_0004
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584793652298_0004_000001 with final state: FINISHING, and exit status: -1000
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from RUNNING to FINAL_SAVING
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584793652298_0004 with final state: FINISHING
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584793652298_0004
2020-03-21 20:47:19,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from FINAL_SAVING to FINISHING
2020-03-21 20:47:19,659 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-21 20:47:20,665 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584793652298_0004 unregistered successfully. 
2020-03-21 20:47:22,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:47:22,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0004_01_000003 in state: COMPLETED event:FINISHED
2020-03-21 20:47:22,337 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000003
2020-03-21 20:47:22,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:42225, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-21 20:47:22,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-21 20:47:22,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0004_01_000003, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-21 20:47:22,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:22,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-21 20:47:22,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0004_000001 released container container_1584793652298_0004_01_000003 on node: host: dell:42225 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584793652298_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584793652298_0004_01_000001 in state: COMPLETED event:FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584793652298_0004_000001
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584793652298_0004_000001
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584793652298_0004	CONTAINERID=container_1584793652298_0004_01_000001
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584793652298_0004_000001 State change from FINISHING to FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584793652298_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:42225, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584793652298_0004 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584793652298_0004
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584793652298_0004_01_000001, NodeId: dell:42225, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:42225 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584793652298_0004_000001 released container container_1584793652298_0004_01_000001 on node: host: dell:42225 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584793652298_0004_000001 is done. finalState=FINISHED
2020-03-21 20:47:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584793652298_0004,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584793652298_0004/,appMasterHost=dell,startTime=1584794823094,finishTime=1584794839658,finalStatus=SUCCEEDED,memorySeconds=68202,vcoreSeconds=38,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-21 20:47:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584793652298_0004 requests cleared
2020-03-21 20:47:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584793652298_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-21 20:47:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584793652298_0004_000001
2020-03-21 20:47:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584793652298_0004 user: xidian leaf-queue of parent: root #applications: 0
2020-03-21 20:47:32,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-22 00:16:58,234 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-22 00:16:58,237 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-22 00:16:58,238 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-22 00:16:58,338 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-22 00:16:58,341 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-22 00:16:58,341 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-22 00:16:58,341 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-22 00:16:58,343 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-22 00:16:58,343 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-22 00:16:58,344 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-22 00:16:58,347 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-22 00:16:58,347 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-22 00:16:58,349 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-22 00:16:58,350 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-22 00:16:58,351 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-22 00:16:58,355 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-22 00:16:58,355 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-22 00:16:58,355 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-22 00:16:58,356 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-22 00:16:58,356 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-22 00:16:58,361 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-22 00:16:58,361 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-22 00:16:58,356 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-22 00:16:58,356 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-22 00:16:58,362 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-22 00:16:58,367 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-22 00:16:58,367 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-22 00:16:58,368 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-22 00:16:58,368 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-22 00:16:58,368 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-22 15:50:52,431 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-22 15:50:52,462 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-22 15:50:52,618 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-22 15:50:52,675 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-22 15:50:52,752 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-22 15:50:52,891 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-22 15:50:53,065 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-22 15:50:53,068 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-22 15:50:53,073 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-22 15:50:53,104 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-22 15:50:53,124 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-22 15:50:53,124 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-22 15:50:53,146 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-22 15:50:53,146 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-22 15:50:53,147 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-22 15:50:53,148 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-22 15:50:53,211 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-22 15:50:53,266 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-22 15:50:53,266 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-22 15:50:53,277 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-22 15:50:53,285 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-22 15:50:53,286 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-22 15:50:53,287 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-22 15:50:53,288 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-22 15:50:53,289 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-22 15:50:53,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-22 15:50:53,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-22 15:50:53,332 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-22 15:50:53,332 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-22 15:50:53,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-22 15:50:53,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-22 15:50:53,340 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-22 15:50:53,340 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-22 15:50:53,340 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-22 15:50:53,341 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-22 15:50:53,341 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-22 15:50:53,341 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-22 15:50:53,348 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-22 15:50:53,348 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-22 15:50:53,357 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-22 15:50:53,357 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-22 15:50:53,357 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-22 15:50:53,357 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-22 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-22 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-22 15:50:53,359 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-22 15:50:53,359 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-22 15:50:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-22 15:50:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-22 15:50:53,360 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-22 15:50:53,445 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-22 15:50:53,453 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-22 15:50:53,623 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-22 15:50:53,623 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-22 15:50:53,623 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-22 15:50:53,765 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-22 15:50:53,770 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-22 15:50:53,777 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-22 15:50:53,777 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-22 15:50:53,777 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-22 15:50:53,915 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-22 15:50:53,915 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-22 15:50:53,921 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-22 15:50:53,921 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-22 15:50:53,921 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-22 15:50:53,967 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-22 15:50:54,078 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-22 15:50:54,085 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-22 15:50:54,090 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-22 15:50:54,096 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-22 15:50:54,099 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-22 15:50:54,102 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-22 15:50:54,102 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-22 15:50:54,585 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-22 15:50:54,587 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-22 15:50:54,587 INFO org.mortbay.log: jetty-6.1.26
2020-03-22 15:50:54,606 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-22 15:50:54,738 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-22 15:50:54,739 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-22 15:50:54,739 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-22 15:50:55,868 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-22 15:50:55,869 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-22 15:50:55,962 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-22 15:50:55,963 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-22 15:50:55,966 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-22 15:50:55,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-22 15:50:55,984 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-22 15:50:56,683 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-22 15:50:56,685 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 46165 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:46165
2020-03-22 15:50:56,687 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:46165 Node Transitioned from NEW to RUNNING
2020-03-22 15:50:56,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:46165 clusterResource: <memory:8192, vCores:8>
2020-03-22 15:52:11,408 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-22 15:52:12,839 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-22 15:52:12,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0001
2020-03-22 15:52:12,840 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0001
2020-03-22 15:52:12,851 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from NEW to NEW_SAVING on event=START
2020-03-22 15:52:12,852 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0001
2020-03-22 15:52:12,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-22 15:52:12,853 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-22 15:52:12,853 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0001 from user: xidian, in queue: default
2020-03-22 15:52:12,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-22 15:52:12,871 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0001_000001
2020-03-22 15:52:12,872 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from NEW to SUBMITTED
2020-03-22 15:52:12,880 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-22 15:52:12,880 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-22 15:52:12,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0001 from user: xidian activated in queue: default
2020-03-22 15:52:12,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@46fc3eb1, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-22 15:52:12,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0001_000001 to scheduler from user xidian in queue default
2020-03-22 15:52:12,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-22 15:52:12,948 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:52:12,948 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000001
2020-03-22 15:52:12,948 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-22 15:52:12,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0001_000001 container=Container: [ContainerId: container_1584863453349_0001_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-22 15:52:12,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-22 15:52:12,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:12,958 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0001_01_000001
2020-03-22 15:52:12,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:52:12,965 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0001_000001
2020-03-22 15:52:12,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0001 AttemptId: appattempt_1584863453349_0001_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0001_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-22 15:52:12,975 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-22 15:52:12,976 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-22 15:52:12,978 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0001_000001
2020-03-22 15:52:13,028 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0001_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0001_000001
2020-03-22 15:52:13,028 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-22 15:52:13,029 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0001_000001
2020-03-22 15:52:13,031 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0001_000001
2020-03-22 15:52:13,198 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0001_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0001_000001
2020-03-22 15:52:13,199 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-22 15:52:13,944 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:52:25,667 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0001_000001 (auth:SIMPLE)
2020-03-22 15:52:25,673 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0001_000001
2020-03-22 15:52:25,673 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0001	APPATTEMPTID=appattempt_1584863453349_0001_000001
2020-03-22 15:52:25,673 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from LAUNCHED to RUNNING
2020-03-22 15:52:25,673 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-22 15:52:26,974 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:52:26,974 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000002
2020-03-22 15:52:26,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-22 15:52:26,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0001_000001 container=Container: [ContainerId: container_1584863453349_0001_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-22 15:52:26,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-22 15:52:26,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:28,591 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0001_01_000002
2020-03-22 15:52:28,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:52:28,977 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:52:29,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0001
2020-03-22 15:52:32,984 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:52:32,985 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000003
2020-03-22 15:52:32,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-22 15:52:32,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0001_000001 container=Container: [ContainerId: container_1584863453349_0001_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-22 15:52:32,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-22 15:52:32,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:33,554 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:52:33,554 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0001_01_000002 in state: COMPLETED event:FINISHED
2020-03-22 15:52:33,554 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000002
2020-03-22 15:52:33,554 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-22 15:52:33,554 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-22 15:52:33,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0001_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-22 15:52:33,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:33,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-22 15:52:33,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0001_000001 released container container_1584863453349_0001_01_000002 on node: host: dell:46165 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-22 15:52:33,662 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:52:34,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:52:34,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0001
2020-03-22 15:52:38,386 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0001_000001 with final state: FINISHING, and exit status: -1000
2020-03-22 15:52:38,388 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from RUNNING to FINAL_SAVING
2020-03-22 15:52:38,388 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0001 with final state: FINISHING
2020-03-22 15:52:38,389 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-22 15:52:38,389 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0001
2020-03-22 15:52:38,389 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from FINAL_SAVING to FINISHING
2020-03-22 15:52:38,389 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-22 15:52:38,749 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:52:38,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0001_01_000003 in state: COMPLETED event:FINISHED
2020-03-22 15:52:38,749 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000003
2020-03-22 15:52:38,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-22 15:52:38,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-22 15:52:38,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0001_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-22 15:52:38,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:38,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-22 15:52:38,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0001_000001 released container container_1584863453349_0001_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-22 15:52:39,398 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0001 unregistered successfully. 
2020-03-22 15:52:47,669 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:52:47,669 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0001_000001
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0001	CONTAINERID=container_1584863453349_0001_01_000001
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0001_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0001_000001 released container container_1584863453349_0001_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0001_000001
2020-03-22 15:52:47,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0001_000001 State change from FINISHING to FINISHED
2020-03-22 15:52:47,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-22 15:52:47,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0001_000001 is done. finalState=FINISHED
2020-03-22 15:52:47,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0001 requests cleared
2020-03-22 15:52:47,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-22 15:52:47,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-22 15:52:47,672 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0001_000001
2020-03-22 15:52:47,672 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0001
2020-03-22 15:52:47,674 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0001,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0001/,appMasterHost=dell,startTime=1584863532839,finishTime=1584863558388,finalStatus=SUCCEEDED,memorySeconds=83750,vcoreSeconds=45,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-22 15:52:49,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-22 15:52:56,284 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0002
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from NEW to NEW_SAVING on event=START
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0002
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0002
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-22 15:52:58,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0002 from user: xidian, in queue: default
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from NEW to SUBMITTED
2020-03-22 15:52:58,278 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-22 15:52:58,278 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0002 from user: xidian activated in queue: default
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@41d684a8, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-22 15:52:58,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0002_000001 to scheduler from user xidian in queue default
2020-03-22 15:52:58,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000001
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0002_000001 container=Container: [ContainerId: container_1584863453349_0002_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-22 15:52:58,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-22 15:52:58,693 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0002_01_000001
2020-03-22 15:52:58,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:52:58,694 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0002 AttemptId: appattempt_1584863453349_0002_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0002_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-22 15:52:58,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-22 15:52:58,695 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-22 15:52:58,695 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0002_000001
2020-03-22 15:52:58,696 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0002_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,696 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-22 15:52:58,697 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,697 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,704 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0002_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0002_000001
2020-03-22 15:52:58,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-22 15:52:59,695 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:53:02,313 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0002_000001 (auth:SIMPLE)
2020-03-22 15:53:02,315 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0002_000001
2020-03-22 15:53:02,315 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0002	APPATTEMPTID=appattempt_1584863453349_0002_000001
2020-03-22 15:53:02,315 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from LAUNCHED to RUNNING
2020-03-22 15:53:02,316 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000002
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0002_000001 container=Container: [ContainerId: container_1584863453349_0002_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-22 15:53:03,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-22 15:53:04,351 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0002_01_000002
2020-03-22 15:53:04,352 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:53:04,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:53:05,361 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0002
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0002_01_000002 in state: COMPLETED event:FINISHED
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000002
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-22 15:53:09,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0002_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0002_000001 released container container_1584863453349_0002_01_000002 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000003
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0002_000001 container=Container: [ContainerId: container_1584863453349_0002_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-22 15:53:09,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-22 15:53:10,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-22 15:53:10,692 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-22 15:53:11,392 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0002
2020-03-22 15:53:15,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0002_000001 with final state: FINISHING, and exit status: -1000
2020-03-22 15:53:15,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from RUNNING to FINAL_SAVING
2020-03-22 15:53:15,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0002 with final state: FINISHING
2020-03-22 15:53:15,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-22 15:53:15,112 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0002
2020-03-22 15:53:15,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from FINAL_SAVING to FINISHING
2020-03-22 15:53:15,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-22 15:53:16,118 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0002 unregistered successfully. 
2020-03-22 15:53:17,075 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:53:17,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0002_01_000003 in state: COMPLETED event:FINISHED
2020-03-22 15:53:17,075 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000003
2020-03-22 15:53:17,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-22 15:53:17,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-22 15:53:17,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0002_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-22 15:53:17,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-22 15:53:17,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-22 15:53:17,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0002_000001 released container container_1584863453349_0002_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0002_000001
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0002_000001
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0002_000001 State change from FINISHING to FINISHED
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0002	CONTAINERID=container_1584863453349_0002_01_000001
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-22 15:53:25,032 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0002
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0002_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0002_000001 released container container_1584863453349_0002_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0002_000001
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0002,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0002/,appMasterHost=dell,startTime=1584863578277,finishTime=1584863595111,finalStatus=SUCCEEDED,memorySeconds=67635,vcoreSeconds=38,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0002_000001 is done. finalState=FINISHED
2020-03-22 15:53:25,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0002 requests cleared
2020-03-22 15:53:25,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-22 15:53:25,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-22 15:53:27,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-22 16:00:53,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-23 09:24:01,730 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-23 09:24:02,828 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user xidian
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0003
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from NEW to NEW_SAVING on event=START
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0003
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0003
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0003 user: xidian leaf-queue of parent: root #applications: 1
2020-03-23 09:24:02,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0003 from user: xidian, in queue: default
2020-03-23 09:24:02,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-23 09:24:02,830 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0003_000001
2020-03-23 09:24:02,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from NEW to SUBMITTED
2020-03-23 09:24:02,830 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:24:02,830 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:24:02,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0003 from user: xidian activated in queue: default
2020-03-23 09:24:02,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@30d7a33d, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-23 09:24:02,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0003_000001 to scheduler from user xidian in queue default
2020-03-23 09:24:02,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from SUBMITTED to SCHEDULED
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000001
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0003_000001 container=Container: [ContainerId: container_1584863453349_0003_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:24:03,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:03,256 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0003_01_000001
2020-03-23 09:24:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:24:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0003_000001
2020-03-23 09:24:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0003 AttemptId: appattempt_1584863453349_0003_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0003_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-23 09:24:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-23 09:24:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-23 09:24:03,258 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0003_000001
2020-03-23 09:24:03,259 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0003_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0003_000001
2020-03-23 09:24:03,259 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0003_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-23 09:24:03,259 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0003_000001
2020-03-23 09:24:03,259 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0003_000001
2020-03-23 09:24:03,273 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0003_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0003_000001
2020-03-23 09:24:03,273 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from ALLOCATED to LAUNCHED
2020-03-23 09:24:04,258 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:24:16,111 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0003_000001 (auth:SIMPLE)
2020-03-23 09:24:16,120 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0003_000001
2020-03-23 09:24:16,120 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0003	APPATTEMPTID=appattempt_1584863453349_0003_000001
2020-03-23 09:24:16,120 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from LAUNCHED to RUNNING
2020-03-23 09:24:16,120 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000002
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0003_000001 container=Container: [ContainerId: container_1584863453349_0003_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:24:17,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:18,187 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0003_01_000002
2020-03-23 09:24:18,189 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:24:19,256 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0003
2020-03-23 09:24:19,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:24:23,286 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:24:23,286 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000003
2020-03-23 09:24:23,286 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-23 09:24:23,286 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0003_000001 container=Container: [ContainerId: container_1584863453349_0003_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:24:23,287 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-23 09:24:23,287 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:24:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0003_01_000002 in state: COMPLETED event:FINISHED
2020-03-23 09:24:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000002
2020-03-23 09:24:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-23 09:24:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-23 09:24:23,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0003_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-23 09:24:23,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:23,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:24:23,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0003_000001 released container container_1584863453349_0003_01_000002 on node: host: dell:46165 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-23 09:24:24,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:24:24,980 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:24:25,286 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0003
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0003_000001 with final state: FINISHING, and exit status: -1000
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from RUNNING to FINAL_SAVING
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0003 with final state: FINISHING
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0003
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from FINAL_SAVING to FINISHING
2020-03-23 09:24:28,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-23 09:24:29,863 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0003 unregistered successfully. 
2020-03-23 09:24:30,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:24:30,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0003_01_000003 in state: COMPLETED event:FINISHED
2020-03-23 09:24:30,369 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000003
2020-03-23 09:24:30,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-23 09:24:30,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-23 09:24:30,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0003_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-23 09:24:30,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:30,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:24:30,370 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0003_000001 released container container_1584863453349_0003_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-23 09:24:38,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:24:38,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0003_01_000001 in state: COMPLETED event:FINISHED
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0003_000001
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0003_000001
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0003	CONTAINERID=container_1584863453349_0003_01_000001
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0003_000001 State change from FINISHING to FINISHED
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0003_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0003
2020-03-23 09:24:38,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0003_000001 released container container_1584863453349_0003_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0003,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0003/,appMasterHost=dell,startTime=1584926642828,finishTime=1584926668860,finalStatus=SUCCEEDED,memorySeconds=85346,vcoreSeconds=47,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0003_000001 is done. finalState=FINISHED
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0003_000001
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0003 requests cleared
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-23 09:24:38,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0003 user: xidian leaf-queue of parent: root #applications: 0
2020-03-23 09:24:40,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-23 09:27:21,310 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user xidian
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0004
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0004
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from NEW to NEW_SAVING on event=START
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0004
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0004 from user: xidian, in queue: default
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from NEW to SUBMITTED
2020-03-23 09:27:22,152 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:27:22,152 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0004 from user: xidian activated in queue: default
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@22985e54, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-23 09:27:22,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0004_000001 to scheduler from user xidian in queue default
2020-03-23 09:27:22,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from SUBMITTED to SCHEDULED
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000001
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0004_000001 container=Container: [ContainerId: container_1584863453349_0004_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:27:22,241 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0004_01_000001
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0004 AttemptId: appattempt_1584863453349_0004_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0004_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-23 09:27:22,242 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0004_000001
2020-03-23 09:27:22,243 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0004_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,243 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0004_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-23 09:27:22,244 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,244 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,250 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0004_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0004_000001
2020-03-23 09:27:22,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from ALLOCATED to LAUNCHED
2020-03-23 09:27:23,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:27:25,844 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0004_000001 (auth:SIMPLE)
2020-03-23 09:27:25,846 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0004_000001
2020-03-23 09:27:25,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0004	APPATTEMPTID=appattempt_1584863453349_0004_000001
2020-03-23 09:27:25,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from LAUNCHED to RUNNING
2020-03-23 09:27:25,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000002
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0004_000001 container=Container: [ContainerId: container_1584863453349_0004_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:27:27,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:27,885 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0004_01_000002
2020-03-23 09:27:27,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:27:28,248 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:27:28,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0004
2020-03-23 09:27:32,252 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:27:32,252 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000003
2020-03-23 09:27:32,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-23 09:27:32,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0004_000001 container=Container: [ContainerId: container_1584863453349_0004_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:27:32,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-23 09:27:32,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:32,783 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:27:32,783 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0004_01_000002 in state: COMPLETED event:FINISHED
2020-03-23 09:27:32,783 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000002
2020-03-23 09:27:32,783 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-23 09:27:32,783 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-23 09:27:32,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0004_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-23 09:27:32,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:32,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:27:32,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0004_000001 released container container_1584863453349_0004_01_000002 on node: host: dell:46165 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-23 09:27:32,923 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:27:33,785 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:27:33,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0004
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0004_000001 with final state: FINISHING, and exit status: -1000
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from RUNNING to FINAL_SAVING
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0004 with final state: FINISHING
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0004
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from FINAL_SAVING to FINISHING
2020-03-23 09:27:36,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-23 09:27:37,192 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0004 unregistered successfully. 
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0004_01_000003 in state: COMPLETED event:FINISHED
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000003
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0004_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:37,786 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:27:37,787 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0004_000001 released container container_1584863453349_0004_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-23 09:27:46,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0004_01_000001 in state: COMPLETED event:FINISHED
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0004	CONTAINERID=container_1584863453349_0004_01_000001
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0004_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-23 09:27:46,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-23 09:27:46,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0004_000001 released container container_1584863453349_0004_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-23 09:27:46,953 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0004_000001
2020-03-23 09:27:46,954 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0004_000001
2020-03-23 09:27:46,954 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0004_000001 State change from FINISHING to FINISHED
2020-03-23 09:27:46,954 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0004 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-23 09:27:46,954 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0004
2020-03-23 09:27:46,955 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0004,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0004/,appMasterHost=dell,startTime=1584926842151,finishTime=1584926856188,finalStatus=SUCCEEDED,memorySeconds=61940,vcoreSeconds=34,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-23 09:27:46,955 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0004_000001 is done. finalState=FINISHED
2020-03-23 09:27:46,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0004 requests cleared
2020-03-23 09:27:46,961 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0004_000001
2020-03-23 09:27:46,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-23 09:27:46,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0004 user: xidian leaf-queue of parent: root #applications: 0
2020-03-23 09:27:48,957 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-23 09:29:08,736 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2020-03-23 09:29:09,720 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user xidian
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0005
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0005
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from NEW to NEW_SAVING on event=START
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0005
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0005 user: xidian leaf-queue of parent: root #applications: 1
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0005 from user: xidian, in queue: default
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0005_000001
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from NEW to SUBMITTED
2020-03-23 09:29:09,721 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:29:09,721 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0005 from user: xidian activated in queue: default
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@74448f44, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-23 09:29:09,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0005_000001 to scheduler from user xidian in queue default
2020-03-23 09:29:09,722 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from SUBMITTED to SCHEDULED
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000001
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0005_000001 container=Container: [ContainerId: container_1584863453349_0005_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0005_01_000001
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0005_000001
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0005 AttemptId: appattempt_1584863453349_0005_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0005_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-23 09:29:10,045 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0005_000001
2020-03-23 09:29:10,047 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0005_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0005_000001
2020-03-23 09:29:10,047 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0005_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-23 09:29:10,047 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0005_000001
2020-03-23 09:29:10,047 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0005_000001
2020-03-23 09:29:10,054 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0005_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0005_000001
2020-03-23 09:29:10,055 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from ALLOCATED to LAUNCHED
2020-03-23 09:29:11,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:29:14,866 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0005_000001 (auth:SIMPLE)
2020-03-23 09:29:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0005_000001
2020-03-23 09:29:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0005	APPATTEMPTID=appattempt_1584863453349_0005_000001
2020-03-23 09:29:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from LAUNCHED to RUNNING
2020-03-23 09:29:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-23 09:29:16,049 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:29:16,049 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000002
2020-03-23 09:29:16,049 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0005_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-23 09:29:16,049 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0005_000001 container=Container: [ContainerId: container_1584863453349_0005_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-23 09:29:16,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:29:16,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:16,931 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0005_01_000002
2020-03-23 09:29:16,932 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:29:17,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0005
2020-03-23 09:29:18,050 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000003
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0005_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0005_000001 container=Container: [ContainerId: container_1584863453349_0005_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-23 09:29:21,060 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:21,962 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 09:29:22,061 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 09:29:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:29:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0005_01_000002 in state: COMPLETED event:FINISHED
2020-03-23 09:29:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000002
2020-03-23 09:29:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0005_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-23 09:29:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-23 09:29:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0005_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-23 09:29:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 09:29:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0005_000001 released container container_1584863453349_0005_01_000002 on node: host: dell:46165 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-23 09:29:22,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0005
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0005_000001 with final state: FINISHING, and exit status: -1000
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from RUNNING to FINAL_SAVING
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0005 with final state: FINISHING
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0005
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from FINAL_SAVING to FINISHING
2020-03-23 09:29:28,655 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-23 09:29:29,661 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0005 unregistered successfully. 
2020-03-23 09:29:30,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:29:30,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0005_01_000003 in state: COMPLETED event:FINISHED
2020-03-23 09:29:30,205 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000003
2020-03-23 09:29:30,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0005_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-23 09:29:30,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-23 09:29:30,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0005_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-23 09:29:30,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:30,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 09:29:30,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0005_000001 released container container_1584863453349_0005_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0005_000001
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0005_01_000001 in state: COMPLETED event:FINISHED
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0005_000001
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0005	CONTAINERID=container_1584863453349_0005_01_000001
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0005_000001 State change from FINISHING to FINISHED
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0005 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0005
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0005_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0005,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0005/,appMasterHost=dell,startTime=1584926949720,finishTime=1584926968655,finalStatus=SUCCEEDED,memorySeconds=73591,vcoreSeconds=43,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-23 09:29:38,380 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0005_000001 released container container_1584863453349_0005_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-23 09:29:38,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0005_000001 is done. finalState=FINISHED
2020-03-23 09:29:38,381 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0005_000001
2020-03-23 09:29:38,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0005 requests cleared
2020-03-23 09:29:38,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-23 09:29:38,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0005 user: xidian leaf-queue of parent: root #applications: 0
2020-03-23 09:29:40,384 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-23 11:13:27,753 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 6
2020-03-23 11:13:28,682 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 6 submitted by user xidian
2020-03-23 11:13:28,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1584863453349_0006
2020-03-23 11:13:28,682 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1584863453349_0006
2020-03-23 11:13:28,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from NEW to NEW_SAVING on event=START
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1584863453349_0006
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1584863453349_0006 user: xidian leaf-queue of parent: root #applications: 1
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1584863453349_0006 from user: xidian, in queue: default
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from NEW to SUBMITTED
2020-03-23 11:13:28,683 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 11:13:28,683 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1584863453349_0006 from user: xidian activated in queue: default
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1584863453349_0006 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1c2b6a0, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-23 11:13:28,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1584863453349_0006_000001 to scheduler from user xidian in queue default
2020-03-23 11:13:28,684 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from SUBMITTED to SCHEDULED
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000001
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0006_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0006_000001 container=Container: [ContainerId: container_1584863453349_0006_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:28,722 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0006_01_000001
2020-03-23 11:13:28,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 11:13:28,723 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1584863453349_0006 AttemptId: appattempt_1584863453349_0006_000001 MasterContainer: Container: [ContainerId: container_1584863453349_0006_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ]
2020-03-23 11:13:28,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-23 11:13:28,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-23 11:13:28,728 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1584863453349_0006_000001
2020-03-23 11:13:28,730 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1584863453349_0006_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,730 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1584863453349_0006_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-23 11:13:28,730 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,730 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,747 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1584863453349_0006_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] for AM appattempt_1584863453349_0006_000001
2020-03-23 11:13:28,747 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from ALLOCATED to LAUNCHED
2020-03-23 11:13:29,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 11:13:32,801 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1584863453349_0006_000001 (auth:SIMPLE)
2020-03-23 11:13:32,803 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1584863453349_0006_000001
2020-03-23 11:13:32,803 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1584863453349_0006	APPATTEMPTID=appattempt_1584863453349_0006_000001
2020-03-23 11:13:32,803 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from LAUNCHED to RUNNING
2020-03-23 11:13:32,803 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-23 11:13:34,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-23 11:13:34,727 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000002
2020-03-23 11:13:34,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0006_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-23 11:13:34,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0006_000001 container=Container: [ContainerId: container_1584863453349_0006_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-23 11:13:34,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 11:13:34,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:34,846 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:46165 for container : container_1584863453349_0006_01_000002
2020-03-23 11:13:34,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 11:13:35,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 11:13:35,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0006
2020-03-23 11:13:40,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-23 11:13:40,500 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0006_01_000002 in state: COMPLETED event:FINISHED
2020-03-23 11:13:40,500 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000002
2020-03-23 11:13:40,500 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0006_01_000002 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-23 11:13:40,500 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0006_01_000002, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0006_000001 released container container_1584863453349_0006_01_000002 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000003
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1584863453349_0006_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-23 11:13:40,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1584863453349_0006_000001 container=Container: [ContainerId: container_1584863453349_0006_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-23 11:13:40,502 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-23 11:13:40,502 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:40,879 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-23 11:13:41,501 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-23 11:13:41,895 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1584863453349_0006
2020-03-23 11:13:48,226 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1584863453349_0006_000001 with final state: FINISHING, and exit status: -1000
2020-03-23 11:13:48,226 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from RUNNING to FINAL_SAVING
2020-03-23 11:13:48,226 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1584863453349_0006 with final state: FINISHING
2020-03-23 11:13:48,226 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-23 11:13:48,228 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1584863453349_0006
2020-03-23 11:13:48,228 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from FINAL_SAVING to FINISHING
2020-03-23 11:13:48,228 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-23 11:13:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-23 11:13:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0006_01_000003 in state: COMPLETED event:FINISHED
2020-03-23 11:13:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000003
2020-03-23 11:13:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0006_01_000003 of capacity <memory:1024, vCores:1> on host dell:46165, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-23 11:13:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-23 11:13:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0006_01_000003, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-23 11:13:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-23 11:13:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0006_000001 released container container_1584863453349_0006_01_000003 on node: host: dell:46165 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-23 11:13:49,230 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1584863453349_0006 unregistered successfully. 
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1584863453349_0006_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1584863453349_0006_01_000001 in state: COMPLETED event:FINISHED
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1584863453349_0006	CONTAINERID=container_1584863453349_0006_01_000001
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1584863453349_0006_01_000001 of capacity <memory:2048, vCores:1> on host dell:46165, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1584863453349_0006_000001
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1584863453349_0006_000001
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1584863453349_0006_000001 State change from FINISHING to FINISHED
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1584863453349_0006_01_000001, NodeId: dell:46165, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:46165 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1584863453349_0006 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1584863453349_0006
2020-03-23 11:13:57,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1584863453349_0006_000001 released container container_1584863453349_0006_01_000001 on node: host: dell:46165 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1584863453349_0006_000001 is done. finalState=FINISHED
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1584863453349_0006,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1584863453349_0006/,appMasterHost=dell,startTime=1584933208682,finishTime=1584933228226,finalStatus=SUCCEEDED,memorySeconds=74070,vcoreSeconds=42,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1584863453349_0006 requests cleared
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1584863453349_0006 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1584863453349_0006_000001
2020-03-23 11:13:57,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1584863453349_0006 user: xidian leaf-queue of parent: root #applications: 0
2020-03-23 11:13:59,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Rolling master-key for amrm-tokens
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Going to activate master-key with key-id -624991440 in 900000ms
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-23 15:50:53,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Going to activate master-key with key-id 1164230856 in 900000ms
2020-03-23 15:50:56,092 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-23 15:50:56,092 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 3
2020-03-23 15:50:56,092 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-23 15:50:57,452 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-23 16:05:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Activating next master key with id: -624991440
2020-03-23 16:05:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Activating next master key with id: 1164230856
2020-03-23 16:05:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Activating next master key with id: 989562041
2020-03-23 16:05:53,359 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-23 16:33:42,642 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-23 16:33:42,645 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-23 16:33:42,646 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-23 16:33:42,747 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-23 16:33:42,748 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-23 16:33:42,749 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-23 16:33:42,749 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-23 16:33:42,751 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-23 16:33:42,752 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-23 16:33:42,752 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-23 16:33:42,753 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-23 16:33:42,755 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-23 16:33:42,763 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-23 16:33:42,763 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-23 16:33:42,763 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-23 16:33:42,766 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-23 16:33:42,766 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-23 16:33:42,766 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-23 16:33:42,767 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-23 16:33:42,769 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-23 16:33:42,769 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-23 16:33:42,770 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-23 16:33:42,769 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-23 16:33:42,769 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-23 16:33:42,771 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-23 16:33:42,774 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-23 16:33:42,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-23 16:33:42,775 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-23 16:33:42,775 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-23 16:33:42,776 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 09:07:40,753 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 09:07:40,843 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 09:07:41,135 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 09:07:41,225 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 09:07:41,929 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 09:07:42,062 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 09:07:43,100 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 09:07:43,103 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 09:07:43,105 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 09:07:43,452 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 09:07:43,486 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 09:07:43,486 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 09:07:44,673 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 09:07:44,674 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 09:07:44,674 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 09:07:44,797 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 09:07:46,424 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 09:07:46,467 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 09:07:46,467 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 09:07:46,474 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 09:07:46,636 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 09:07:46,640 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 09:07:46,644 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 09:07:46,646 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 09:07:46,649 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 09:07:46,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 09:07:46,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 09:07:46,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 09:07:46,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 09:07:46,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 09:07:46,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 09:07:46,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 09:07:46,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 09:07:46,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 09:07:46,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 09:07:46,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 09:07:46,872 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 09:07:47,012 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 09:07:47,013 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 09:07:47,209 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 09:07:47,210 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 09:07:47,211 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 09:07:47,211 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 09:07:47,213 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 09:07:47,213 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 09:07:47,216 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 09:07:47,217 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 09:07:47,217 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 09:07:47,217 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 09:07:47,222 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 09:07:47,305 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 09:07:47,312 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 09:07:47,401 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 09:07:47,401 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 09:07:47,401 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 09:07:47,605 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 09:07:47,608 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 09:07:47,614 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 09:07:47,615 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 09:07:47,615 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 09:07:47,953 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 09:07:47,953 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 09:07:47,956 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 09:07:47,956 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 09:07:47,956 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 09:07:47,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 09:07:48,026 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 09:07:48,030 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 09:07:48,034 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 09:07:48,039 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 09:07:48,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 09:07:48,042 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 09:07:48,042 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 09:07:49,569 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 09:07:49,571 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 09:07:49,571 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 09:07:49,585 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 09:07:50,148 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 09:07:50,149 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 09:07:50,150 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 09:07:54,148 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 09:07:54,151 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 09:07:54,276 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 09:07:54,276 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 09:07:54,281 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 09:07:54,281 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 09:07:54,281 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 09:07:54,342 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 09:07:54,344 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 40583 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:40583
2020-03-26 09:07:54,347 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:40583 Node Transitioned from NEW to RUNNING
2020-03-26 09:07:54,352 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:40583 clusterResource: <memory:8192, vCores:8>
2020-03-26 09:17:46,649 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-26 09:28:35,238 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 09:28:37,619 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-26 09:28:37,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585184867013_0001
2020-03-26 09:28:37,621 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585184867013_0001
2020-03-26 09:28:37,652 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from NEW to NEW_SAVING on event=START
2020-03-26 09:28:37,652 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585184867013_0001
2020-03-26 09:28:37,653 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 09:28:37,654 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585184867013_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 09:28:37,657 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585184867013_0001 from user: xidian, in queue: default
2020-03-26 09:28:37,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 09:28:37,703 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585184867013_0001_000001
2020-03-26 09:28:37,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from NEW to SUBMITTED
2020-03-26 09:28:37,710 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:28:37,710 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:28:37,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585184867013_0001 from user: xidian activated in queue: default
2020-03-26 09:28:37,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585184867013_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@147d8607, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 09:28:37,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585184867013_0001_000001 to scheduler from user xidian in queue default
2020-03-26 09:28:37,713 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 09:28:38,238 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 09:28:38,238 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000001
2020-03-26 09:28:38,239 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 09:28:38,239 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0001_000001 container=Container: [ContainerId: container_1585184867013_0001_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 09:28:38,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 09:28:38,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 09:28:38,255 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0001_01_000001
2020-03-26 09:28:38,260 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 09:28:38,260 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585184867013_0001_000001
2020-03-26 09:28:38,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585184867013_0001 AttemptId: appattempt_1585184867013_0001_000001 MasterContainer: Container: [ContainerId: container_1585184867013_0001_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ]
2020-03-26 09:28:38,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 09:28:38,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 09:28:38,324 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585184867013_0001_000001
2020-03-26 09:28:38,343 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585184867013_0001_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0001_000001
2020-03-26 09:28:38,343 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585184867013_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 09:28:38,345 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585184867013_0001_000001
2020-03-26 09:28:38,347 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585184867013_0001_000001
2020-03-26 09:28:38,721 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585184867013_0001_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0001_000001
2020-03-26 09:28:38,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 09:28:39,172 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 09:29:07,747 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585184867013_0001_000001 (auth:SIMPLE)
2020-03-26 09:29:07,752 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585184867013_0001_000001
2020-03-26 09:29:07,753 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585184867013_0001	APPATTEMPTID=appattempt_1585184867013_0001_000001
2020-03-26 09:29:07,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from LAUNCHED to RUNNING
2020-03-26 09:29:07,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-26 09:29:09,215 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-26 09:29:09,215 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000002
2020-03-26 09:29:09,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:40583, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 09:29:09,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0001_000001 container=Container: [ContainerId: container_1585184867013_0001_01_000002, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 09:29:09,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 09:29:09,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 09:29:09,981 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0001_01_000002
2020-03-26 09:29:09,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 09:29:10,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585184867013_0001
2020-03-26 09:29:11,218 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 09:29:19,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-26 09:29:19,234 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000003
2020-03-26 09:29:19,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:40583, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-26 09:29:19,235 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0001_000001 container=Container: [ContainerId: container_1585184867013_0001_01_000003, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 09:29:19,235 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 09:29:19,235 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 09:29:20,029 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 09:29:20,246 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 09:29:21,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585184867013_0001
2020-03-26 09:29:21,906 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-26 09:29:21,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0001_01_000002 in state: COMPLETED event:FINISHED
2020-03-26 09:29:21,906 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000002
2020-03-26 09:29:21,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:40583, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-26 09:29:21,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-26 09:29:21,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0001_01_000002, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-26 09:29:21,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 09:29:21,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 09:29:21,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0001_000001 released container container_1585184867013_0001_01_000002 on node: host: dell:40583 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-26 09:29:27,219 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585184867013_0001_000001 with final state: FINISHING, and exit status: -1000
2020-03-26 09:29:27,221 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from RUNNING to FINAL_SAVING
2020-03-26 09:29:27,221 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585184867013_0001 with final state: FINISHING
2020-03-26 09:29:27,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-26 09:29:27,223 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585184867013_0001
2020-03-26 09:29:27,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from FINAL_SAVING to FINISHING
2020-03-26 09:29:27,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-26 09:29:28,232 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585184867013_0001 unregistered successfully. 
2020-03-26 09:29:28,517 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-26 09:29:28,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0001_01_000003 in state: COMPLETED event:FINISHED
2020-03-26 09:29:28,517 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000003
2020-03-26 09:29:28,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:40583, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 09:29:28,518 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 09:29:28,518 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0001_01_000003, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 09:29:28,518 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 09:29:28,518 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 09:29:28,518 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0001_000001 released container container_1585184867013_0001_01_000003 on node: host: dell:40583 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-26 09:29:39,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 09:29:39,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 09:29:39,012 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585184867013_0001_000001
2020-03-26 09:29:39,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0001	CONTAINERID=container_1585184867013_0001_01_000001
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0001_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0001_000001 released container container_1585184867013_0001_01_000001 on node: host: dell:40583 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585184867013_0001_000001
2020-03-26 09:29:39,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0001_000001 State change from FINISHING to FINISHED
2020-03-26 09:29:39,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-26 09:29:39,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585184867013_0001_000001 is done. finalState=FINISHED
2020-03-26 09:29:39,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585184867013_0001 requests cleared
2020-03-26 09:29:39,015 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585184867013_0001_000001
2020-03-26 09:29:39,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585184867013_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 09:29:39,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585184867013_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 09:29:39,050 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585184867013_0001
2020-03-26 09:29:39,052 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585184867013_0001,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585184867013_0001/,appMasterHost=dell,startTime=1585186117619,finishTime=1585186167221,finalStatus=SUCCEEDED,memorySeconds=146971,vcoreSeconds=81,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 09:29:41,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 09:53:42,592 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 09:56:20,384 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-26 09:56:55,406 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-03-26 09:56:56,167 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user xidian
2020-03-26 09:56:56,167 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585184867013_0004
2020-03-26 09:56:56,167 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585184867013_0004
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0004 State change from NEW to NEW_SAVING on event=START
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585184867013_0004
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585184867013_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585184867013_0004 from user: xidian, in queue: default
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from NEW to SUBMITTED
2020-03-26 09:56:56,168 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:56:56,169 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:56:56,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585184867013_0004 from user: xidian activated in queue: default
2020-03-26 09:56:56,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585184867013_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@3b901a34, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 09:56:56,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585184867013_0004_000001 to scheduler from user xidian in queue default
2020-03-26 09:56:56,169 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 09:56:56,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 09:56:56,983 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0004	CONTAINERID=container_1585184867013_0004_01_000001
2020-03-26 09:56:56,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 09:56:56,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0004_000001 container=Container: [ContainerId: container_1585184867013_0004_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 09:56:56,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 09:56:56,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 09:56:56,989 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0004_01_000001
2020-03-26 09:56:56,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 09:56:56,990 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585184867013_0004 AttemptId: appattempt_1585184867013_0004_000001 MasterContainer: Container: [ContainerId: container_1585184867013_0004_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ]
2020-03-26 09:56:56,991 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 09:56:56,991 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 09:56:56,991 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585184867013_0004_000001
2020-03-26 09:56:56,992 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585184867013_0004_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,992 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585184867013_0004_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 09:56:56,992 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,993 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,999 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585184867013_0004_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0004_000001
2020-03-26 09:56:56,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 09:56:57,984 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0004_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0004	CONTAINERID=container_1585184867013_0004_01_000001
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585184867013_0004_000001 with final state: FAILED, and exit status: -1
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 09:56:59,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0004_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585184867013_0004_000001
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0004_000001 released container container_1585184867013_0004_01_000001 on node: host: dell:40583 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585184867013_0004_000001
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000001 State change from FINAL_SAVING to FAILED
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585184867013_0004_000001 is done. finalState=FAILED
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585184867013_0004 requests cleared
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585184867013_0004_000002
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585184867013_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 09:56:59,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from NEW to SUBMITTED
2020-03-26 09:56:59,346 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:56:59,347 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 09:56:59,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585184867013_0004 from user: xidian activated in queue: default
2020-03-26 09:56:59,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585184867013_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@57109ef, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 09:56:59,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585184867013_0004_000002 to scheduler from user xidian in queue default
2020-03-26 09:56:59,347 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 09:57:00,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 09:57:00,346 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0004	CONTAINERID=container_1585184867013_0004_02_000001
2020-03-26 09:57:00,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0004_02_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 09:57:00,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0004_000002 container=Container: [ContainerId: container_1585184867013_0004_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 09:57:00,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 09:57:00,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 09:57:00,347 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0004_02_000001
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585184867013_0004_000002
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585184867013_0004 AttemptId: appattempt_1585184867013_0004_000002 MasterContainer: Container: [ContainerId: container_1585184867013_0004_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ]
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 09:57:00,349 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585184867013_0004_000002
2020-03-26 09:57:00,352 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585184867013_0004_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0004_000002
2020-03-26 09:57:00,352 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585184867013_0004_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 09:57:00,352 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585184867013_0004_000002
2020-03-26 09:57:00,352 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585184867013_0004_000002
2020-03-26 09:57:00,361 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585184867013_0004_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0004_000002
2020-03-26 09:57:00,361 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 09:57:01,348 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0004_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0004_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0004	CONTAINERID=container_1585184867013_0004_02_000001
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0004_02_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585184867013_0004_000002 with final state: FAILED, and exit status: -1
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0004_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 09:57:02,498 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585184867013_0004_000002
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585184867013_0004_000002
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0004_000002 released container container_1585184867013_0004_02_000001 on node: host: dell:40583 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0004_000002 State change from FINAL_SAVING to FAILED
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585184867013_0004 with final state: FAILED
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0004 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585184867013_0004
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585184867013_0004_000002 is done. finalState=FAILED
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585184867013_0004 requests cleared
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585184867013_0004 failed 2 times due to AM Container for appattempt_1585184867013_0004_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585184867013_0004Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585184867013_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 09:57:02,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0004 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 09:57:02,500 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585184867013_0004 failed 2 times due to AM Container for appattempt_1585184867013_0004_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585184867013_0004Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585184867013_0004
2020-03-26 09:57:02,500 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585184867013_0004 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 09:57:02,500 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585184867013_0004,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585184867013_0004,appMasterHost=N/A,startTime=1585187816167,finishTime=1585187822499,finalStatus=FAILED,memorySeconds=9246,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 10:05:45,736 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2020-03-26 10:05:46,450 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user xidian
2020-03-26 10:05:46,450 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585184867013_0005
2020-03-26 10:05:46,450 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585184867013_0005
2020-03-26 10:05:46,450 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0005 State change from NEW to NEW_SAVING on event=START
2020-03-26 10:05:46,450 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585184867013_0005
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585184867013_0005 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585184867013_0005 from user: xidian, in queue: default
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585184867013_0005_000001
2020-03-26 10:05:46,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from NEW to SUBMITTED
2020-03-26 10:05:46,451 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 10:05:46,451 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 10:05:46,452 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585184867013_0005 from user: xidian activated in queue: default
2020-03-26 10:05:46,452 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585184867013_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4aa343e1, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 10:05:46,452 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585184867013_0005_000001 to scheduler from user xidian in queue default
2020-03-26 10:05:46,452 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0005	CONTAINERID=container_1585184867013_0005_01_000001
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0005_000001 container=Container: [ContainerId: container_1585184867013_0005_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 10:05:47,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 10:05:47,107 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0005_01_000001
2020-03-26 10:05:47,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 10:05:47,108 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585184867013_0005_000001
2020-03-26 10:05:47,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585184867013_0005 AttemptId: appattempt_1585184867013_0005_000001 MasterContainer: Container: [ContainerId: container_1585184867013_0005_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ]
2020-03-26 10:05:47,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 10:05:47,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 10:05:47,109 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585184867013_0005_000001
2020-03-26 10:05:47,111 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585184867013_0005_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0005_000001
2020-03-26 10:05:47,111 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585184867013_0005_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 10:05:47,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585184867013_0005_000001
2020-03-26 10:05:47,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585184867013_0005_000001
2020-03-26 10:05:47,120 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585184867013_0005_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0005_000001
2020-03-26 10:05:47,121 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 10:05:48,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 10:05:49,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 10:05:49,313 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0005_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 10:05:49,313 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0005	CONTAINERID=container_1585184867013_0005_01_000001
2020-03-26 10:05:49,313 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585184867013_0005_000001 with final state: FAILED, and exit status: -1
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0005_01_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585184867013_0005_000001
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585184867013_0005_000001
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000001 State change from FINAL_SAVING to FAILED
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0005_000001 released container container_1585184867013_0005_01_000001 on node: host: dell:40583 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585184867013_0005_000002
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585184867013_0005_000001 is done. finalState=FAILED
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from NEW to SUBMITTED
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585184867013_0005 requests cleared
2020-03-26 10:05:49,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585184867013_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 10:05:49,315 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 10:05:49,315 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 10:05:49,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585184867013_0005 from user: xidian activated in queue: default
2020-03-26 10:05:49,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585184867013_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1a17fbf, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 10:05:49,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585184867013_0005_000002 to scheduler from user xidian in queue default
2020-03-26 10:05:49,315 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 10:05:50,315 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 10:05:50,315 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0005	CONTAINERID=container_1585184867013_0005_02_000001
2020-03-26 10:05:50,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585184867013_0005_02_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 10:05:50,316 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585184867013_0005_000002 container=Container: [ContainerId: container_1585184867013_0005_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 10:05:50,316 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 10:05:50,316 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 10:05:50,317 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40583 for container : container_1585184867013_0005_02_000001
2020-03-26 10:05:50,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 10:05:50,320 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585184867013_0005_000002
2020-03-26 10:05:50,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585184867013_0005 AttemptId: appattempt_1585184867013_0005_000002 MasterContainer: Container: [ContainerId: container_1585184867013_0005_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ]
2020-03-26 10:05:50,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 10:05:50,321 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 10:05:50,322 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585184867013_0005_000002
2020-03-26 10:05:50,325 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585184867013_0005_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0005_000002
2020-03-26 10:05:50,325 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585184867013_0005_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 10:05:50,325 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585184867013_0005_000002
2020-03-26 10:05:50,325 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585184867013_0005_000002
2020-03-26 10:05:50,332 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585184867013_0005_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] for AM appattempt_1585184867013_0005_000002
2020-03-26 10:05:50,332 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 10:05:51,317 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 10:05:52,459 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585184867013_0005_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 10:05:52,459 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585184867013_0005_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 10:05:52,459 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585184867013_0005	CONTAINERID=container_1585184867013_0005_02_000001
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585184867013_0005_02_000001 of capacity <memory:2048, vCores:1> on host dell:40583, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585184867013_0005_02_000001, NodeId: dell:40583, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40583 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585184867013_0005_000002 with final state: FAILED, and exit status: -1
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585184867013_0005_000002
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585184867013_0005_000002 released container container_1585184867013_0005_02_000001 on node: host: dell:40583 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585184867013_0005_000002
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585184867013_0005_000002 State change from FINAL_SAVING to FAILED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585184867013_0005 with final state: FAILED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0005 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585184867013_0005
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585184867013_0005_000002 is done. finalState=FAILED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585184867013_0005 failed 2 times due to AM Container for appattempt_1585184867013_0005_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585184867013_0005Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585184867013_0005 requests cleared
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585184867013_0005 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585184867013_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 10:05:52,460 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585184867013_0005 failed 2 times due to AM Container for appattempt_1585184867013_0005_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585184867013_0005Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585184867013_0005
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585184867013_0005 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 10:05:52,460 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585184867013_0005,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585184867013_0005,appMasterHost=N/A,startTime=1585188346450,finishTime=1585188352460,finalStatus=FAILED,memorySeconds=8909,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 10:08:02,346 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 10:08:02,358 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 10:08:02,363 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 10:08:02,469 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 10:08:02,492 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 10:08:02,494 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 10:08:02,498 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 10:08:02,500 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 10:08:02,501 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 10:08:02,501 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 10:08:02,504 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 10:08:02,507 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 10:08:02,512 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 10:08:02,512 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 10:08:02,513 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 10:08:02,518 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 10:08:02,518 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 10:08:02,525 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 10:08:02,526 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 10:08:02,526 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 10:08:02,527 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 10:08:02,527 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 10:08:02,528 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 10:08:02,528 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 10:08:02,529 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 10:08:02,535 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 10:08:02,535 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 10:08:02,535 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 10:08:02,536 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 10:08:02,536 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:06:40,344 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/wordcount.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:06:40,355 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:06:40,533 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:06:40,609 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:06:40,726 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:06:40,882 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:06:41,069 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:06:41,089 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:06:41,092 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:06:41,116 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:06:41,127 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:06:41,127 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:06:41,143 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:06:41,144 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:06:41,144 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:06:41,154 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:06:41,218 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:06:41,264 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:06:41,264 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:06:41,273 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:06:41,278 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:06:41,280 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:06:41,281 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:06:41,282 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:06:41,285 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:06:41,395 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:06:41,395 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:06:41,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:06:41,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:06:41,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:06:41,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:06:41,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:06:41,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:06:41,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:06:41,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:06:41,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:06:41,442 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:06:41,465 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:06:41,466 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:06:41,512 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:06:41,512 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:06:41,512 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:06:41,513 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:06:41,514 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:06:41,514 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:06:41,515 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:06:41,515 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:06:41,515 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:06:41,515 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:06:41,520 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:06:41,623 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:06:41,629 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:06:41,726 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:06:41,727 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:06:41,727 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:06:41,856 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:06:41,859 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:06:41,865 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:06:41,865 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:06:41,865 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:06:42,089 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:06:42,090 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:06:42,094 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:06:42,094 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:06:42,094 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:06:42,115 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:06:42,188 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:06:42,194 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:06:42,198 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:06:42,205 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:06:42,207 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:06:42,207 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:06:42,207 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:06:42,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:06:42,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:06:42,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:06:42,211 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:06:42,211 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:06:43,856 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:06:43,857 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:06:43,857 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:06:43,871 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:06:44,031 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:06:44,032 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:06:44,032 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:06:45,660 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:06:45,660 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:06:45,767 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:06:45,768 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:06:45,780 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:06:45,782 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:06:45,790 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:06:46,087 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:06:46,089 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 41843 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:41843
2020-03-26 16:06:46,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:41843 Node Transitioned from NEW to RUNNING
2020-03-26 16:06:46,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:41843 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:14:19,159 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:14:22,326 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-26 16:14:22,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585210001469_0001
2020-03-26 16:14:22,327 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585210001469_0001
2020-03-26 16:14:22,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0001 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:14:22,364 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585210001469_0001
2020-03-26 16:14:22,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:14:22,365 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585210001469_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:14:22,365 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585210001469_0001 from user: xidian, in queue: default
2020-03-26 16:14:22,371 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:14:22,385 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585210001469_0001_000001
2020-03-26 16:14:22,385 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from NEW to SUBMITTED
2020-03-26 16:14:22,392 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:14:22,392 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:14:22,392 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585210001469_0001 from user: xidian activated in queue: default
2020-03-26 16:14:22,392 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585210001469_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@46498c56, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:14:22,393 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585210001469_0001_000001 to scheduler from user xidian in queue default
2020-03-26 16:14:22,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:14:23,216 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:14:23,216 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0001	CONTAINERID=container_1585210001469_0001_01_000001
2020-03-26 16:14:23,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210001469_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:14:23,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210001469_0001_000001 container=Container: [ContainerId: container_1585210001469_0001_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:14:23,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:14:23,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:14:23,226 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:41843 for container : container_1585210001469_0001_01_000001
2020-03-26 16:14:23,230 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:14:23,231 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585210001469_0001_000001
2020-03-26 16:14:23,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585210001469_0001 AttemptId: appattempt_1585210001469_0001_000001 MasterContainer: Container: [ContainerId: container_1585210001469_0001_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ]
2020-03-26 16:14:23,238 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:14:23,238 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:14:23,240 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585210001469_0001_000001
2020-03-26 16:14:23,282 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585210001469_0001_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0001_000001
2020-03-26 16:14:23,282 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585210001469_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:14:23,283 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585210001469_0001_000001
2020-03-26 16:14:23,285 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585210001469_0001_000001
2020-03-26 16:14:23,541 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585210001469_0001_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0001_000001
2020-03-26 16:14:23,541 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:14:24,172 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210001469_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0001	CONTAINERID=container_1585210001469_0001_01_000001
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210001469_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210001469_0001_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:14:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210001469_0001_000001 released container container_1585210001469_0001_01_000001 on node: host: dell:41843 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:14:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585210001469_0001_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:14:26,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:14:26,251 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585210001469_0001_000001
2020-03-26 16:14:26,251 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585210001469_0001_000001
2020-03-26 16:14:26,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585210001469_0001_000002
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585210001469_0001_000001 is done. finalState=FAILED
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from NEW to SUBMITTED
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585210001469_0001 requests cleared
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585210001469_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:14:26,252 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:14:26,252 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585210001469_0001 from user: xidian activated in queue: default
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585210001469_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@51527b5, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:14:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585210001469_0001_000002 to scheduler from user xidian in queue default
2020-03-26 16:14:26,253 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:14:27,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:14:27,252 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0001	CONTAINERID=container_1585210001469_0001_02_000001
2020-03-26 16:14:27,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210001469_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:14:27,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210001469_0001_000002 container=Container: [ContainerId: container_1585210001469_0001_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:14:27,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:14:27,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:14:27,255 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:41843 for container : container_1585210001469_0001_02_000001
2020-03-26 16:14:27,258 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:14:27,258 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585210001469_0001_000002
2020-03-26 16:14:27,258 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585210001469_0001 AttemptId: appattempt_1585210001469_0001_000002 MasterContainer: Container: [ContainerId: container_1585210001469_0001_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ]
2020-03-26 16:14:27,259 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:14:27,259 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:14:27,260 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585210001469_0001_000002
2020-03-26 16:14:27,265 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585210001469_0001_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0001_000002
2020-03-26 16:14:27,265 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585210001469_0001_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:14:27,266 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585210001469_0001_000002
2020-03-26 16:14:27,266 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585210001469_0001_000002
2020-03-26 16:14:27,287 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585210001469_0001_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0001_000002
2020-03-26 16:14:27,287 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:14:28,254 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0001_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210001469_0001_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0001	CONTAINERID=container_1585210001469_0001_02_000001
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210001469_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585210001469_0001_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210001469_0001_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585210001469_0001_000002
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585210001469_0001_000002
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0001_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:14:29,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210001469_0001_000002 released container container_1585210001469_0001_02_000001 on node: host: dell:41843 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585210001469_0001 with final state: FAILED
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0001 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585210001469_0001
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585210001469_0001_000002 is done. finalState=FAILED
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585210001469_0001 requests cleared
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585210001469_0001 failed 2 times due to AM Container for appattempt_1585210001469_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585210001469_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:14:29,426 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585210001469_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:14:29,427 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0001 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:14:29,427 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585210001469_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:14:29,427 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585210001469_0001 failed 2 times due to AM Container for appattempt_1585210001469_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585210001469_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585210001469_0001
2020-03-26 16:14:29,428 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585210001469_0001,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585210001469_0001,appMasterHost=N/A,startTime=1585210462326,finishTime=1585210469426,finalStatus=FAILED,memorySeconds=10663,vcoreSeconds=5,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:16:41,286 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-26 16:16:51,678 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 16:16:52,889 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 16:16:52,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585210001469_0002
2020-03-26 16:16:52,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585210001469_0002
2020-03-26 16:16:52,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585210001469_0002
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585210001469_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585210001469_0002 from user: xidian, in queue: default
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:16:52,890 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585210001469_0002_000001
2020-03-26 16:16:52,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from NEW to SUBMITTED
2020-03-26 16:16:52,891 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:16:52,891 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:16:52,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585210001469_0002 from user: xidian activated in queue: default
2020-03-26 16:16:52,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585210001469_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@63c1a939, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:16:52,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585210001469_0002_000001 to scheduler from user xidian in queue default
2020-03-26 16:16:52,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0002	CONTAINERID=container_1585210001469_0002_01_000001
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210001469_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210001469_0002_000001 container=Container: [ContainerId: container_1585210001469_0002_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:16:53,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:16:53,716 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:41843 for container : container_1585210001469_0002_01_000001
2020-03-26 16:16:53,717 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:16:53,718 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585210001469_0002_000001
2020-03-26 16:16:53,718 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585210001469_0002 AttemptId: appattempt_1585210001469_0002_000001 MasterContainer: Container: [ContainerId: container_1585210001469_0002_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ]
2020-03-26 16:16:53,718 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:16:53,718 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:16:53,718 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585210001469_0002_000001
2020-03-26 16:16:53,719 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585210001469_0002_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0002_000001
2020-03-26 16:16:53,719 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585210001469_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:16:53,720 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585210001469_0002_000001
2020-03-26 16:16:53,720 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585210001469_0002_000001
2020-03-26 16:16:53,727 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585210001469_0002_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0002_000001
2020-03-26 16:16:53,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:16:54,718 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:16:55,928 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210001469_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0002	CONTAINERID=container_1585210001469_0002_01_000001
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210001469_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585210001469_0002_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210001469_0002_01_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585210001469_0002_000001
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585210001469_0002_000001
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210001469_0002_000001 released container container_1585210001469_0002_01_000001 on node: host: dell:41843 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:16:55,929 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585210001469_0002_000002
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585210001469_0002_000001 is done. finalState=FAILED
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585210001469_0002 requests cleared
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585210001469_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from NEW to SUBMITTED
2020-03-26 16:16:55,930 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:16:55,930 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585210001469_0002 from user: xidian activated in queue: default
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585210001469_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4fc5027b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585210001469_0002_000002 to scheduler from user xidian in queue default
2020-03-26 16:16:55,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:16:56,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:16:56,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0002	CONTAINERID=container_1585210001469_0002_02_000001
2020-03-26 16:16:56,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210001469_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:16:56,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210001469_0002_000002 container=Container: [ContainerId: container_1585210001469_0002_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:16:56,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:16:56,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:16:56,934 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:41843 for container : container_1585210001469_0002_02_000001
2020-03-26 16:16:56,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:16:56,937 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585210001469_0002_000002
2020-03-26 16:16:56,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585210001469_0002 AttemptId: appattempt_1585210001469_0002_000002 MasterContainer: Container: [ContainerId: container_1585210001469_0002_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ]
2020-03-26 16:16:56,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:16:56,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:16:56,939 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585210001469_0002_000002
2020-03-26 16:16:56,947 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585210001469_0002_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0002_000002
2020-03-26 16:16:56,947 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585210001469_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:16:56,948 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585210001469_0002_000002
2020-03-26 16:16:56,948 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585210001469_0002_000002
2020-03-26 16:16:56,968 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585210001469_0002_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] for AM appattempt_1585210001469_0002_000002
2020-03-26 16:16:56,969 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:16:57,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:16:59,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210001469_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:16:59,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210001469_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:16:59,111 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210001469_0002	CONTAINERID=container_1585210001469_0002_02_000001
2020-03-26 16:16:59,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210001469_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:41843, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585210001469_0002_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210001469_0002_02_000001, NodeId: dell:41843, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:41843 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585210001469_0002_000002
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585210001469_0002_000002
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210001469_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210001469_0002_000002 released container container_1585210001469_0002_02_000001 on node: host: dell:41843 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585210001469_0002 with final state: FAILED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585210001469_0002
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585210001469_0002_000002 is done. finalState=FAILED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585210001469_0002 failed 2 times due to AM Container for appattempt_1585210001469_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585210001469_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585210001469_0002 requests cleared
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210001469_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585210001469_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:16:59,112 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585210001469_0002 failed 2 times due to AM Container for appattempt_1585210001469_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585210001469_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585210001469_0002
2020-03-26 16:16:59,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585210001469_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:16:59,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585210001469_0002,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585210001469_0002,appMasterHost=N/A,startTime=1585210612889,finishTime=1585210619112,finalStatus=FAILED,memorySeconds=8998,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:17:23,802 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 16:17:23,806 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:17:23,810 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:17:23,911 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 16:17:23,914 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 16:17:23,915 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 16:17:23,917 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:17:23,919 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 16:17:23,922 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:17:23,922 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 16:17:23,924 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 16:17:23,924 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 16:17:23,928 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 16:17:23,928 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 16:17:23,928 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:17:23,933 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 16:17:23,935 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:17:23,935 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 16:17:23,936 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 16:17:23,938 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:17:23,939 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 16:17:23,939 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:17:23,940 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 16:17:23,940 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:17:23,940 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:17:23,943 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 16:17:23,944 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 16:17:23,944 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:17:23,944 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 16:17:23,945 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:18:00,400 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:18:00,405 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:18:00,554 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:18:00,611 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:18:00,641 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:18:00,766 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:18:00,958 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:18:00,960 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:18:00,964 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:18:00,984 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:18:00,985 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:18:00,985 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:18:00,995 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:18:00,995 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:18:00,995 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:18:00,996 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:18:01,028 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:18:01,064 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:18:01,064 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:18:01,071 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:18:01,074 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:18:01,075 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:18:01,076 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:18:01,076 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:18:01,077 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:18:01,101 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:18:01,101 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:18:01,103 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:18:01,103 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:18:01,107 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:18:01,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:18:01,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:18:01,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:18:01,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:18:01,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:18:01,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:18:01,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:18:01,114 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:18:01,114 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:18:01,120 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:18:01,121 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:18:01,121 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:18:01,121 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:18:01,121 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:18:01,121 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:18:01,122 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:18:01,122 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:18:01,122 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:18:01,122 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:18:01,123 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:18:01,197 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:18:01,208 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:18:01,317 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:18:01,317 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:18:01,317 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:18:01,398 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:18:01,403 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:18:01,410 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:18:01,411 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:18:01,411 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:18:01,515 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:18:01,515 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:18:01,519 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:18:01,519 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:18:01,520 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:18:01,544 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:18:01,638 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:18:01,644 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:18:01,649 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:18:01,656 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:18:01,658 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:18:01,658 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:18:01,658 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:18:01,658 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:18:01,658 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:18:01,659 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:18:01,661 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:18:01,661 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:18:01,845 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:18:01,846 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:18:01,846 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:18:01,863 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:18:01,977 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:18:01,978 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:18:01,978 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:18:02,674 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:18:02,674 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:18:02,755 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:18:02,756 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:18:02,758 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:18:02,759 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:18:02,759 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:18:03,711 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:18:03,712 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 45491 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:45491
2020-03-26 16:18:03,714 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:45491 Node Transitioned from NEW to RUNNING
2020-03-26 16:18:03,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:45491 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:18:06,370 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:18:32,859 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 16:18:34,303 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 16:18:34,305 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585210681115_0002
2020-03-26 16:18:34,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585210681115_0002
2020-03-26 16:18:34,310 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:18:34,310 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585210681115_0002
2020-03-26 16:18:34,311 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:18:34,311 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585210681115_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:18:34,312 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585210681115_0002 from user: xidian, in queue: default
2020-03-26 16:18:34,316 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:18:34,337 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585210681115_0002_000001
2020-03-26 16:18:34,338 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from NEW to SUBMITTED
2020-03-26 16:18:34,344 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:18:34,344 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:18:34,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585210681115_0002 from user: xidian activated in queue: default
2020-03-26 16:18:34,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585210681115_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6f2ef396, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:18:34,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585210681115_0002_000001 to scheduler from user xidian in queue default
2020-03-26 16:18:34,347 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:18:34,854 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:34,854 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000001
2020-03-26 16:18:34,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:45491, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:18:34,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000001, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:18:34,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:18:34,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:34,864 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:45491 for container : container_1585210681115_0002_01_000001
2020-03-26 16:18:34,869 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:34,870 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585210681115_0002_000001
2020-03-26 16:18:34,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585210681115_0002 AttemptId: appattempt_1585210681115_0002_000001 MasterContainer: Container: [ContainerId: container_1585210681115_0002_01_000001, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ]
2020-03-26 16:18:34,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:18:34,878 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:18:34,879 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585210681115_0002_000001
2020-03-26 16:18:34,897 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585210681115_0002_01_000001, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] for AM appattempt_1585210681115_0002_000001
2020-03-26 16:18:34,897 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585210681115_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:18:34,898 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585210681115_0002_000001
2020-03-26 16:18:34,930 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585210681115_0002_000001
2020-03-26 16:18:35,080 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585210681115_0002_01_000001, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] for AM appattempt_1585210681115_0002_000001
2020-03-26 16:18:35,080 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:18:35,853 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:37,946 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585210681115_0002_000001 (auth:SIMPLE)
2020-03-26 16:18:37,951 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585210681115_0002_000001
2020-03-26 16:18:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585210681115_0002	APPATTEMPTID=appattempt_1585210681115_0002_000001
2020-03-26 16:18:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from LAUNCHED to RUNNING
2020-03-26 16:18:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-26 16:18:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000002
2020-03-26 16:18:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:45491, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 16:18:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000002, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 16:18:39,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:39,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,864 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000003
2020-03-26 16:18:39,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:45491, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-26 16:18:39,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000003, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 16:18:39,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:39,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,865 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000004
2020-03-26 16:18:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:45491, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 16:18:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000004, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 16:18:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:39,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,868 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000005
2020-03-26 16:18:39,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:45491, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 16:18:39,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000005, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 16:18:39,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:39,869 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,869 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000006
2020-03-26 16:18:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:45491, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 16:18:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000006, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000007
2020-03-26 16:18:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000007 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000007, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:39,872 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:39,872 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:40,025 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:45491 for container : container_1585210681115_0002_01_000002
2020-03-26 16:18:40,028 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,030 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,033 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,035 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:40,863 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:40,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:40,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:40,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:40,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:40,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000007 in state: COMPLETED event:FINISHED
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000007
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000007 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000007, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:54,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000007 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000008
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000008 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000008, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:54,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:55,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:55,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:55,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000004 in state: COMPLETED event:FINISHED
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000004
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000004, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000004 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:55,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000009
2020-03-26 16:18:55,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000009 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:55,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000009, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:55,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:55,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,118 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:56,635 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:56,636 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:56,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000005 in state: COMPLETED event:FINISHED
2020-03-26 16:18:56,636 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000005
2020-03-26 16:18:56,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:56,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:56,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000005, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:56,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000005 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:56,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:56,640 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000010
2020-03-26 16:18:56,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000010 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:56,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000010, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:56,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:56,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,950 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:56,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000003 in state: COMPLETED event:FINISHED
2020-03-26 16:18:56,950 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000003
2020-03-26 16:18:56,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:56,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000003, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000003 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000011 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000011
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000011 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000011, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:56,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:56,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:57,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:57,136 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:57,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:57,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000011 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000006 in state: COMPLETED event:FINISHED
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000006
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000006, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:57,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000006 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:57,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000012 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:57,301 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000012
2020-03-26 16:18:57,301 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000012 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:57,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000012, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:18:57,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:57,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:58,144 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:58,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000012 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000002 in state: COMPLETED event:FINISHED
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000002
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:18:58,975 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000002, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000002 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000013 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000013
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000013 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:18:58,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000013, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:18:58,977 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:18:58,977 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:18:59,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:18:59,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000013 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:00,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:01,377 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000008 in state: COMPLETED event:FINISHED
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000008
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000008 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000008, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:01,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000008 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000014 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000014
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000014 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000014, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:01,379 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:02,170 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:02,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000014 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:10,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:10,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000009 in state: COMPLETED event:FINISHED
2020-03-26 16:19:10,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000009
2020-03-26 16:19:10,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000009 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:10,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000009, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000009 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000010 in state: COMPLETED event:FINISHED
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000010
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000010 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 16:19:10,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 16:19:10,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000010, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:10,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:10,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 16:19:10,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000010 on node: host: dell:45491 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000015 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000015
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000015 of capacity <memory:1024, vCores:1> on host dell:45491, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000015, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:10,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:11,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:11,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000015 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000016 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000016
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000016 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000016, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:11,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:12,212 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:12,213 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:12,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000016 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000012 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000012 in state: COMPLETED event:FINISHED
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000012
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000012 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000012, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:14,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000012 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000017 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000017
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000017 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000017, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:14,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000011 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000011 in state: COMPLETED event:FINISHED
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000011
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000011 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000011, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:14,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000011 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000018 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000018
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000018 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000018, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:14,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:15,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000014 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:15,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000014 in state: COMPLETED event:FINISHED
2020-03-26 16:19:15,153 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000014
2020-03-26 16:19:15,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000014 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:15,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:15,157 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000014, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:15,157 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:15,157 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:15,157 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000014 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000019 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000019
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000019 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000019, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:15,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:15,222 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:15,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:15,224 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000019 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:16,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000017 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:16,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000018 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:16,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000019 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000016 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000016 in state: COMPLETED event:FINISHED
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000016
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000016 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000016, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000016 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000020 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000020
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000020 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:23,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000020, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:23,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:23,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:23,343 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000020 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:24,185 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000020 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:24,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:27,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000019 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:27,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000019 in state: COMPLETED event:FINISHED
2020-03-26 16:19:27,242 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000019
2020-03-26 16:19:27,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000019 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:27,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000019, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000019 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000021 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000021
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000021 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000021, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:27,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:27,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:27,358 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000021 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:28,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000021 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:28,542 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000018 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:28,542 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000018 in state: COMPLETED event:FINISHED
2020-03-26 16:19:28,542 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000018
2020-03-26 16:19:28,542 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000018 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:28,542 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000018, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000018 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000022 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000022
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000022 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000022, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:28,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000017 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000017 in state: COMPLETED event:FINISHED
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000017
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000017 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000017, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000017 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:28,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000023 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:28,858 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000023
2020-03-26 16:19:28,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000023 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:28,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000023, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:28,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:28,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:29,363 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000022 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:29,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000023 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:29,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000022 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:29,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000023 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:31,866 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000021 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000021 in state: COMPLETED event:FINISHED
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000021
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000021 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000021, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000021 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000024 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000024
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000024 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000024, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:31,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:32,371 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000024 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:32,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000024 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:33,373 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:37,050 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000023 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000023 in state: COMPLETED event:FINISHED
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000023
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000023 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000023, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000023 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000025 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000025
2020-03-26 16:19:37,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000025 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:37,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000025, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:37,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:37,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:37,383 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000025 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:37,571 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000025 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:37,572 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000022 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:37,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000022 in state: COMPLETED event:FINISHED
2020-03-26 16:19:37,572 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000022
2020-03-26 16:19:37,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000022 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:37,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000022, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000022 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000026 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000026
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000026 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000026, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:37,573 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:38,387 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000026 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:38,573 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000026 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000024 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000024 in state: COMPLETED event:FINISHED
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000024
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000024 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000024, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:39,087 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000024 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000027 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000027
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000027 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000027, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:39,088 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:39,389 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:39,390 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000027 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:40,088 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000027 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:40,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000015 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:40,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000015 in state: COMPLETED event:FINISHED
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000015
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000015 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000015, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:40,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000015 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:40,114 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000028 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:40,114 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000028
2020-03-26 16:19:40,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000028 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:40,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000028, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:40,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:40,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000020 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000020 in state: COMPLETED event:FINISHED
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000020
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000020 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000020, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000020 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000029 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000029
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000029 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000029, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:40,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,393 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000028 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:40,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000029 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:40,484 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000028 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000025 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000025 in state: COMPLETED event:FINISHED
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000025
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000025 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000025, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:40,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000025 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000030 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000030
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585210681115_0002_01_000030 of capacity <memory:1024, vCores:1> on host dell:45491, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585210681115_0002_000001 container=Container: [ContainerId: container_1585210681115_0002_01_000030, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 16:19:40,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000013 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000013 in state: COMPLETED event:FINISHED
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000013
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000013 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000013, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 16:19:40,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000013 on node: host: dell:45491 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000026 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000026 in state: COMPLETED event:FINISHED
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000026
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000026 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000026, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 16:19:40,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000026 on node: host: dell:45491 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 16:19:41,399 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000029 Container Transitioned from ACQUIRED to RELEASED
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000029 in state: RELEASED event:RELEASED
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000029
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000029 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000029, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:41,400 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:41,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 16:19:41,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000029 on node: host: dell:45491 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: RELEASED
2020-03-26 16:19:41,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585210681115_0002
2020-03-26 16:19:41,402 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000030 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:19:41,535 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000027 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000027 in state: COMPLETED event:FINISHED
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000027
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000027 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000027, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 16:19:41,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000027 on node: host: dell:45491 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000028 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000028 in state: COMPLETED event:FINISHED
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000028
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000028 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000028, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 16:19:42,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000028 on node: host: dell:45491 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-26 16:19:42,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000030 Container Transitioned from ACQUIRED to RELEASED
2020-03-26 16:19:42,407 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000030 in state: RELEASED event:RELEASED
2020-03-26 16:19:42,408 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000030
2020-03-26 16:19:42,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000030 of capacity <memory:1024, vCores:1> on host dell:45491, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 16:19:42,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 16:19:42,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000030, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:42,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:42,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:19:42,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000030 on node: host: dell:45491 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: RELEASED
2020-03-26 16:19:43,594 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585210681115_0002_000001 with final state: FINISHING, and exit status: -1000
2020-03-26 16:19:43,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from RUNNING to FINAL_SAVING
2020-03-26 16:19:43,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585210681115_0002 with final state: FINISHING
2020-03-26 16:19:43,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-26 16:19:43,596 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585210681115_0002
2020-03-26 16:19:43,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from FINAL_SAVING to FINISHING
2020-03-26 16:19:43,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-26 16:19:44,613 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585210681115_0002 unregistered successfully. 
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585210681115_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585210681115_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585210681115_0002	CONTAINERID=container_1585210681115_0002_01_000001
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585210681115_0002_000001
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585210681115_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:45491, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:19:50,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585210681115_0002_01_000001, NodeId: dell:45491, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:45491 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:19:50,935 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:19:50,935 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:19:50,935 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585210681115_0002_000001 released container container_1585210681115_0002_01_000001 on node: host: dell:45491 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:19:50,935 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585210681115_0002_000001
2020-03-26 16:19:50,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585210681115_0002_000001 State change from FINISHING to FINISHED
2020-03-26 16:19:50,936 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585210681115_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-26 16:19:50,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585210681115_0002_000001 is done. finalState=FINISHED
2020-03-26 16:19:50,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585210681115_0002 requests cleared
2020-03-26 16:19:50,936 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585210681115_0002_000001
2020-03-26 16:19:50,937 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585210681115_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:19:50,937 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585210681115_0002
2020-03-26 16:19:50,937 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585210681115_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:19:50,938 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585210681115_0002,name=Base.jar,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585210681115_0002/,appMasterHost=dell,startTime=1585210714302,finishTime=1585210783595,finalStatus=SUCCEEDED,memorySeconds=533252,vcoreSeconds=433,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:23:49,037 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 16:23:49,043 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:23:49,045 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:23:49,145 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 16:23:49,148 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 16:23:49,149 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 16:23:49,149 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:23:49,150 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 16:23:49,151 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 16:23:49,151 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:23:49,151 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 16:23:49,154 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 16:23:49,159 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 16:23:49,159 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 16:23:49,160 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:23:49,163 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 16:23:49,163 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:23:49,163 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 16:23:49,163 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 16:23:49,165 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:23:49,166 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:23:49,166 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 16:23:49,166 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:23:49,166 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:23:49,167 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 16:23:49,169 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 16:23:49,169 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 16:23:49,169 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:23:49,170 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 16:23:49,170 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:24:44,516 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:24:44,524 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:24:44,721 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:24:44,802 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:24:44,845 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:24:44,992 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:24:45,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:24:45,114 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:24:45,119 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:24:45,140 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:24:45,142 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:24:45,142 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:24:45,154 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:24:45,155 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:24:45,155 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:24:45,156 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:24:45,198 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:24:45,238 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:24:45,238 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:24:45,247 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:24:45,253 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:24:45,255 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:24:45,256 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:24:45,257 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:24:45,258 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:24:45,296 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:24:45,296 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:24:45,298 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:24:45,298 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:24:45,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:24:45,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:24:45,306 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:24:45,306 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:24:45,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:24:45,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:24:45,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:24:45,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:24:45,315 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:24:45,316 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:24:45,326 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:24:45,326 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:24:45,326 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:24:45,326 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:24:45,327 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:24:45,327 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:24:45,327 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:24:45,327 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:24:45,327 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:24:45,327 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:24:45,329 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:24:45,409 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:24:45,418 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:24:45,543 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:24:45,543 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:24:45,543 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:24:45,652 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:24:45,656 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:24:45,665 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:24:45,668 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:24:45,668 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:24:45,839 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:24:45,840 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:24:45,844 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:24:45,846 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:24:45,846 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:24:45,895 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:24:45,974 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:24:45,980 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:24:45,985 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:24:45,990 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:24:45,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:24:45,994 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:24:45,995 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:24:46,239 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:24:46,241 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:24:46,241 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:24:46,276 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:24:46,407 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:24:46,408 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:24:46,408 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:24:47,237 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:24:47,237 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:24:47,326 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:24:47,327 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:24:47,329 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:24:47,329 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:24:47,329 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:24:48,432 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:24:48,434 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 44027 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:44027
2020-03-26 16:24:48,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:44027 Node Transitioned from NEW to RUNNING
2020-03-26 16:24:48,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:44027 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:29:36,176 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:29:37,956 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-26 16:29:37,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585211085316_0001
2020-03-26 16:29:37,957 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585211085316_0001
2020-03-26 16:29:37,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0001 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:29:37,961 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585211085316_0001
2020-03-26 16:29:37,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:29:37,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585211085316_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:29:37,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585211085316_0001 from user: xidian, in queue: default
2020-03-26 16:29:37,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:29:37,982 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211085316_0001_000001
2020-03-26 16:29:37,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from NEW to SUBMITTED
2020-03-26 16:29:37,990 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:29:37,990 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:29:37,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211085316_0001 from user: xidian activated in queue: default
2020-03-26 16:29:37,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211085316_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@167a282a, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:29:37,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211085316_0001_000001 to scheduler from user xidian in queue default
2020-03-26 16:29:37,992 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:29:38,163 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:29:38,163 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0001	CONTAINERID=container_1585211085316_0001_01_000001
2020-03-26 16:29:38,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211085316_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:29:38,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211085316_0001_000001 container=Container: [ContainerId: container_1585211085316_0001_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:29:38,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:29:38,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:29:38,179 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:44027 for container : container_1585211085316_0001_01_000001
2020-03-26 16:29:38,185 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:29:38,185 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211085316_0001_000001
2020-03-26 16:29:38,187 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211085316_0001 AttemptId: appattempt_1585211085316_0001_000001 MasterContainer: Container: [ContainerId: container_1585211085316_0001_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ]
2020-03-26 16:29:38,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:29:38,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:29:38,197 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211085316_0001_000001
2020-03-26 16:29:38,268 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211085316_0001_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0001_000001
2020-03-26 16:29:38,268 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211085316_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:29:38,269 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211085316_0001_000001
2020-03-26 16:29:38,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211085316_0001_000001
2020-03-26 16:29:38,440 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211085316_0001_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0001_000001
2020-03-26 16:29:38,441 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:29:39,176 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:29:41,125 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:29:41,125 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211085316_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:29:41,125 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0001	CONTAINERID=container_1585211085316_0001_01_000001
2020-03-26 16:29:41,125 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211085316_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211085316_0001_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211085316_0001_000001 released container container_1585211085316_0001_01_000001 on node: host: dell:44027 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:29:41,126 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211085316_0001_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:29:41,127 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:29:41,127 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211085316_0001_000001
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211085316_0001_000001
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211085316_0001_000002
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211085316_0001_000001 is done. finalState=FAILED
2020-03-26 16:29:41,128 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from NEW to SUBMITTED
2020-03-26 16:29:41,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211085316_0001 requests cleared
2020-03-26 16:29:41,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211085316_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:29:41,129 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:29:41,129 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:29:41,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211085316_0001 from user: xidian activated in queue: default
2020-03-26 16:29:41,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211085316_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@2f7cd436, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:29:41,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211085316_0001_000002 to scheduler from user xidian in queue default
2020-03-26 16:29:41,130 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:29:42,127 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:29:42,127 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0001	CONTAINERID=container_1585211085316_0001_02_000001
2020-03-26 16:29:42,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211085316_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:29:42,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211085316_0001_000002 container=Container: [ContainerId: container_1585211085316_0001_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:29:42,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:29:42,129 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:29:42,131 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:44027 for container : container_1585211085316_0001_02_000001
2020-03-26 16:29:42,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:29:42,134 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211085316_0001_000002
2020-03-26 16:29:42,134 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211085316_0001 AttemptId: appattempt_1585211085316_0001_000002 MasterContainer: Container: [ContainerId: container_1585211085316_0001_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ]
2020-03-26 16:29:42,134 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:29:42,135 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:29:42,136 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211085316_0001_000002
2020-03-26 16:29:42,141 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211085316_0001_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0001_000002
2020-03-26 16:29:42,141 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211085316_0001_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:29:42,141 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211085316_0001_000002
2020-03-26 16:29:42,141 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211085316_0001_000002
2020-03-26 16:29:42,162 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211085316_0001_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0001_000002
2020-03-26 16:29:42,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:29:43,130 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:29:44,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0001_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:29:44,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211085316_0001_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:29:44,325 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0001	CONTAINERID=container_1585211085316_0001_02_000001
2020-03-26 16:29:44,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211085316_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211085316_0001_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211085316_0001_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211085316_0001_000002
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:29:44,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211085316_0001_000002 released container container_1585211085316_0001_02_000001 on node: host: dell:44027 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:29:44,326 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211085316_0001_000002
2020-03-26 16:29:44,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0001_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:29:44,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:29:44,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585211085316_0001 with final state: FAILED
2020-03-26 16:29:44,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0001 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:29:44,328 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585211085316_0001
2020-03-26 16:29:44,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211085316_0001_000002 is done. finalState=FAILED
2020-03-26 16:29:44,329 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585211085316_0001 failed 2 times due to AM Container for appattempt_1585211085316_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211085316_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:29:44,329 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211085316_0001 requests cleared
2020-03-26 16:29:44,329 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211085316_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:29:44,330 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0001 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:29:44,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585211085316_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:29:44,331 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585211085316_0001 failed 2 times due to AM Container for appattempt_1585211085316_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211085316_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585211085316_0001
2020-03-26 16:29:44,332 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585211085316_0001,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585211085316_0001,appMasterHost=N/A,startTime=1585211377956,finishTime=1585211384328,finalStatus=FAILED,memorySeconds=10567,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:30:33,250 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 16:30:34,441 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 16:30:34,441 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585211085316_0002
2020-03-26 16:30:34,441 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585211085316_0002
2020-03-26 16:30:34,441 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:30:34,441 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585211085316_0002
2020-03-26 16:30:34,442 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:30:34,442 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585211085316_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:30:34,442 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585211085316_0002 from user: xidian, in queue: default
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211085316_0002_000001
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from NEW to SUBMITTED
2020-03-26 16:30:34,443 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:30:34,443 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211085316_0002 from user: xidian activated in queue: default
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211085316_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@60e56332, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:30:34,443 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211085316_0002_000001 to scheduler from user xidian in queue default
2020-03-26 16:30:34,444 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:30:35,430 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:30:35,431 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0002	CONTAINERID=container_1585211085316_0002_01_000001
2020-03-26 16:30:35,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211085316_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:30:35,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211085316_0002_000001 container=Container: [ContainerId: container_1585211085316_0002_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:30:35,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:30:35,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:30:35,433 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:44027 for container : container_1585211085316_0002_01_000001
2020-03-26 16:30:35,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:30:35,435 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211085316_0002_000001
2020-03-26 16:30:35,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211085316_0002 AttemptId: appattempt_1585211085316_0002_000001 MasterContainer: Container: [ContainerId: container_1585211085316_0002_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ]
2020-03-26 16:30:35,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:30:35,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:30:35,436 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211085316_0002_000001
2020-03-26 16:30:35,437 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211085316_0002_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0002_000001
2020-03-26 16:30:35,437 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211085316_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:30:35,437 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211085316_0002_000001
2020-03-26 16:30:35,437 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211085316_0002_000001
2020-03-26 16:30:35,443 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211085316_0002_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0002_000001
2020-03-26 16:30:35,443 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:30:36,433 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:30:37,678 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:30:37,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211085316_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:30:37,678 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0002	CONTAINERID=container_1585211085316_0002_01_000001
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211085316_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211085316_0002_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211085316_0002_01_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211085316_0002_000001
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211085316_0002_000001
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211085316_0002_000001 released container container_1585211085316_0002_01_000001 on node: host: dell:44027 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:30:37,679 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211085316_0002_000001 is done. finalState=FAILED
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211085316_0002_000002
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211085316_0002 requests cleared
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from NEW to SUBMITTED
2020-03-26 16:30:37,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211085316_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:30:37,680 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:30:37,681 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:30:37,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211085316_0002 from user: xidian activated in queue: default
2020-03-26 16:30:37,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211085316_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@2971d67c, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:30:37,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211085316_0002_000002 to scheduler from user xidian in queue default
2020-03-26 16:30:37,681 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:30:38,681 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:30:38,681 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0002	CONTAINERID=container_1585211085316_0002_02_000001
2020-03-26 16:30:38,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211085316_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:30:38,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211085316_0002_000002 container=Container: [ContainerId: container_1585211085316_0002_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:30:38,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:30:38,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:30:38,683 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:44027 for container : container_1585211085316_0002_02_000001
2020-03-26 16:30:38,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:30:38,686 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211085316_0002_000002
2020-03-26 16:30:38,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211085316_0002 AttemptId: appattempt_1585211085316_0002_000002 MasterContainer: Container: [ContainerId: container_1585211085316_0002_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ]
2020-03-26 16:30:38,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:30:38,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:30:38,687 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211085316_0002_000002
2020-03-26 16:30:38,689 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211085316_0002_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0002_000002
2020-03-26 16:30:38,689 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211085316_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:30:38,689 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211085316_0002_000002
2020-03-26 16:30:38,689 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211085316_0002_000002
2020-03-26 16:30:38,695 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211085316_0002_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] for AM appattempt_1585211085316_0002_000002
2020-03-26 16:30:38,695 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:30:39,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211085316_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211085316_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211085316_0002	CONTAINERID=container_1585211085316_0002_02_000001
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211085316_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:44027, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211085316_0002_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211085316_0002_02_000001, NodeId: dell:44027, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:44027 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:30:40,847 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211085316_0002_000002
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211085316_0002_000002
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211085316_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585211085316_0002 with final state: FAILED
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211085316_0002_000002 released container container_1585211085316_0002_02_000001 on node: host: dell:44027 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:30:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585211085316_0002
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211085316_0002_000002 is done. finalState=FAILED
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211085316_0002 requests cleared
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585211085316_0002 failed 2 times due to AM Container for appattempt_1585211085316_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211085316_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211085316_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211085316_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585211085316_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:30:40,849 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585211085316_0002 failed 2 times due to AM Container for appattempt_1585211085316_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211085316_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585211085316_0002
2020-03-26 16:30:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585211085316_0002,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585211085316_0002,appMasterHost=N/A,startTime=1585211434441,finishTime=1585211440848,finalStatus=FAILED,memorySeconds=9038,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:33:22,964 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 16:33:22,965 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:33:22,966 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:33:23,066 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 16:33:23,069 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 16:33:23,069 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 16:33:23,070 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:33:23,071 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 16:33:23,071 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:33:23,072 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 16:33:23,072 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 16:33:23,074 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 16:33:23,079 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 16:33:23,079 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 16:33:23,081 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:33:23,081 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 16:33:23,081 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:33:23,081 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 16:33:23,081 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 16:33:23,082 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:33:23,085 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:33:23,086 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:33:23,085 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:33:23,085 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 16:33:23,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 16:33:23,090 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 16:33:23,091 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 16:33:23,091 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:33:23,091 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 16:33:23,092 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:34:12,597 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:34:12,602 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:34:12,759 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:34:12,815 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:34:12,845 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:34:12,963 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:34:13,058 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:34:13,061 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:34:13,063 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:34:13,080 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:34:13,080 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:34:13,081 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:34:13,089 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:34:13,089 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:34:13,089 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:34:13,090 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:34:13,121 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:34:13,156 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:34:13,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:34:13,163 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:34:13,167 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:34:13,168 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:34:13,169 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:34:13,169 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:34:13,170 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:34:13,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:34:13,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:34:13,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:34:13,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:34:13,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:34:13,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:34:13,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:34:13,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:34:13,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:34:13,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:34:13,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:34:13,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:34:13,206 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:34:13,206 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:34:13,212 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:34:13,212 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:34:13,212 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:34:13,212 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:34:13,212 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:34:13,212 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:34:13,213 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:34:13,213 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:34:13,213 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:34:13,213 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:34:13,214 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:34:13,302 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:34:13,323 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:34:13,422 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:34:13,423 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:34:13,423 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:34:13,496 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:34:13,499 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:34:13,504 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:34:13,504 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:34:13,504 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:34:13,591 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:34:13,592 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:34:13,595 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:34:13,595 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:34:13,595 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:34:13,624 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:34:13,694 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:34:13,699 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:34:13,704 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:34:13,710 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:34:13,712 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:34:13,712 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:34:13,712 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:34:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:34:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:34:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:34:13,715 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:34:13,715 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:34:13,911 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:34:13,912 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:34:13,912 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:34:13,927 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:34:14,043 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:34:14,045 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:34:14,045 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:34:14,733 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:34:14,734 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:34:14,814 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:34:14,814 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:34:14,816 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:34:14,817 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:34:14,817 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:34:15,769 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:34:15,771 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 34945 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:34945
2020-03-26 16:34:15,773 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:34945 Node Transitioned from NEW to RUNNING
2020-03-26 16:34:15,776 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:34945 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:34:39,443 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:34:41,497 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-26 16:34:41,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585211653206_0001
2020-03-26 16:34:41,498 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585211653206_0001
2020-03-26 16:34:41,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211653206_0001 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:34:41,510 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585211653206_0001
2020-03-26 16:34:41,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211653206_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:34:41,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585211653206_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:34:41,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585211653206_0001 from user: xidian, in queue: default
2020-03-26 16:34:41,523 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211653206_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:34:41,543 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211653206_0001_000001
2020-03-26 16:34:41,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from NEW to SUBMITTED
2020-03-26 16:34:41,552 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:34:41,553 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:34:41,553 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211653206_0001 from user: xidian activated in queue: default
2020-03-26 16:34:41,553 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211653206_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7add438d, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:34:41,553 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211653206_0001_000001 to scheduler from user xidian in queue default
2020-03-26 16:34:41,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:34:41,882 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:34:41,882 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211653206_0001	CONTAINERID=container_1585211653206_0001_01_000001
2020-03-26 16:34:41,882 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211653206_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:34945, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:34:41,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211653206_0001_000001 container=Container: [ContainerId: container_1585211653206_0001_01_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:34:41,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:34:41,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:34:41,895 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34945 for container : container_1585211653206_0001_01_000001
2020-03-26 16:34:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:34:41,902 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211653206_0001_000001
2020-03-26 16:34:41,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211653206_0001 AttemptId: appattempt_1585211653206_0001_000001 MasterContainer: Container: [ContainerId: container_1585211653206_0001_01_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ]
2020-03-26 16:34:41,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:34:41,911 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:34:41,912 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211653206_0001_000001
2020-03-26 16:34:41,931 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211653206_0001_01_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] for AM appattempt_1585211653206_0001_000001
2020-03-26 16:34:41,931 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211653206_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:34:41,989 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211653206_0001_000001
2020-03-26 16:34:41,991 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211653206_0001_000001
2020-03-26 16:34:42,179 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211653206_0001_01_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] for AM appattempt_1585211653206_0001_000001
2020-03-26 16:34:42,179 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:34:42,893 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211653206_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211653206_0001	CONTAINERID=container_1585211653206_0001_01_000001
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211653206_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:34945, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211653206_0001_01_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:34:44,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211653206_0001_000001 released container container_1585211653206_0001_01_000001 on node: host: dell:34945 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:34:44,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211653206_0001_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:34:44,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:34:44,807 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211653206_0001_000001
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211653206_0001_000001
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211653206_0001_000002
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from NEW to SUBMITTED
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211653206_0001_000001 is done. finalState=FAILED
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211653206_0001 requests cleared
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211653206_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:34:44,808 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:34:44,808 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211653206_0001 from user: xidian activated in queue: default
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211653206_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@5a186d63, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:34:44,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211653206_0001_000002 to scheduler from user xidian in queue default
2020-03-26 16:34:44,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:34:45,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:34:45,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211653206_0001	CONTAINERID=container_1585211653206_0001_02_000001
2020-03-26 16:34:45,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211653206_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:34945, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:34:45,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211653206_0001_000002 container=Container: [ContainerId: container_1585211653206_0001_02_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:34:45,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:34:45,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:34:45,811 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:34945 for container : container_1585211653206_0001_02_000001
2020-03-26 16:34:45,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:34:45,811 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211653206_0001_000002
2020-03-26 16:34:45,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211653206_0001 AttemptId: appattempt_1585211653206_0001_000002 MasterContainer: Container: [ContainerId: container_1585211653206_0001_02_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ]
2020-03-26 16:34:45,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:34:45,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:34:45,812 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211653206_0001_000002
2020-03-26 16:34:45,813 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211653206_0001_02_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] for AM appattempt_1585211653206_0001_000002
2020-03-26 16:34:45,813 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211653206_0001_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:34:45,813 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211653206_0001_000002
2020-03-26 16:34:45,813 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211653206_0001_000002
2020-03-26 16:34:45,820 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211653206_0001_02_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] for AM appattempt_1585211653206_0001_000002
2020-03-26 16:34:45,820 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:34:46,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211653206_0001_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211653206_0001_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211653206_0001	CONTAINERID=container_1585211653206_0001_02_000001
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211653206_0001_02_000001 of capacity <memory:2048, vCores:1> on host dell:34945, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211653206_0001_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211653206_0001_02_000001, NodeId: dell:34945, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:34945 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:34:47,950 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211653206_0001_000002 released container container_1585211653206_0001_02_000001 on node: host: dell:34945 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211653206_0001_000002
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211653206_0001_000002
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211653206_0001_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:34:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585211653206_0001 with final state: FAILED
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211653206_0001 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211653206_0001_000002 is done. finalState=FAILED
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211653206_0001 requests cleared
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585211653206_0001
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211653206_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:34:47,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585211653206_0001 failed 2 times due to AM Container for appattempt_1585211653206_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211653206_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:34:47,953 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211653206_0001 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:34:47,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585211653206_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:34:47,953 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585211653206_0001 failed 2 times due to AM Container for appattempt_1585211653206_0001_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211653206_0001Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585211653206_0001
2020-03-26 16:34:47,954 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585211653206_0001,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585211653206_0001,appMasterHost=N/A,startTime=1585211681497,finishTime=1585211687952,finalStatus=FAILED,memorySeconds=10372,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:35:21,126 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 16:35:21,128 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:35:21,129 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:35:21,229 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 16:35:21,232 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 16:35:21,232 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 16:35:21,233 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:35:21,233 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 16:35:21,234 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 16:35:21,234 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 16:35:21,238 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 16:35:21,239 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:35:21,241 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 16:35:21,241 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 16:35:21,242 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:35:21,246 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 16:35:21,257 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 16:35:21,257 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:35:21,257 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 16:35:21,258 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:35:21,259 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 16:35:21,259 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:35:21,259 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:35:21,259 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:35:21,260 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 16:35:21,262 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 16:35:21,262 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 16:35:21,263 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:35:21,263 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 16:35:21,263 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:35:57,447 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:35:57,452 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:35:57,615 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:35:57,671 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:35:57,701 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:35:57,833 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:35:57,960 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:35:57,965 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:35:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:35:57,988 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:35:57,989 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:35:57,989 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:35:57,997 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:35:57,997 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:35:57,998 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:35:57,998 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:35:58,029 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:35:58,061 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:35:58,061 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:35:58,068 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:35:58,072 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:35:58,073 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:35:58,074 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:35:58,074 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:35:58,075 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:35:58,101 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:35:58,102 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:35:58,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:35:58,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:35:58,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:35:58,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:35:58,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:35:58,116 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:35:58,116 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:35:58,123 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:35:58,123 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:35:58,123 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:35:58,123 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:35:58,124 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:35:58,124 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:35:58,124 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:35:58,124 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:35:58,124 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:35:58,124 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:35:58,125 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:35:58,203 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:35:58,214 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:35:58,345 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:35:58,345 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:35:58,345 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:35:58,422 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:35:58,426 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:35:58,434 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:35:58,434 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:35:58,436 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:35:58,536 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:35:58,537 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:35:58,541 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:35:58,541 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:35:58,541 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:35:58,561 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:35:58,667 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:35:58,673 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:35:58,680 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:35:58,686 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:35:58,688 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:35:58,688 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:35:58,688 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:35:58,689 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:35:58,689 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:35:58,689 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:35:58,691 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:35:58,692 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:35:58,890 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:35:58,891 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:35:58,891 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:35:58,905 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:35:59,026 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:35:59,027 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:35:59,027 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:35:59,669 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:35:59,669 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:35:59,743 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:35:59,743 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:35:59,746 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:35:59,747 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:35:59,747 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:36:00,647 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:36:00,648 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 33795 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:33795
2020-03-26 16:36:00,651 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:33795 Node Transitioned from NEW to RUNNING
2020-03-26 16:36:00,653 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:33795 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:36:13,331 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:36:27,972 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 16:36:29,760 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 16:36:29,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585211758117_0002
2020-03-26 16:36:29,761 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585211758117_0002
2020-03-26 16:36:29,764 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211758117_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:36:29,764 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585211758117_0002
2020-03-26 16:36:29,764 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211758117_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:36:29,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585211758117_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:36:29,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585211758117_0002 from user: xidian, in queue: default
2020-03-26 16:36:29,771 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211758117_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:36:29,793 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211758117_0002_000001
2020-03-26 16:36:29,794 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from NEW to SUBMITTED
2020-03-26 16:36:29,802 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:36:29,802 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:36:29,802 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211758117_0002 from user: xidian activated in queue: default
2020-03-26 16:36:29,802 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211758117_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@63c37683, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:36:29,802 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211758117_0002_000001 to scheduler from user xidian in queue default
2020-03-26 16:36:29,805 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:36:30,791 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:36:30,792 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211758117_0002	CONTAINERID=container_1585211758117_0002_01_000001
2020-03-26 16:36:30,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211758117_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:33795, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:36:30,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211758117_0002_000001 container=Container: [ContainerId: container_1585211758117_0002_01_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:36:30,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:36:30,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:36:30,801 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33795 for container : container_1585211758117_0002_01_000001
2020-03-26 16:36:30,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:36:30,807 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211758117_0002_000001
2020-03-26 16:36:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211758117_0002 AttemptId: appattempt_1585211758117_0002_000001 MasterContainer: Container: [ContainerId: container_1585211758117_0002_01_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ]
2020-03-26 16:36:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:36:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:36:30,817 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211758117_0002_000001
2020-03-26 16:36:30,835 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211758117_0002_01_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] for AM appattempt_1585211758117_0002_000001
2020-03-26 16:36:30,835 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211758117_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:36:30,875 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211758117_0002_000001
2020-03-26 16:36:30,877 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211758117_0002_000001
2020-03-26 16:36:31,034 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211758117_0002_01_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] for AM appattempt_1585211758117_0002_000001
2020-03-26 16:36:31,035 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:36:31,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:36:33,618 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:36:33,618 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211758117_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211758117_0002	CONTAINERID=container_1585211758117_0002_01_000001
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211758117_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:33795, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211758117_0002_01_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211758117_0002_000001 released container container_1585211758117_0002_01_000001 on node: host: dell:33795 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:36:33,619 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211758117_0002_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:36:33,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:36:33,620 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211758117_0002_000001
2020-03-26 16:36:33,620 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211758117_0002_000001
2020-03-26 16:36:33,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:36:33,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585211758117_0002_000002
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from NEW to SUBMITTED
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211758117_0002_000001 is done. finalState=FAILED
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211758117_0002 requests cleared
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211758117_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:36:33,621 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:36:33,621 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585211758117_0002 from user: xidian activated in queue: default
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585211758117_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7f9c9c32, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:36:33,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585211758117_0002_000002 to scheduler from user xidian in queue default
2020-03-26 16:36:33,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:36:34,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:36:34,622 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211758117_0002	CONTAINERID=container_1585211758117_0002_02_000001
2020-03-26 16:36:34,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585211758117_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:33795, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:36:34,623 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585211758117_0002_000002 container=Container: [ContainerId: container_1585211758117_0002_02_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:36:34,623 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:36:34,623 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:36:34,625 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33795 for container : container_1585211758117_0002_02_000001
2020-03-26 16:36:34,625 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:36:34,626 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585211758117_0002_000002
2020-03-26 16:36:34,626 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585211758117_0002 AttemptId: appattempt_1585211758117_0002_000002 MasterContainer: Container: [ContainerId: container_1585211758117_0002_02_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ]
2020-03-26 16:36:34,626 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:36:34,626 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:36:34,626 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585211758117_0002_000002
2020-03-26 16:36:34,627 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585211758117_0002_02_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] for AM appattempt_1585211758117_0002_000002
2020-03-26 16:36:34,627 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585211758117_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:36:34,627 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585211758117_0002_000002
2020-03-26 16:36:34,627 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585211758117_0002_000002
2020-03-26 16:36:34,634 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585211758117_0002_02_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] for AM appattempt_1585211758117_0002_000002
2020-03-26 16:36:34,634 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:36:35,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585211758117_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585211758117_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585211758117_0002	CONTAINERID=container_1585211758117_0002_02_000001
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585211758117_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:33795, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585211758117_0002_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:36:36,789 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585211758117_0002_02_000001, NodeId: dell:33795, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33795 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585211758117_0002_000002
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585211758117_0002_000002
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585211758117_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:36:36,790 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:36:36,791 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585211758117_0002_000002 released container container_1585211758117_0002_02_000001 on node: host: dell:33795 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:36:36,791 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585211758117_0002 with final state: FAILED
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211758117_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585211758117_0002
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585211758117_0002_000002 is done. finalState=FAILED
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585211758117_0002 requests cleared
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585211758117_0002 failed 2 times due to AM Container for appattempt_1585211758117_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211758117_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:36:36,792 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585211758117_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:36:36,794 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585211758117_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:36:36,794 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585211758117_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:36:36,794 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585211758117_0002 failed 2 times due to AM Container for appattempt_1585211758117_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585211758117_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585211758117_0002
2020-03-26 16:36:36,796 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585211758117_0002,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585211758117_0002,appMasterHost=N/A,startTime=1585211789759,finishTime=1585211796791,finalStatus=FAILED,memorySeconds=10227,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:41:32,485 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 16:41:32,487 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:41:32,487 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:41:32,588 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 16:41:32,590 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 16:41:32,591 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 16:41:32,592 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:41:32,593 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 16:41:32,593 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 16:41:32,594 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 16:41:32,598 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 16:41:32,598 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:41:32,600 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 16:41:32,600 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 16:41:32,600 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:41:32,602 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 16:41:32,602 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 16:41:32,603 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:41:32,603 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 16:41:32,606 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 16:41:32,607 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:41:32,606 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 16:41:32,603 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 16:41:32,603 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 16:41:32,612 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 16:41:32,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 16:41:32,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 16:41:32,614 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 16:41:32,615 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 16:41:32,615 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 16:42:05,309 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 16:42:05,314 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 16:42:05,465 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 16:42:05,535 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 16:42:05,573 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 16:42:05,689 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 16:42:05,797 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 16:42:05,799 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 16:42:05,804 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 16:42:05,828 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 16:42:05,829 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 16:42:05,830 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 16:42:05,841 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 16:42:05,841 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 16:42:05,841 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 16:42:05,842 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 16:42:05,879 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 16:42:05,926 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 16:42:05,926 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 16:42:05,934 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 16:42:05,940 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 16:42:05,941 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 16:42:05,942 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 16:42:05,942 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 16:42:05,943 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 16:42:05,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 16:42:05,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 16:42:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 16:42:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 16:42:05,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 16:42:05,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 16:42:05,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 16:42:05,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:42:05,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:42:05,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 16:42:05,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 16:42:05,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 16:42:05,994 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 16:42:05,994 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 16:42:06,001 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 16:42:06,001 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 16:42:06,001 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 16:42:06,001 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:42:06,002 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 16:42:06,002 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:42:06,003 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:42:06,003 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:42:06,003 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 16:42:06,003 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 16:42:06,004 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 16:42:06,096 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:42:06,125 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 16:42:06,275 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 16:42:06,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:42:06,276 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 16:42:06,357 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:42:06,370 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 16:42:06,391 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 16:42:06,391 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:42:06,391 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 16:42:06,526 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 16:42:06,527 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 16:42:06,530 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 16:42:06,530 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:42:06,530 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 16:42:06,543 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 16:42:06,659 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 16:42:06,664 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 16:42:06,669 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 16:42:06,676 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 16:42:06,678 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 16:42:06,678 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 16:42:06,678 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 16:42:06,678 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 16:42:06,678 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 16:42:06,679 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 16:42:06,681 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 16:42:06,681 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 16:42:06,868 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 16:42:06,869 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 16:42:06,870 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 16:42:06,888 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 16:42:07,007 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:42:07,007 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 16:42:07,007 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 16:42:07,664 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 16:42:07,664 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 16:42:07,737 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 16:42:07,738 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 16:42:07,741 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 16:42:07,741 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 16:42:07,741 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 16:42:08,717 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 16:42:08,719 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 35183 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:35183
2020-03-26 16:42:08,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:35183 Node Transitioned from NEW to RUNNING
2020-03-26 16:42:08,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:35183 clusterResource: <memory:8192, vCores:8>
2020-03-26 16:42:15,252 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 16:42:34,396 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 16:42:36,270 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 16:42:36,270 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585212125995_0002
2020-03-26 16:42:36,270 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585212125995_0002
2020-03-26 16:42:36,282 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585212125995_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 16:42:36,282 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585212125995_0002
2020-03-26 16:42:36,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585212125995_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 16:42:36,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585212125995_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 16:42:36,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585212125995_0002 from user: xidian, in queue: default
2020-03-26 16:42:36,295 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585212125995_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 16:42:36,311 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585212125995_0002_000001
2020-03-26 16:42:36,311 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from NEW to SUBMITTED
2020-03-26 16:42:36,317 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:42:36,317 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:42:36,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585212125995_0002 from user: xidian activated in queue: default
2020-03-26 16:42:36,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585212125995_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@ed4e666, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:42:36,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585212125995_0002_000001 to scheduler from user xidian in queue default
2020-03-26 16:42:36,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 16:42:36,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:42:36,848 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585212125995_0002	CONTAINERID=container_1585212125995_0002_01_000001
2020-03-26 16:42:36,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585212125995_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:35183, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:42:36,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585212125995_0002_000001 container=Container: [ContainerId: container_1585212125995_0002_01_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:42:36,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:42:36,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:42:36,858 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:35183 for container : container_1585212125995_0002_01_000001
2020-03-26 16:42:36,863 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:42:36,863 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585212125995_0002_000001
2020-03-26 16:42:36,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585212125995_0002 AttemptId: appattempt_1585212125995_0002_000001 MasterContainer: Container: [ContainerId: container_1585212125995_0002_01_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ]
2020-03-26 16:42:36,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:42:36,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:42:36,872 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585212125995_0002_000001
2020-03-26 16:42:36,889 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585212125995_0002_01_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] for AM appattempt_1585212125995_0002_000001
2020-03-26 16:42:36,889 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585212125995_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:42:36,890 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585212125995_0002_000001
2020-03-26 16:42:36,892 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585212125995_0002_000001
2020-03-26 16:42:37,099 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585212125995_0002_01_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] for AM appattempt_1585212125995_0002_000001
2020-03-26 16:42:37,099 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 16:42:37,859 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:42:39,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585212125995_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585212125995_0002	CONTAINERID=container_1585212125995_0002_01_000001
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585212125995_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:35183, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585212125995_0002_01_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:42:39,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:42:39,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585212125995_0002_000001 released container container_1585212125995_0002_01_000001 on node: host: dell:35183 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:42:39,730 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585212125995_0002_000001 with final state: FAILED, and exit status: -1
2020-03-26 16:42:39,731 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:42:39,731 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585212125995_0002_000001
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585212125995_0002_000001
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585212125995_0002_000002
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585212125995_0002_000001 is done. finalState=FAILED
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from NEW to SUBMITTED
2020-03-26 16:42:39,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585212125995_0002 requests cleared
2020-03-26 16:42:39,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585212125995_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:42:39,733 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:42:39,733 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 16:42:39,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585212125995_0002 from user: xidian activated in queue: default
2020-03-26 16:42:39,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585212125995_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@13d0cd7d, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 16:42:39,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585212125995_0002_000002 to scheduler from user xidian in queue default
2020-03-26 16:42:39,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 16:42:40,731 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 16:42:40,731 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585212125995_0002	CONTAINERID=container_1585212125995_0002_02_000001
2020-03-26 16:42:40,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585212125995_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:35183, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 16:42:40,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585212125995_0002_000002 container=Container: [ContainerId: container_1585212125995_0002_02_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 16:42:40,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 16:42:40,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 16:42:40,735 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:35183 for container : container_1585212125995_0002_02_000001
2020-03-26 16:42:40,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 16:42:40,736 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585212125995_0002_000002
2020-03-26 16:42:40,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585212125995_0002 AttemptId: appattempt_1585212125995_0002_000002 MasterContainer: Container: [ContainerId: container_1585212125995_0002_02_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ]
2020-03-26 16:42:40,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 16:42:40,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 16:42:40,737 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585212125995_0002_000002
2020-03-26 16:42:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585212125995_0002_02_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] for AM appattempt_1585212125995_0002_000002
2020-03-26 16:42:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585212125995_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 16:42:40,739 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585212125995_0002_000002
2020-03-26 16:42:40,739 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585212125995_0002_000002
2020-03-26 16:42:40,747 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585212125995_0002_02_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] for AM appattempt_1585212125995_0002_000002
2020-03-26 16:42:40,747 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 16:42:41,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585212125995_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585212125995_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585212125995_0002	CONTAINERID=container_1585212125995_0002_02_000001
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585212125995_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:35183, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585212125995_0002_000002 with final state: FAILED, and exit status: -1
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585212125995_0002_02_000001, NodeId: dell:35183, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:35183 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585212125995_0002_000002
2020-03-26 16:42:42,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585212125995_0002_000002 released container container_1585212125995_0002_02_000001 on node: host: dell:35183 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585212125995_0002_000002
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585212125995_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 16:42:42,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585212125995_0002 with final state: FAILED
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585212125995_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585212125995_0002_000002 is done. finalState=FAILED
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585212125995_0002
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585212125995_0002 requests cleared
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585212125995_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585212125995_0002 failed 2 times due to AM Container for appattempt_1585212125995_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585212125995_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 16:42:42,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585212125995_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 16:42:42,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585212125995_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 16:42:42,876 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585212125995_0002 failed 2 times due to AM Container for appattempt_1585212125995_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585212125995_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585212125995_0002
2020-03-26 16:42:42,877 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585212125995_0002,name=Base.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585212125995_0002,appMasterHost=N/A,startTime=1585212156269,finishTime=1585212162874,finalStatus=FAILED,memorySeconds=10288,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 16:52:05,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-26 17:07:24,908 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 17:07:24,909 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 17:07:24,910 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 17:07:25,011 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 17:07:25,012 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 17:07:25,013 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 17:07:25,013 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 17:07:25,015 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 17:07:25,016 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 17:07:25,016 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 17:07:25,016 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 17:07:25,018 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 17:07:25,024 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 17:07:25,024 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 17:07:25,024 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 17:07:25,026 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 17:07:25,027 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 17:07:25,028 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 17:07:25,028 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 17:07:25,030 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 17:07:25,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 17:07:25,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 17:07:25,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 17:07:25,031 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 17:07:25,032 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 17:07:25,035 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 17:07:25,035 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 17:07:25,035 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 17:07:25,036 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 17:07:25,036 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-26 18:37:47,216 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/usr/local/java/jdk1.8.0_131/lib/tools.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-26 18:37:47,281 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-26 18:37:47,452 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-26 18:37:47,510 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-26 18:37:47,607 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-26 18:37:47,742 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-26 18:37:47,935 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-26 18:37:47,951 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-26 18:37:47,956 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-26 18:37:47,998 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-26 18:37:48,011 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-26 18:37:48,011 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-26 18:37:48,034 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-26 18:37:48,034 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-26 18:37:48,035 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-26 18:37:48,036 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-26 18:37:48,084 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-26 18:37:48,134 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-26 18:37:48,134 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-26 18:37:48,143 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-26 18:37:48,152 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-26 18:37:48,156 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-26 18:37:48,158 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-26 18:37:48,159 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-26 18:37:48,160 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-26 18:37:48,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-26 18:37:48,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-26 18:37:48,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-03-26 18:37:48,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-26 18:37:48,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-26 18:37:48,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-26 18:37:48,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-26 18:37:48,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 18:37:48,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 18:37:48,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-26 18:37:48,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-26 18:37:48,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-26 18:37:48,219 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-26 18:37:48,219 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-26 18:37:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-26 18:37:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-26 18:37:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-26 18:37:48,248 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 18:37:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-26 18:37:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 18:37:48,249 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 18:37:48,249 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 18:37:48,249 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-26 18:37:48,249 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-26 18:37:48,251 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-26 18:37:48,344 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 18:37:48,359 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-26 18:37:48,509 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-26 18:37:48,509 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 18:37:48,509 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-26 18:37:48,584 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 18:37:48,589 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-26 18:37:48,597 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-26 18:37:48,597 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 18:37:48,597 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-26 18:37:48,718 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-26 18:37:48,719 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-26 18:37:48,725 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-26 18:37:48,725 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 18:37:48,726 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-26 18:37:48,780 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-26 18:37:48,879 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-26 18:37:48,885 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-26 18:37:48,892 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-26 18:37:48,899 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-26 18:37:48,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-26 18:37:48,903 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-26 18:37:48,904 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-26 18:37:49,351 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-26 18:37:49,352 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-26 18:37:49,352 INFO org.mortbay.log: jetty-6.1.26
2020-03-26 18:37:49,372 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-26 18:37:49,510 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 18:37:49,511 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-26 18:37:49,511 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-26 18:37:50,960 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 18:37:50,961 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-26 18:37:51,055 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-26 18:37:51,056 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-26 18:37:51,059 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-26 18:37:51,059 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-26 18:37:51,061 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-26 18:37:51,538 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-26 18:37:51,539 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 40919 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:40919
2020-03-26 18:37:51,542 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:40919 Node Transitioned from NEW to RUNNING
2020-03-26 18:37:51,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:40919 clusterResource: <memory:8192, vCores:8>
2020-03-26 18:38:46,398 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-26 18:38:49,159 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-26 18:38:49,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585219068220_0001
2020-03-26 18:38:49,160 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585219068220_0001
2020-03-26 18:38:49,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from NEW to NEW_SAVING on event=START
2020-03-26 18:38:49,195 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585219068220_0001
2020-03-26 18:38:49,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 18:38:49,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585219068220_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 18:38:49,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585219068220_0001 from user: xidian, in queue: default
2020-03-26 18:38:49,202 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 18:38:49,217 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0001_000001
2020-03-26 18:38:49,217 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from NEW to SUBMITTED
2020-03-26 18:38:49,224 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:38:49,224 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:38:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0001 from user: xidian activated in queue: default
2020-03-26 18:38:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@389c230b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 18:38:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0001_000001 to scheduler from user xidian in queue default
2020-03-26 18:38:49,227 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 18:38:49,755 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 18:38:49,755 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000001
2020-03-26 18:38:49,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 18:38:49,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0001_000001 container=Container: [ContainerId: container_1585219068220_0001_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 18:38:49,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 18:38:49,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 18:38:49,766 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0001_01_000001
2020-03-26 18:38:49,772 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 18:38:49,772 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0001_000001
2020-03-26 18:38:49,774 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0001 AttemptId: appattempt_1585219068220_0001_000001 MasterContainer: Container: [ContainerId: container_1585219068220_0001_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 18:38:49,782 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 18:38:49,782 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 18:38:49,784 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0001_000001
2020-03-26 18:38:49,848 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0001_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0001_000001
2020-03-26 18:38:49,848 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 18:38:49,849 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0001_000001
2020-03-26 18:38:49,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0001_000001
2020-03-26 18:38:50,080 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0001_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0001_000001
2020-03-26 18:38:50,080 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 18:38:50,765 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 18:39:03,776 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585219068220_0001_000001 (auth:SIMPLE)
2020-03-26 18:39:03,780 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585219068220_0001_000001
2020-03-26 18:39:03,781 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585219068220_0001	APPATTEMPTID=appattempt_1585219068220_0001_000001
2020-03-26 18:39:03,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from LAUNCHED to RUNNING
2020-03-26 18:39:03,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-26 18:39:05,799 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-26 18:39:05,800 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000002
2020-03-26 18:39:05,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 18:39:05,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0001_000001 container=Container: [ContainerId: container_1585219068220_0001_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 18:39:05,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 18:39:05,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 18:39:05,977 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0001_01_000002
2020-03-26 18:39:05,980 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 18:39:06,799 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 18:39:07,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0001
2020-03-26 18:39:11,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-26 18:39:11,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0001_01_000002 in state: COMPLETED event:FINISHED
2020-03-26 18:39:11,544 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000002
2020-03-26 18:39:11,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 18:39:11,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 18:39:11,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0001_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 18:39:11,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 18:39:11,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 18:39:11,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0001_000001 released container container_1585219068220_0001_01_000002 on node: host: dell:40919 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-26 18:39:11,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-26 18:39:11,546 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000003
2020-03-26 18:39:11,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 18:39:11,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0001_000001 container=Container: [ContainerId: container_1585219068220_0001_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 18:39:11,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 18:39:11,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 18:39:12,036 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 18:39:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 18:39:13,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0001
2020-03-26 18:39:19,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0001_000001 with final state: FINISHING, and exit status: -1000
2020-03-26 18:39:19,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from RUNNING to FINAL_SAVING
2020-03-26 18:39:19,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585219068220_0001 with final state: FINISHING
2020-03-26 18:39:19,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-26 18:39:19,972 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585219068220_0001
2020-03-26 18:39:19,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from FINAL_SAVING to FINISHING
2020-03-26 18:39:19,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0001_01_000003 in state: COMPLETED event:FINISHED
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000003
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0001_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 18:39:20,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0001_000001 released container container_1585219068220_0001_01_000003 on node: host: dell:40919 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-26 18:39:20,975 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585219068220_0001 unregistered successfully. 
2020-03-26 18:39:29,777 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 18:39:29,777 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0001_000001
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0001	CONTAINERID=container_1585219068220_0001_01_000001
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0001_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0001_000001 released container container_1585219068220_0001_01_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0001_000001
2020-03-26 18:39:29,778 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0001_000001 State change from FINISHING to FINISHED
2020-03-26 18:39:29,779 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-26 18:39:29,780 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0001_000001 is done. finalState=FINISHED
2020-03-26 18:39:29,780 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0001 requests cleared
2020-03-26 18:39:29,780 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585219068220_0001_000001
2020-03-26 18:39:29,781 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 18:39:29,781 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585219068220_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 18:39:29,781 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585219068220_0001
2020-03-26 18:39:29,782 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585219068220_0001,name=word count,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585219068220_0001/,appMasterHost=dell,startTime=1585219129159,finishTime=1585219159972,finalStatus=SUCCEEDED,memorySeconds=96574,vcoreSeconds=53,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 18:39:31,785 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 18:47:48,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-26 18:57:24,537 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-26 18:57:25,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-26 18:57:25,329 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585219068220_0002
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585219068220_0002
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0002 State change from NEW to NEW_SAVING on event=START
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585219068220_0002
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585219068220_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 18:57:25,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585219068220_0002 from user: xidian, in queue: default
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from NEW to SUBMITTED
2020-03-26 18:57:25,331 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:57:25,331 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0002 from user: xidian activated in queue: default
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@5ea540ac, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 18:57:25,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0002_000001 to scheduler from user xidian in queue default
2020-03-26 18:57:25,332 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0002	CONTAINERID=container_1585219068220_0002_01_000001
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0002_000001 container=Container: [ContainerId: container_1585219068220_0002_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 18:57:25,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 18:57:25,610 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0002_01_000001
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0002 AttemptId: appattempt_1585219068220_0002_000001 MasterContainer: Container: [ContainerId: container_1585219068220_0002_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 18:57:25,612 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0002_000001
2020-03-26 18:57:25,614 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0002_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,614 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 18:57:25,614 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,614 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,622 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0002_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0002_000001
2020-03-26 18:57:25,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 18:57:26,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 18:57:27,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0002	CONTAINERID=container_1585219068220_0002_01_000001
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0002_000001 with final state: FAILED, and exit status: -1
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0002_000001
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0002_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0002_000001
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000001 State change from FINAL_SAVING to FAILED
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0002_000001 released container container_1585219068220_0002_01_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 18:57:27,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0002_000002
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0002_000001 is done. finalState=FAILED
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from NEW to SUBMITTED
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0002 requests cleared
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 18:57:27,831 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:57:27,831 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0002 from user: xidian activated in queue: default
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@77b9311c, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0002_000002 to scheduler from user xidian in queue default
2020-03-26 18:57:27,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 18:57:28,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 18:57:28,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0002	CONTAINERID=container_1585219068220_0002_02_000001
2020-03-26 18:57:28,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 18:57:28,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0002_000002 container=Container: [ContainerId: container_1585219068220_0002_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 18:57:28,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 18:57:28,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 18:57:28,835 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0002_02_000001
2020-03-26 18:57:28,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 18:57:28,838 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0002_000002
2020-03-26 18:57:28,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0002 AttemptId: appattempt_1585219068220_0002_000002 MasterContainer: Container: [ContainerId: container_1585219068220_0002_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 18:57:28,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 18:57:28,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 18:57:28,839 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0002_000002
2020-03-26 18:57:28,848 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0002_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0002_000002
2020-03-26 18:57:28,848 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0002_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 18:57:28,848 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0002_000002
2020-03-26 18:57:28,848 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0002_000002
2020-03-26 18:57:28,867 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0002_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0002_000002
2020-03-26 18:57:28,867 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 18:57:29,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 18:57:31,024 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0002_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0002_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0002	CONTAINERID=container_1585219068220_0002_02_000001
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0002_02_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0002_000002 with final state: FAILED, and exit status: -1
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0002_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0002_000002
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0002_000002
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0002_000002 State change from FINAL_SAVING to FAILED
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 18:57:31,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0002_000002 released container container_1585219068220_0002_02_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585219068220_0002 with final state: FAILED
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0002 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585219068220_0002
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0002_000002 is done. finalState=FAILED
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585219068220_0002 failed 2 times due to AM Container for appattempt_1585219068220_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585219068220_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0002 requests cleared
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0002 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585219068220_0002 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 18:57:31,026 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585219068220_0002 failed 2 times due to AM Container for appattempt_1585219068220_0002_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585219068220_0002Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585219068220_0002
2020-03-26 18:57:31,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585219068220_0002,name=wc.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585219068220_0002,appMasterHost=N/A,startTime=1585220245329,finishTime=1585220251026,finalStatus=FAILED,memorySeconds=9037,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 19:00:56,779 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user xidian
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585219068220_0003
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0003 State change from NEW to NEW_SAVING on event=START
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585219068220_0003
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585219068220_0003
2020-03-26 19:00:57,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585219068220_0003 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585219068220_0003 from user: xidian, in queue: default
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0003_000001
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from NEW to SUBMITTED
2020-03-26 19:00:57,530 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:00:57,530 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0003 from user: xidian activated in queue: default
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@8eee2cb, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 19:00:57,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0003_000001 to scheduler from user xidian in queue default
2020-03-26 19:00:57,531 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 19:00:58,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:00:58,320 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0003	CONTAINERID=container_1585219068220_0003_01_000001
2020-03-26 19:00:58,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 19:00:58,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0003_000001 container=Container: [ContainerId: container_1585219068220_0003_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:00:58,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 19:00:58,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:00:58,323 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0003_01_000001
2020-03-26 19:00:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:00:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0003_000001
2020-03-26 19:00:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0003 AttemptId: appattempt_1585219068220_0003_000001 MasterContainer: Container: [ContainerId: container_1585219068220_0003_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 19:00:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 19:00:58,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 19:00:58,329 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0003_000001
2020-03-26 19:00:58,332 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0003_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0003_000001
2020-03-26 19:00:58,332 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0003_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 19:00:58,333 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0003_000001
2020-03-26 19:00:58,333 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0003_000001
2020-03-26 19:00:58,339 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0003_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0003_000001
2020-03-26 19:00:58,339 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 19:00:59,322 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0003_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0003	CONTAINERID=container_1585219068220_0003_01_000001
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0003_000001 with final state: FAILED, and exit status: -1
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from LAUNCHED to FINAL_SAVING
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0003_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0003_000001
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 19:01:00,527 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0003_000001
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0003_000001 released container container_1585219068220_0003_01_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000001 State change from FINAL_SAVING to FAILED
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0003_000001 is done. finalState=FAILED
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0003_000002
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0003 requests cleared
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from NEW to SUBMITTED
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 19:01:00,528 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:01:00,528 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0003 from user: xidian activated in queue: default
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@49d4d721, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0003_000002 to scheduler from user xidian in queue default
2020-03-26 19:01:00,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from SUBMITTED to SCHEDULED
2020-03-26 19:01:01,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_02_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:01:01,529 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0003	CONTAINERID=container_1585219068220_0003_02_000001
2020-03-26 19:01:01,529 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0003_02_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 19:01:01,529 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0003_000002 container=Container: [ContainerId: container_1585219068220_0003_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:01:01,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 19:01:01,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:01:01,531 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0003_02_000001
2020-03-26 19:01:01,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:01:01,534 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0003_000002
2020-03-26 19:01:01,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0003 AttemptId: appattempt_1585219068220_0003_000002 MasterContainer: Container: [ContainerId: container_1585219068220_0003_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 19:01:01,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 19:01:01,535 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 19:01:01,536 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0003_000002
2020-03-26 19:01:01,538 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0003_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0003_000002
2020-03-26 19:01:01,538 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0003_02_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 19:01:01,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0003_000002
2020-03-26 19:01:01,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0003_000002
2020-03-26 19:01:01,546 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0003_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0003_000002
2020-03-26 19:01:01,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from ALLOCATED to LAUNCHED
2020-03-26 19:01:02,531 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_02_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:01:03,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0003_02_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0003_02_000001 in state: COMPLETED event:FINISHED
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0003	CONTAINERID=container_1585219068220_0003_02_000001
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0003_02_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0003_000002 with final state: FAILED, and exit status: -1
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0003_02_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from LAUNCHED to FINAL_SAVING
2020-03-26 19:01:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0003_000002
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0003_000002
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0003_000002 released container container_1585219068220_0003_02_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0003_000002 State change from FINAL_SAVING to FAILED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585219068220_0003 with final state: FAILED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0003 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585219068220_0003
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0003_000002 is done. finalState=FAILED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1585219068220_0003 failed 2 times due to AM Container for appattempt_1585219068220_0003_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585219068220_0003Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0003 requests cleared
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0003 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585219068220_0003 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 19:01:03,688 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1585219068220_0003 failed 2 times due to AM Container for appattempt_1585219068220_0003_000002 exited with  exitCode: -1
For more detailed output, check application tracking page:http://dell:8088/cluster/app/application_1585219068220_0003Then, click on links to logs of each attempt.
Diagnostics: Container image must not be null
Failing this attempt. Failing the application.	APPID=application_1585219068220_0003
2020-03-26 19:01:03,688 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585219068220_0003,name=wc.jar,user=xidian,queue=default,state=FAILED,trackingUrl=http://dell:8088/cluster/app/application_1585219068220_0003,appMasterHost=N/A,startTime=1585220457528,finishTime=1585220463688,finalStatus=FAILED,memorySeconds=8938,vcoreSeconds=4,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 19:05:43,258 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user xidian
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585219068220_0004
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585219068220_0004
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from NEW to NEW_SAVING on event=START
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585219068220_0004
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585219068220_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 19:05:44,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585219068220_0004 from user: xidian, in queue: default
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from NEW to SUBMITTED
2020-03-26 19:05:44,008 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:05:44,008 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0004 from user: xidian activated in queue: default
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@3d005e97, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0004_000001 to scheduler from user xidian in queue default
2020-03-26 19:05:44,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 19:05:44,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:44,032 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000001
2020-03-26 19:05:44,032 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 19:05:44,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:05:44,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 19:05:44,033 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:44,038 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0004_01_000001
2020-03-26 19:05:44,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:44,039 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0004 AttemptId: appattempt_1585219068220_0004_000001 MasterContainer: Container: [ContainerId: container_1585219068220_0004_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 19:05:44,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 19:05:44,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 19:05:44,040 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0004_000001
2020-03-26 19:05:44,041 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0004_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,041 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0004_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 19:05:44,041 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,041 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,054 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0004_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0004_000001
2020-03-26 19:05:44,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 19:05:45,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:47,908 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585219068220_0004_000001 (auth:SIMPLE)
2020-03-26 19:05:47,910 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585219068220_0004_000001
2020-03-26 19:05:47,910 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585219068220_0004	APPATTEMPTID=appattempt_1585219068220_0004_000001
2020-03-26 19:05:47,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from LAUNCHED to RUNNING
2020-03-26 19:05:47,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-26 19:05:49,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,039 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000002
2020-03-26 19:05:49,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 19:05:49,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 19:05:49,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000003
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:05:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000004
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000004 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000004, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:05:49,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,043 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,043 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000005
2020-03-26 19:05:49,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000005 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:05:49,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000005, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000006
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000006 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000006, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:05:49,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000007
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000007 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000007, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:05:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:05:49,996 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0004_01_000002
2020-03-26 19:05:49,998 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:49,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:49,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:50,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:50,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:50,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:05:51,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:51,043 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:51,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:51,046 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:51,046 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:05:51,047 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000007 in state: COMPLETED event:FINISHED
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000007
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000007 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:06:37,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000007, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000007 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000003 in state: COMPLETED event:FINISHED
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000003
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:06:37,953 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000003 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000008
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000008 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000008, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:06:37,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:38,954 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:38,955 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:38,977 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000006 in state: COMPLETED event:FINISHED
2020-03-26 19:06:38,977 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000006
2020-03-26 19:06:38,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000006 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:06:38,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:06:38,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000006, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:06:38,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000006 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:06:38,980 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:38,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000005 in state: COMPLETED event:FINISHED
2020-03-26 19:06:38,980 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000005
2020-03-26 19:06:38,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000005 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:06:38,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:06:38,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000005, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:06:38,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000005 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:06:38,982 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:38,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000004 in state: COMPLETED event:FINISHED
2020-03-26 19:06:38,982 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000004
2020-03-26 19:06:38,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000004 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:06:38,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:06:38,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000004, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:06:38,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000004 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:06:38,984 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:06:38,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000002 in state: COMPLETED event:FINISHED
2020-03-26 19:06:38,984 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000002
2020-03-26 19:06:38,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-26 19:06:38,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-26 19:06:38,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 19:06:38,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000002 on node: host: dell:40919 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-26 19:06:38,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:38,988 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000009
2020-03-26 19:06:38,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000009 of capacity <memory:1024, vCores:1> on host dell:40919, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-26 19:06:38,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000009, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:06:38,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:06:38,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:38,989 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000010
2020-03-26 19:06:38,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000010 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:06:38,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000010, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:06:38,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:06:38,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000011 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000011
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000011 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000011, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:06:38,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000012 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000012
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000012 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000012, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:06:38,992 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000013 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000013
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000013 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000013, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:06:38,993 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:06:39,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:06:39,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:39,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:39,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:39,158 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:39,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:06:39,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:39,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:39,958 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000011 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:39,958 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000012 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:06:39,959 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000013 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000012 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000012 in state: COMPLETED event:FINISHED
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000012
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000012 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000012, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:07:23,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000012 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000014 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000014
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000014 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000014, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:07:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:23,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:07:24,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000014 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:07:25,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000013 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:07:25,299 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000013 in state: COMPLETED event:FINISHED
2020-03-26 19:07:25,299 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000013
2020-03-26 19:07:25,299 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000013 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:07:25,299 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:07:25,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000013, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:07:25,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000013 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:07:25,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000011 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:07:25,301 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000011 in state: COMPLETED event:FINISHED
2020-03-26 19:07:25,301 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000011
2020-03-26 19:07:25,301 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000011 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:07:25,301 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000011, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000011 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000010 in state: COMPLETED event:FINISHED
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000010
2020-03-26 19:07:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000010 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:07:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:07:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000010, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:07:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000010 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000009 in state: COMPLETED event:FINISHED
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000009
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000009 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000009, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:07:25,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000009 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000015 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000015
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000015 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000015, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:07:25,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:25,449 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:07:26,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000015 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:07:26,302 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000016 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:07:26,302 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000016
2020-03-26 19:07:26,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000016 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000016, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000017 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000017
2020-03-26 19:07:26,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000017 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000017, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000018 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000018
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000018 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:07:26,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000018, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:07:26,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:07:26,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:07:26,455 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:07:26,459 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:07:26,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:07:26,462 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:07:27,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000016 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:07:27,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000017 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:07:27,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000018 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:00,193 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000018 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:00,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000018 in state: COMPLETED event:FINISHED
2020-03-26 19:08:00,193 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000018
2020-03-26 19:08:00,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000018 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:08:00,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000018, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000018 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000017 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000017 in state: COMPLETED event:FINISHED
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000017
2020-03-26 19:08:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000017 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000017, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000017 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000019 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000019
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000019 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000019, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:00,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000020 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000020
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000020 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000020, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:08:00,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:00,743 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000019 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:00,745 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000020 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:01,194 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000019 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:01,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000020 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000016 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000016 in state: COMPLETED event:FINISHED
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000016
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000016 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000016, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:01,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000016 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000021 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000021
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000021 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000021, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:08:01,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:01,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000021 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:02,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000021 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:34,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000020 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:34,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000020 in state: COMPLETED event:FINISHED
2020-03-26 19:08:34,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000020
2020-03-26 19:08:34,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000020 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:08:34,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000020, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000020 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000022 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000022
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000022 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000022, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:08:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:34,198 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000022 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:35,115 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000022 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:36,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000019 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:36,251 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000019 in state: COMPLETED event:FINISHED
2020-03-26 19:08:36,251 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000019
2020-03-26 19:08:36,251 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000019 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:08:36,251 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:08:36,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000019, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:36,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:36,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:36,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000019 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:08:36,254 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000023 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:36,254 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000023
2020-03-26 19:08:36,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000023 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:08:36,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000023, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:36,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000021 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000021 in state: COMPLETED event:FINISHED
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000021
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000021 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000021, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000021 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000024 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000024
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000024 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000024, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:08:36,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:08:37,211 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000023 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:37,213 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000024 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:08:37,253 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000023 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:37,253 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000024 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:08:38,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:09:07,264 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:09:13,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000023 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:13,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000023 in state: COMPLETED event:FINISHED
2020-03-26 19:09:13,141 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000023
2020-03-26 19:09:13,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000023 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:09:13,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:09:13,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000023, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:13,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:13,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:09:13,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000023 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:09:13,144 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000022 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:13,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000022 in state: COMPLETED event:FINISHED
2020-03-26 19:09:13,144 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000022
2020-03-26 19:09:13,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000022 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:09:13,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:09:13,145 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000022, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:13,145 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:13,145 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:09:13,146 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000022 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000025 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000025
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000025 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000025, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:09:13,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:13,275 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000025 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:14,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000025 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:14,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000026 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:14,143 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000026
2020-03-26 19:09:14,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000026 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:09:14,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000026, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:14,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:09:14,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:14,335 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000026 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:15,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000026 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000024 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000024 in state: COMPLETED event:FINISHED
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000024
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000024 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000024, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:09:19,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000024 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000027 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000027
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000027 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000027, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:09:19,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000008 in state: COMPLETED event:FINISHED
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000008
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000008 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000008, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000008 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000015 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000015 in state: COMPLETED event:FINISHED
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000015
2020-03-26 19:09:19,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000015 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:09:19,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:09:19,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000015, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:09:19,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000015 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000014 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000014 in state: COMPLETED event:FINISHED
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000014
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000014 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000014, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000014 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000028 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000028
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000028 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000028, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:19,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:09:19,817 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:20,355 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000027 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:20,356 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000028 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:20,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000027 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:20,818 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000028 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:21,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:09:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000029 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000029
2020-03-26 19:09:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0004_01_000029 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:09:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0004_000001 container=Container: [ContainerId: container_1585219068220_0004_01_000029, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:09:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:33,386 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000029 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000029 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:34,388 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0004
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0004_000001 with final state: FINISHING, and exit status: -1000
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from RUNNING to FINAL_SAVING
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585219068220_0004 with final state: FINISHING
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from FINAL_SAVING to FINISHING
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585219068220_0004
2020-03-26 19:09:43,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-26 19:09:44,767 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585219068220_0004 unregistered successfully. 
2020-03-26 19:09:45,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2020-03-26 19:09:46,698 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user xidian
2020-03-26 19:09:46,698 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585219068220_0005
2020-03-26 19:09:46,698 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585219068220_0005
2020-03-26 19:09:46,698 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from NEW to NEW_SAVING on event=START
2020-03-26 19:09:46,698 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585219068220_0005
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585219068220_0005 user: xidian leaf-queue of parent: root #applications: 2
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585219068220_0005 from user: xidian, in queue: default
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585219068220_0005_000001
2020-03-26 19:09:46,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from NEW to SUBMITTED
2020-03-26 19:09:46,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: not starting application as amIfStarted exceeds amLimit
2020-03-26 19:09:46,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585219068220_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@3d005e97, leaf-queue: default #user-pending-applications: 1 #user-active-applications: 1 #queue-pending-applications: 1 #queue-active-applications: 1
2020-03-26 19:09:46,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585219068220_0005_000001 to scheduler from user xidian in queue default
2020-03-26 19:09:46,700 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from SUBMITTED to SCHEDULED
2020-03-26 19:09:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000028 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000028 in state: COMPLETED event:FINISHED
2020-03-26 19:09:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000028
2020-03-26 19:09:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000028 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:09:47,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000028, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=2, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=2, numContainers=5
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000028 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000027 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000027 in state: COMPLETED event:FINISHED
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000027
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000027 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000027, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=2, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=2, numContainers=4
2020-03-26 19:09:47,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000027 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000026 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000026 in state: COMPLETED event:FINISHED
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000026
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000026 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000026, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=2, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=2, numContainers=3
2020-03-26 19:09:47,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000026 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:09:48,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000029 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:48,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000029 in state: COMPLETED event:FINISHED
2020-03-26 19:09:48,414 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000029
2020-03-26 19:09:48,414 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000029 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-26 19:09:48,414 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-26 19:09:48,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000029, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=2, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:48,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:48,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=2, numContainers=2
2020-03-26 19:09:48,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000029 on node: host: dell:40919 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-26 19:09:48,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000025 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:48,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000025 in state: COMPLETED event:FINISHED
2020-03-26 19:09:48,416 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000025
2020-03-26 19:09:48,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000025 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 19:09:48,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 19:09:48,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000025, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=2, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:48,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:48,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=2, numContainers=1
2020-03-26 19:09:48,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000025 on node: host: dell:40919 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-26 19:09:54,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:09:54,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0004_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 19:09:54,864 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0004_000001
2020-03-26 19:09:54,864 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0004	CONTAINERID=container_1585219068220_0004_01_000001
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0004_000001
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0004_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0004_000001 State change from FINISHING to FINISHED
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0004 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0004_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=2, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=2, numContainers=0
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0004_000001 released container container_1585219068220_0004_01_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585219068220_0004
2020-03-26 19:09:54,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0004_000001 is done. finalState=FINISHED
2020-03-26 19:09:54,867 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585219068220_0004,name=job1,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585219068220_0004/,appMasterHost=dell,startTime=1585220744007,finishTime=1585220983760,finalStatus=SUCCEEDED,memorySeconds=1933446,vcoreSeconds=1620,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 19:09:54,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0004 requests cleared
2020-03-26 19:09:54,868 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585219068220_0004_000001
2020-03-26 19:09:54,868 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:09:54,868 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-26 19:09:54,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585219068220_0005 from user: xidian activated in queue: default
2020-03-26 19:09:54,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0004 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-26 19:09:54,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585219068220_0004 user: xidian leaf-queue of parent: root #applications: 1
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000001
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 19:09:55,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:09:55,867 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0005_01_000001
2020-03-26 19:09:55,869 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:09:55,869 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585219068220_0005_000001
2020-03-26 19:09:55,869 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585219068220_0005 AttemptId: appattempt_1585219068220_0005_000001 MasterContainer: Container: [ContainerId: container_1585219068220_0005_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ]
2020-03-26 19:09:55,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-26 19:09:55,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-26 19:09:55,871 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585219068220_0005_000001
2020-03-26 19:09:55,872 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585219068220_0005_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0005_000001
2020-03-26 19:09:55,872 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585219068220_0005_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-26 19:09:55,872 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585219068220_0005_000001
2020-03-26 19:09:55,872 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585219068220_0005_000001
2020-03-26 19:09:55,877 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585219068220_0005_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] for AM appattempt_1585219068220_0005_000001
2020-03-26 19:09:55,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from ALLOCATED to LAUNCHED
2020-03-26 19:09:56,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:09:56,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:09:56,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:09:56,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:09:56,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:09:56,872 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:10:01,180 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585219068220_0005_000001 (auth:SIMPLE)
2020-03-26 19:10:01,182 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585219068220_0005_000001
2020-03-26 19:10:01,182 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585219068220_0005	APPATTEMPTID=appattempt_1585219068220_0005_000001
2020-03-26 19:10:01,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from LAUNCHED to RUNNING
2020-03-26 19:10:01,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000002
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000003
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000004
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000004 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000004, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000005
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000005 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000005, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:10:02,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000006
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000006 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000006, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000007
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000007 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000007, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:02,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:03,257 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:40919 for container : container_1585219068220_0005_01_000002
2020-03-26 19:10:03,259 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,260 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,263 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,265 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,266 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:03,876 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:03,876 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:03,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:03,878 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:03,878 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:03,879 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000003 in state: COMPLETED event:FINISHED
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000003
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000003 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000003, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000003 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000008
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000008 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000008, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:32,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000007 in state: COMPLETED event:FINISHED
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000007
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000007 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000007, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:32,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000007 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000004 in state: COMPLETED event:FINISHED
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000004
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000004 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000004, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000004 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000009
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000009 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000009, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:32,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:32,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:32,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:33,469 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:33,470 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:33,470 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:33,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000002 in state: COMPLETED event:FINISHED
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000002
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000002 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000002, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:10:33,471 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000002 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:10:33,472 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:33,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000006 in state: COMPLETED event:FINISHED
2020-03-26 19:10:33,472 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000006
2020-03-26 19:10:33,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000006 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:10:33,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:10:33,473 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000006, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,473 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,473 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:10:33,473 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000006 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:10:33,474 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:33,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000005 in state: COMPLETED event:FINISHED
2020-03-26 19:10:33,474 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000005
2020-03-26 19:10:33,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000005 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:10:33,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000005, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000005 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000010
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000010 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000010, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:10:33,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:33,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:34,471 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000011 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000011
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000011 of capacity <memory:1024, vCores:1> on host dell:40919, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000011, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:10:34,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:35,316 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:35,473 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000011 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000012 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000012
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000012 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000012, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:35,474 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:36,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:36,475 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000012 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000013 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000013
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000013 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000013, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:36,476 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:37,329 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0005
2020-03-26 19:10:37,332 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:38,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000013 Container Transitioned from ACQUIRED to RELEASED
2020-03-26 19:10:38,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000013 in state: RELEASED event:RELEASED
2020-03-26 19:10:38,673 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000013
2020-03-26 19:10:38,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000013 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:10:38,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:10:38,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000013, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:38,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:38,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:38,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000013 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: RELEASED
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000014 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000014
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000014 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000014, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:38,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:39,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:40,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000014 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:40,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0005
2020-03-26 19:10:49,373 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:49,373 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000008 in state: COMPLETED event:FINISHED
2020-03-26 19:10:49,373 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000008
2020-03-26 19:10:49,373 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000008 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:10:49,373 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000008, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000008 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000015 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000015
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000015 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000015, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:49,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:49,696 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:10:50,373 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000015 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:10:54,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0005
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000014 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000014 in state: COMPLETED event:FINISHED
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000014
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000014 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000014, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000014 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:10:59,507 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000016 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:10:59,508 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000016
2020-03-26 19:10:59,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000016 of capacity <memory:1024, vCores:1> on host dell:40919, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-26 19:10:59,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000016, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:10:59,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-26 19:10:59,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-26 19:10:59,712 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:11:00,511 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000016 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000015 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000015 in state: COMPLETED event:FINISHED
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000015
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000015 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000015, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000015 on node: host: dell:40919 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000012 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000012 in state: COMPLETED event:FINISHED
2020-03-26 19:11:12,467 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000012
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000012 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000012, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000012 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000017 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000017
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000017 of capacity <memory:1024, vCores:1> on host dell:40919, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000017, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-26 19:11:12,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:12,755 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:11:13,467 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000017 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000010 in state: COMPLETED event:FINISHED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000010
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000010 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000010, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000010 on node: host: dell:40919 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000011 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000011 in state: COMPLETED event:FINISHED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000011
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000011 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000011, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000011 on node: host: dell:40919 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000009 in state: COMPLETED event:FINISHED
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000009
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000009 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000009, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:11:13,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000009 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:11:13,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0005
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000018 Container Transitioned from NEW to ALLOCATED
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000018
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585219068220_0005_01_000018 of capacity <memory:1024, vCores:1> on host dell:40919, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585219068220_0005_000001 container=Container: [ContainerId: container_1585219068220_0005_01_000018, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-26 19:11:16,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:16,763 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-26 19:11:17,472 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000018 Container Transitioned from ACQUIRED to RUNNING
2020-03-26 19:11:17,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585219068220_0005
2020-03-26 19:11:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000016 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000016 in state: COMPLETED event:FINISHED
2020-03-26 19:11:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000016
2020-03-26 19:11:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000016 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-26 19:11:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-26 19:11:25,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000016, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-26 19:11:25,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000016 on node: host: dell:40919 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000018 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000018 in state: COMPLETED event:FINISHED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000018
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000018 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000018, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000018 on node: host: dell:40919 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000017 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000017 in state: COMPLETED event:FINISHED
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000017
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000017 of capacity <memory:1024, vCores:1> on host dell:40919, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-26 19:11:25,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-26 19:11:25,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000017, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:25,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-26 19:11:25,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000017 on node: host: dell:40919 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-26 19:11:25,302 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585219068220_0005_000001 with final state: FINISHING, and exit status: -1000
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from RUNNING to FINAL_SAVING
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585219068220_0005 with final state: FINISHING
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585219068220_0005
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from FINAL_SAVING to FINISHING
2020-03-26 19:11:25,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-26 19:11:26,305 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585219068220_0005 unregistered successfully. 
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585219068220_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585219068220_0005_000001
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585219068220_0005_000001
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585219068220_0005_01_000001 in state: COMPLETED event:FINISHED
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585219068220_0005_000001 State change from FINISHING to FINISHED
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585219068220_0005	CONTAINERID=container_1585219068220_0005_01_000001
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585219068220_0005_01_000001 of capacity <memory:2048, vCores:1> on host dell:40919, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585219068220_0005 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585219068220_0005
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585219068220_0005_01_000001, NodeId: dell:40919, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:40919 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585219068220_0005_000001 released container container_1585219068220_0005_01_000001 on node: host: dell:40919 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585219068220_0005,name=job2,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585219068220_0005/,appMasterHost=dell,startTime=1585220986698,finishTime=1585221085303,finalStatus=SUCCEEDED,memorySeconds=661559,vcoreSeconds=535,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-26 19:11:35,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585219068220_0005_000001 is done. finalState=FINISHED
2020-03-26 19:11:35,018 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585219068220_0005_000001
2020-03-26 19:11:35,018 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585219068220_0005 requests cleared
2020-03-26 19:11:35,018 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585219068220_0005 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-26 19:11:35,018 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585219068220_0005 user: xidian leaf-queue of parent: root #applications: 0
2020-03-26 19:11:37,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:11:37,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 19:11:37,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-26 21:49:53,615 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-26 21:49:53,620 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 21:49:53,622 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-26 21:49:53,723 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-26 21:49:53,726 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-26 21:49:53,729 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-26 21:49:53,730 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 21:49:53,732 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-26 21:49:53,733 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 21:49:53,734 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-26 21:49:53,735 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-26 21:49:53,735 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-26 21:49:53,737 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-26 21:49:53,737 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-26 21:49:53,737 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 21:49:53,743 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-26 21:49:53,743 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-26 21:49:53,743 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-26 21:49:53,744 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 21:49:53,744 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-26 21:49:53,745 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 21:49:53,745 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-26 21:49:53,745 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-26 21:49:53,746 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-26 21:49:53,746 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-26 21:49:53,747 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-26 21:49:53,747 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-26 21:49:53,747 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-26 21:49:53,747 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-26 21:49:53,747 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
2020-03-28 08:57:38,858 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = dell/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/etc/hadoop:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/usr/local/java/jdk1.8.0_131/lib/tools.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/xidian/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2020-03-28 08:57:38,918 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-28 08:57:39,092 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-03-28 08:57:39,159 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-03-28 08:57:39,454 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-03-28 08:57:39,577 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-03-28 08:57:39,702 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-03-28 08:57:39,706 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-03-28 08:57:39,710 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-03-28 08:57:39,738 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-03-28 08:57:39,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-03-28 08:57:39,750 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-03-28 08:57:39,766 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-03-28 08:57:39,766 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-03-28 08:57:39,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-03-28 08:57:39,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-03-28 08:57:39,804 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-28 08:57:39,850 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-28 08:57:39,850 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-03-28 08:57:39,861 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-03-28 08:57:39,868 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-03-28 08:57:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-03-28 08:57:39,873 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-03-28 08:57:39,874 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-03-28 08:57:39,883 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/xidian/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-03-28 08:57:39,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-03-28 08:57:39,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-03-28 08:57:39,927 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-03-28 08:57:39,927 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-03-28 08:57:39,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-03-28 08:57:39,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-03-28 08:57:39,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-03-28 08:57:39,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-03-28 08:57:39,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-28 08:57:39,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-03-28 08:57:39,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-03-28 08:57:39,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-03-28 08:57:39,953 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-03-28 08:57:39,953 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-03-28 08:57:39,979 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-03-28 08:57:39,979 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-03-28 08:57:39,979 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-03-28 08:57:39,979 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-28 08:57:39,980 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-03-28 08:57:39,980 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-28 08:57:39,980 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-28 08:57:39,980 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-28 08:57:39,980 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-03-28 08:57:39,980 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-03-28 08:57:39,981 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-03-28 08:57:40,063 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-28 08:57:40,070 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-03-28 08:57:40,175 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-03-28 08:57:40,175 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 08:57:40,175 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-03-28 08:57:40,255 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-28 08:57:40,258 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-03-28 08:57:40,267 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-03-28 08:57:40,267 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 08:57:40,267 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-03-28 08:57:40,404 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-03-28 08:57:40,405 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-03-28 08:57:40,409 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-03-28 08:57:40,412 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 08:57:40,413 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-03-28 08:57:40,473 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-03-28 08:57:40,565 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-28 08:57:40,574 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-28 08:57:40,579 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-03-28 08:57:40,584 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-28 08:57:40,586 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-03-28 08:57:40,587 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-03-28 08:57:40,587 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-03-28 08:57:40,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-03-28 08:57:40,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-28 08:57:40,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-28 08:57:40,590 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-03-28 08:57:40,590 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-03-28 08:57:41,260 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-03-28 08:57:41,261 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-03-28 08:57:41,261 INFO org.mortbay.log: jetty-6.1.26
2020-03-28 08:57:41,276 INFO org.mortbay.log: Extract jar:file:/home/xidian/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-03-28 08:57:41,388 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-28 08:57:41,388 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-03-28 08:57:41,388 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-03-28 08:57:42,543 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-28 08:57:42,543 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-03-28 08:57:42,676 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-03-28 08:57:42,684 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-03-28 08:57:42,714 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-03-28 08:57:42,732 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-28 08:57:42,733 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-03-28 08:57:42,850 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved dell to /default-rack
2020-03-28 08:57:42,852 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node dell(cmPort: 33751 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId dell:33751
2020-03-28 08:57:42,854 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: dell:33751 Node Transitioned from NEW to RUNNING
2020-03-28 08:57:42,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node dell:33751 clusterResource: <memory:8192, vCores:8>
2020-03-28 09:07:39,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-03-28 09:37:02,797 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-03-28 09:37:05,101 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user xidian
2020-03-28 09:37:05,101 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585357059953_0001
2020-03-28 09:37:05,102 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585357059953_0001
2020-03-28 09:37:05,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from NEW to NEW_SAVING on event=START
2020-03-28 09:37:05,153 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585357059953_0001
2020-03-28 09:37:05,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-28 09:37:05,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585357059953_0001 user: xidian leaf-queue of parent: root #applications: 1
2020-03-28 09:37:05,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585357059953_0001 from user: xidian, in queue: default
2020-03-28 09:37:05,188 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-28 09:37:05,201 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585357059953_0001_000001
2020-03-28 09:37:05,202 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from NEW to SUBMITTED
2020-03-28 09:37:05,214 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 09:37:05,214 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 09:37:05,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585357059953_0001 from user: xidian activated in queue: default
2020-03-28 09:37:05,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585357059953_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6f2ef396, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-28 09:37:05,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585357059953_0001_000001 to scheduler from user xidian in queue default
2020-03-28 09:37:05,216 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from SUBMITTED to SCHEDULED
2020-03-28 09:37:06,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:06,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000001
2020-03-28 09:37:06,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-28 09:37:06,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 09:37:06,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 09:37:06,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:06,128 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0001_01_000001
2020-03-28 09:37:06,181 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:06,181 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585357059953_0001_000001
2020-03-28 09:37:06,183 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585357059953_0001 AttemptId: appattempt_1585357059953_0001_000001 MasterContainer: Container: [ContainerId: container_1585357059953_0001_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ]
2020-03-28 09:37:06,190 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-28 09:37:06,191 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-28 09:37:06,196 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585357059953_0001_000001
2020-03-28 09:37:06,216 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585357059953_0001_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0001_000001
2020-03-28 09:37:06,216 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585357059953_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-28 09:37:06,219 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585357059953_0001_000001
2020-03-28 09:37:06,220 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585357059953_0001_000001
2020-03-28 09:37:06,702 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585357059953_0001_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0001_000001
2020-03-28 09:37:06,703 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from ALLOCATED to LAUNCHED
2020-03-28 09:37:07,071 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:25,707 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585357059953_0001_000001 (auth:SIMPLE)
2020-03-28 09:37:25,715 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585357059953_0001_000001
2020-03-28 09:37:25,715 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585357059953_0001	APPATTEMPTID=appattempt_1585357059953_0001_000001
2020-03-28 09:37:25,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from LAUNCHED to RUNNING
2020-03-28 09:37:25,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-28 09:37:27,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,106 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000002
2020-03-28 09:37:27,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-28 09:37:27,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,107 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 09:37:27,107 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,108 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000003
2020-03-28 09:37:27,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-28 09:37:27,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 09:37:27,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,109 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000004
2020-03-28 09:37:27,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 09:37:27,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 09:37:27,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,111 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000005
2020-03-28 09:37:27,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 09:37:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:37:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000006
2020-03-28 09:37:27,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:37:27,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:37:27,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,114 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:27,114 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000007
2020-03-28 09:37:27,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:37:27,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:27,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:37:27,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:27,994 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0001_01_000002
2020-03-28 09:37:27,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:28,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:28,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:28,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:28,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:28,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:29,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:29,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:29,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:54,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:37:54,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000007 in state: COMPLETED event:FINISHED
2020-03-28 09:37:54,493 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000007
2020-03-28 09:37:54,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:37:54,494 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:37:54,494 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,494 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,494 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:37:54,494 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000007 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:37:54,495 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:37:54,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000005 in state: COMPLETED event:FINISHED
2020-03-28 09:37:54,495 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000005
2020-03-28 09:37:54,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:37:54,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:37:54,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:37:54,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000005 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:37:54,496 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000008
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000009
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:37:54,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:37:54,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000004 in state: COMPLETED event:FINISHED
2020-03-28 09:37:54,813 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000004
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:37:54,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000004 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000010
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:37:54,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:37:55,248 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:55,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:55,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:37:55,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:55,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:37:55,818 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:01,746 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:01,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000003 in state: COMPLETED event:FINISHED
2020-03-28 09:38:01,746 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000003
2020-03-28 09:38:01,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:38:01,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000003 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000002 in state: COMPLETED event:FINISHED
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000002
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:38:01,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:38:01,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:01,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:01,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:38:01,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000002 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000011 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000011
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000011 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000011, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:02,344 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:02,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000006 in state: COMPLETED event:FINISHED
2020-03-28 09:38:02,344 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000006
2020-03-28 09:38:02,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:38:02,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:38:02,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:02,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:02,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:38:02,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000006 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:38:02,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000012 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:02,346 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000012
2020-03-28 09:38:02,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000012 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:38:02,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000012, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:02,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:02,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:02,348 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000013 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:02,348 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000013
2020-03-28 09:38:02,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000013 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:38:02,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000013, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:02,349 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:38:02,349 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:02,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:02,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:02,414 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:03,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000011 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:03,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000012 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:03,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000013 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:03,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0001
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000009 in state: COMPLETED event:FINISHED
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000009
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:22,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000009 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:38:22,981 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:22,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000010 in state: COMPLETED event:FINISHED
2020-03-28 09:38:22,981 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000010
2020-03-28 09:38:22,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:38:22,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:38:22,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:22,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:22,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:38:22,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000010 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000014 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000014
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000014 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000014, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000015 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000015
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000015 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000015, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:38:22,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:23,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:23,545 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:23,981 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000014 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:23,982 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000015 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:29,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000012 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:29,618 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000012 in state: COMPLETED event:FINISHED
2020-03-28 09:38:29,618 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000012
2020-03-28 09:38:29,618 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000012 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:38:29,618 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:38:29,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000012, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:29,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:29,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:29,619 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000012 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:38:29,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000016 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:29,620 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000016
2020-03-28 09:38:29,620 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000016 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:38:29,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000016, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:29,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:38:29,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:29,761 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:30,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000016 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:30,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:30,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000008 in state: COMPLETED event:FINISHED
2020-03-28 09:38:30,621 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000008
2020-03-28 09:38:30,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:38:30,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:38:30,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:30,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000008 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:38:30,623 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000013 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:30,623 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000013 in state: COMPLETED event:FINISHED
2020-03-28 09:38:30,623 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000013
2020-03-28 09:38:30,623 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000013 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:38:30,624 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:38:30,624 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000013, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:38:30,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000013 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:38:30,626 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000017 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:30,626 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000017
2020-03-28 09:38:30,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000017 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:38:30,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000017, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:30,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:30,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000018 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:30,627 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000018
2020-03-28 09:38:30,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000018 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:38:30,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000018, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:38:30,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:38:30,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:30,766 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:30,767 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:31,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000017 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:31,621 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000018 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:53,186 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000016 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:38:53,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000016 in state: COMPLETED event:FINISHED
2020-03-28 09:38:53,186 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000016
2020-03-28 09:38:53,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000016 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:38:53,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000016, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000016 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000019 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000019
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000019 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000019, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 09:38:53,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:38:53,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:38:53,908 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000019 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:38:54,187 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000019 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:38:54,910 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0001
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000017 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000017 in state: COMPLETED event:FINISHED
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000017
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000017 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:39:02,859 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000017, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000017 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000018 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000018 in state: COMPLETED event:FINISHED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000018
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000018 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000018, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000018 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000015 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000015 in state: COMPLETED event:FINISHED
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000015
2020-03-28 09:39:02,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000015 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000015, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000015 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000014 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000014 in state: COMPLETED event:FINISHED
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000014
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000014 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000014, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 09:39:02,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000014 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000020 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000020
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000020 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000020, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000021 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000021
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000021 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000021, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000022 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000022
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000022 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000022, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000023 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:02,863 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000023
2020-03-28 09:39:02,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000023 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:39:02,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000023, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:02,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:39:02,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:02,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000020 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:02,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000021 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:02,939 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000022 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:02,940 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000023 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:03,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000020 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:03,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000021 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:03,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000022 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:03,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000023 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:28,204 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000020 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:28,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000020 in state: COMPLETED event:FINISHED
2020-03-28 09:39:28,204 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000020
2020-03-28 09:39:28,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000020 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:39:28,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:39:28,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000020, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:28,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:28,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:28,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000020 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000024 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000024
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000024 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000024, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:39:28,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:28,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000024 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:29,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000024 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:29,602 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0001
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000023 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000023 in state: COMPLETED event:FINISHED
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000023
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000023 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000023, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:30,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000023 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000021 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000021 in state: COMPLETED event:FINISHED
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000021
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000021 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000021, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000021 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000022 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000022 in state: COMPLETED event:FINISHED
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000022
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000022 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000022, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000022 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000025 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000025
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000025 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 09:39:30,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000025, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000026 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000026
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000026 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000026, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000027 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000027
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000027 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000027, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:39:30,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:30,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000025 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:30,611 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000026 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:30,613 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000027 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:31,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000025 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:31,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000026 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:31,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000027 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:49,440 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000025 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:49,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000025 in state: COMPLETED event:FINISHED
2020-03-28 09:39:49,440 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000025
2020-03-28 09:39:49,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000025 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:39:49,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000025, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000025 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000028 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000028
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000028 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000028, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:39:49,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:49,898 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000028 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:50,443 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000028 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:53,754 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000027 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:53,754 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000027 in state: COMPLETED event:FINISHED
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000027
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000027 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000027, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:53,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000027 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000026 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000026 in state: COMPLETED event:FINISHED
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000026
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000026 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:39:53,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000026, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:39:53,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000026 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000029 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000029
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000029 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000029, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000030 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000030
2020-03-28 09:39:53,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000030 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:39:53,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000030, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:39:53,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:39:53,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:39:53,912 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000029 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:53,915 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000030 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:39:54,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000029 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:39:54,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000030 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000028 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000028 in state: COMPLETED event:FINISHED
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000028
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000028 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000028, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:09,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000028 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000031 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000031
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000031 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000031, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:09,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:10,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000031 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:10,638 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000031 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000029 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000029 in state: COMPLETED event:FINISHED
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000029
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000029 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000029, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000029 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000032 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000032
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000032 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000032, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:14,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:14,036 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000032 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:15,126 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000032 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000030 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000030 in state: COMPLETED event:FINISHED
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000030
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000030 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000030, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:16,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000030 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000033 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000033
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000033 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000033, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:16,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:17,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000033 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:17,669 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000033 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000032 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000032 in state: COMPLETED event:FINISHED
2020-03-28 09:40:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000032
2020-03-28 09:40:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000032 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:32,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000032, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:32,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:32,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:32,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000032 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000034 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000034
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000034 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000034, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:32,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:33,382 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000034 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:33,572 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000034 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:36,919 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000033 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000033 in state: COMPLETED event:FINISHED
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000033
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000033 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000033, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:36,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000033 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:36,921 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000035 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:36,921 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000035
2020-03-28 09:40:36,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000035 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:36,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000035, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:36,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:36,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000031 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000031 in state: COMPLETED event:FINISHED
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000031
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000031 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000031, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000031 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000036 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000036
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000036 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:37,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000036, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:37,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:37,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:37,523 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000035 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:37,525 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000036 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:38,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000035 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:38,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000036 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:40:58,929 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000036 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:58,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000036 in state: COMPLETED event:FINISHED
2020-03-28 09:40:58,929 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000036
2020-03-28 09:40:58,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000036 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:58,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000036, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000036 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000034 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000034 in state: COMPLETED event:FINISHED
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000034
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000034 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000034, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:40:58,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000034 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000037 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000037
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000037 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000037, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000038 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000038
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000038 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000038, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:58,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:59,574 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000037 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:59,577 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000038 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:40:59,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000035 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:40:59,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000035 in state: COMPLETED event:FINISHED
2020-03-28 09:40:59,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000035
2020-03-28 09:40:59,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000035 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:40:59,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:40:59,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000035, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:40:59,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:40:59,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:40:59,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000035 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000039 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000039
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000039 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000039, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 09:40:59,933 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:00,602 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000039 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:41:00,933 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000037 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:41:00,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000038 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:41:00,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000039 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000039 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000039 in state: COMPLETED event:FINISHED
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000039
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000039 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000039, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:41:22,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000039 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000038 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000038 in state: COMPLETED event:FINISHED
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000038
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000038 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000038, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000038 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000040 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000040
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000040 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000040, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:41:22,640 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:23,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000040 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:41:23,641 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000040 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:41:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000037 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000037 in state: COMPLETED event:FINISHED
2020-03-28 09:41:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000037
2020-03-28 09:41:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000037 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:41:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:41:23,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000037, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:23,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:23,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:41:23,643 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000037 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:41:24,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0001
2020-03-28 09:41:25,644 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000041 Container Transitioned from NEW to ALLOCATED
2020-03-28 09:41:25,644 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000041
2020-03-28 09:41:25,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0001_01_000041 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 09:41:25,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0001_000001 container=Container: [ContainerId: container_1585357059953_0001_01_000041, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 09:41:25,645 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 09:41:25,645 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:25,752 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000041 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 09:41:26,645 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000041 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 09:41:26,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0001
2020-03-28 09:41:36,431 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000040 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:36,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000040 in state: COMPLETED event:FINISHED
2020-03-28 09:41:36,431 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000040
2020-03-28 09:41:36,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000040 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 09:41:36,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 09:41:36,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000040, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:36,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:36,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 09:41:36,432 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000040 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 09:41:41,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585357059953_0001_000001 with final state: FINISHING, and exit status: -1000
2020-03-28 09:41:41,414 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from RUNNING to FINAL_SAVING
2020-03-28 09:41:41,414 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585357059953_0001 with final state: FINISHING
2020-03-28 09:41:41,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-28 09:41:41,416 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585357059953_0001
2020-03-28 09:41:41,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from FINAL_SAVING to FINISHING
2020-03-28 09:41:41,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-28 09:41:42,810 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585357059953_0001 unregistered successfully. 
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000011 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000011 in state: COMPLETED event:FINISHED
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000011
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000011 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000011, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000011 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000041 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000041 in state: COMPLETED event:FINISHED
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000041
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000041 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000041, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 09:41:44,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000041 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000024 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000024 in state: COMPLETED event:FINISHED
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000024
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000024 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000024, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 09:41:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000024 on node: host: dell:33751 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-28 09:41:45,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000019 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:45,973 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000019 in state: COMPLETED event:FINISHED
2020-03-28 09:41:45,973 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000019
2020-03-28 09:41:45,973 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000019 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-28 09:41:45,973 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-28 09:41:45,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000019, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:45,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:45,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 09:41:45,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000019 on node: host: dell:33751 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585357059953_0001_000001
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0001_01_000001 in state: COMPLETED event:FINISHED
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0001	CONTAINERID=container_1585357059953_0001_01_000001
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0001_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0001_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0001_000001 released container container_1585357059953_0001_01_000001 on node: host: dell:33751 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-28 09:41:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585357059953_0001_000001
2020-03-28 09:41:51,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0001_000001 State change from FINISHING to FINISHED
2020-03-28 09:41:51,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-28 09:41:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585357059953_0001_000001 is done. finalState=FINISHED
2020-03-28 09:41:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585357059953_0001 requests cleared
2020-03-28 09:41:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585357059953_0001 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-28 09:41:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585357059953_0001_000001
2020-03-28 09:41:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585357059953_0001 user: xidian leaf-queue of parent: root #applications: 0
2020-03-28 09:41:51,774 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585357059953_0001
2020-03-28 09:41:51,783 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585357059953_0001,name=fullshuffle,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585357059953_0001/,appMasterHost=dell,startTime=1585359425100,finishTime=1585359701414,finalStatus=SUCCEEDED,memorySeconds=2135920,vcoreSeconds=1781,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-28 09:41:53,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 09:41:53,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 09:41:53,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 09:41:53,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 19:56:58,513 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-03-28 19:57:01,132 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user xidian
2020-03-28 19:57:01,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585357059953_0002
2020-03-28 19:57:01,132 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585357059953_0002
2020-03-28 19:57:01,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from NEW to NEW_SAVING on event=START
2020-03-28 19:57:01,133 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585357059953_0002
2020-03-28 19:57:01,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-28 19:57:01,133 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585357059953_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-28 19:57:01,133 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585357059953_0002 from user: xidian, in queue: default
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from NEW to SUBMITTED
2020-03-28 19:57:01,134 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 19:57:01,134 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585357059953_0002 from user: xidian activated in queue: default
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585357059953_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@d6ee1f6, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-28 19:57:01,134 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585357059953_0002_000001 to scheduler from user xidian in queue default
2020-03-28 19:57:01,135 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from SUBMITTED to SCHEDULED
2020-03-28 19:57:01,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:01,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000001
2020-03-28 19:57:01,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-28 19:57:01,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 19:57:01,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 19:57:01,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:01,847 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0002_01_000001
2020-03-28 19:57:01,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:01,848 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585357059953_0002 AttemptId: appattempt_1585357059953_0002_000001 MasterContainer: Container: [ContainerId: container_1585357059953_0002_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ]
2020-03-28 19:57:01,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-28 19:57:01,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-28 19:57:01,849 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585357059953_0002_000001
2020-03-28 19:57:01,852 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585357059953_0002_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,852 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585357059953_0002_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-28 19:57:01,852 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,852 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,870 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585357059953_0002_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0002_000001
2020-03-28 19:57:01,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from ALLOCATED to LAUNCHED
2020-03-28 19:57:02,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:07,887 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585357059953_0002_000001 (auth:SIMPLE)
2020-03-28 19:57:07,890 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585357059953_0002_000001
2020-03-28 19:57:07,890 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585357059953_0002	APPATTEMPTID=appattempt_1585357059953_0002_000001
2020-03-28 19:57:07,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from LAUNCHED to RUNNING
2020-03-28 19:57:07,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000002
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000003
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000004
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 19:57:09,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000005
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000006
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000007
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:57:09,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:10,010 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0002_01_000002
2020-03-28 19:57:10,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:10,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:10,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:10,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:10,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:10,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:10,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000007 in state: COMPLETED event:FINISHED
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000007
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:57:36,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000007 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000008
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:57:36,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:36,145 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:37,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:46,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:46,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000003 in state: COMPLETED event:FINISHED
2020-03-28 19:57:46,808 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000003
2020-03-28 19:57:46,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:57:46,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000003 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000004 in state: COMPLETED event:FINISHED
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000004
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 19:57:46,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 19:57:46,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:57:46,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000004 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000006 in state: COMPLETED event:FINISHED
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000006
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 19:57:46,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000006 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000009
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:57:46,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,261 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:47,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:47,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:47,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000002 in state: COMPLETED event:FINISHED
2020-03-28 19:57:47,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000002
2020-03-28 19:57:47,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 19:57:47,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000002 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000005 in state: COMPLETED event:FINISHED
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000005
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 19:57:47,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000005 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000010
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000011 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000011
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000011 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000011, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000012 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000012
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000012 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000012, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000013 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000013
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000013 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000013, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:57:47,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:48,266 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0002
2020-03-28 19:57:48,268 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:48,268 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:48,269 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:48,269 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:48,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:48,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000011 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:48,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000012 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:48,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000013 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000008 in state: COMPLETED event:FINISHED
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000008
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:57:58,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000008 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000014 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000014
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000014 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000014, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:57:58,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:57:59,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:57:59,800 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000014 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000011 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000011 in state: COMPLETED event:FINISHED
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000011
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000011 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000011, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:08,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000011 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000015 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000015
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000015 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000015, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:08,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:08,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:09,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000015 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:16,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000013 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:16,515 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000013 in state: COMPLETED event:FINISHED
2020-03-28 19:58:16,515 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000013
2020-03-28 19:58:16,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000013 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:16,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000013, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000013 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000010 in state: COMPLETED event:FINISHED
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000010
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 19:58:16,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 19:58:16,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:16,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:16,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:58:16,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000010 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000016 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000016
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000016 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000016, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000017 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000017
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000017 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000017, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:16,522 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:17,371 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:17,373 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:17,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000016 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:17,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000017 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:18,632 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000012 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:18,632 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000012 in state: COMPLETED event:FINISHED
2020-03-28 19:58:18,632 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000012
2020-03-28 19:58:18,632 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000012 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:18,632 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000012, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000012 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000018 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000018
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000018 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:18,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000018, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000014 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000014 in state: COMPLETED event:FINISHED
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000014
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000014 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:18,637 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000014, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000014 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000019 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000019
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000019 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000019, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:18,638 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:19,457 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:19,458 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000019 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:19,636 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000018 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:19,636 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000019 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000015 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000015 in state: COMPLETED event:FINISHED
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000015
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000015 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000015, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:20,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000015 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000020 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000020
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000020 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000020, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:20,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:21,464 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000020 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:21,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000020 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000017 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000017 in state: COMPLETED event:FINISHED
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000017
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000017 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000017, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:35,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000017 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000021 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000021
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000021 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000021, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:35,766 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000021 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:36,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000021 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:36,533 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000016 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:36,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000016 in state: COMPLETED event:FINISHED
2020-03-28 19:58:36,533 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000016
2020-03-28 19:58:36,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000016 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:36,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000016, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000016 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000022 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000022
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000022 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000022, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:36,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:36,794 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000022 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:37,535 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000022 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:56,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000019 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:56,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000019 in state: COMPLETED event:FINISHED
2020-03-28 19:58:56,326 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000019
2020-03-28 19:58:56,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000019 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:58:56,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000019, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000019 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000018 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000018 in state: COMPLETED event:FINISHED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000018
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000018 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000018, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000018 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000020 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000020 in state: COMPLETED event:FINISHED
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000020
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000020 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000020, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 19:58:56,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000020 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000023 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000023
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000023 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000023, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000024 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000024
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000024 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000024, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000025 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000025
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000025 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000025, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:58:56,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:58:56,823 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000023 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:56,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000024 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:56,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000025 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:58:57,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000023 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:57,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000024 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:58:57,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000025 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000021 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000021 in state: COMPLETED event:FINISHED
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000021
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000021 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000021, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:11,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:11,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:11,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000021 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000026 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000026
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000026 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000026, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:11,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:12,851 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000026 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:12,904 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000026 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000022 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000022 in state: COMPLETED event:FINISHED
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000022
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000022 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000022, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000022 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000027 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000027
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000027 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000027, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:13,424 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:13,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:13,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000027 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:14,428 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000027 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:37,767 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000026 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:37,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000026 in state: COMPLETED event:FINISHED
2020-03-28 19:59:37,767 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000026
2020-03-28 19:59:37,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000026 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:37,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000026, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000026 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000028 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000028
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000028 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000028, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:37,768 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:37,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000028 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:38,768 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000028 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000023 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000023 in state: COMPLETED event:FINISHED
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000023
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000023 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000023, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000023 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000027 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000027 in state: COMPLETED event:FINISHED
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000027
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000027 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 19:59:50,963 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000027, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000027 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000029 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000029
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000029 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000029, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000030 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000030
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000030 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000030, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:50,964 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:51,185 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000029 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:51,186 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000030 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:51,963 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000029 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:51,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000030 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:52,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000024 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000024 in state: COMPLETED event:FINISHED
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000024
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000024 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000024, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:52,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000024 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000031 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000031
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000031 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000031, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:52,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:52,193 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000031 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:53,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000031 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 19:59:54,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000025 Container Transitioned from RUNNING to COMPLETED
2020-03-28 19:59:54,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000025 in state: COMPLETED event:FINISHED
2020-03-28 19:59:54,195 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000025
2020-03-28 19:59:54,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000025 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 19:59:54,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 19:59:54,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000025, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 19:59:54,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:54,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 19:59:54,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000025 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000032 Container Transitioned from NEW to ALLOCATED
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000032
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000032 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000032, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 19:59:54,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 19:59:54,199 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000032 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 19:59:55,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000032 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:00:19,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000028 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:00:19,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000028 in state: COMPLETED event:FINISHED
2020-03-28 20:00:19,257 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000028
2020-03-28 20:00:19,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000028 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000028, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000028 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000033 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000033
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000033 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000033, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:00:19,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:19,297 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000033 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:00:19,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000033 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:00:19,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000029 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:00:19,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000029 in state: COMPLETED event:FINISHED
2020-03-28 20:00:19,337 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000029
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000029 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000029, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000029 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000034 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000034
2020-03-28 20:00:19,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000034 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:00:19,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000034, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:00:19,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:00:19,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:20,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000034 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:00:20,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000034 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:00:26,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000031 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:00:26,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000031 in state: COMPLETED event:FINISHED
2020-03-28 20:00:26,528 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000031
2020-03-28 20:00:26,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000031 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:00:26,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000031, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000031 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000035 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000035
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000035 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000035, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:00:26,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000030 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000030 in state: COMPLETED event:FINISHED
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000030
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000030 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000030, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000030 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000036 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000036
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000036 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000036, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:00:26,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:27,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000035 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:00:27,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000036 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:00:27,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000035 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:00:27,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000036 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000032 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000032 in state: COMPLETED event:FINISHED
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000032
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000032 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:00:28,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000032, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000032 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000037 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000037
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000037 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000037, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:00:28,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:00:29,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000037 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:00:29,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000037 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000033 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000033 in state: COMPLETED event:FINISHED
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000033
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000033 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000033, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:01:06,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000033 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000035 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000035 in state: COMPLETED event:FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000035
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000035 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000035, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000035 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000037 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000037 in state: COMPLETED event:FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000037
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000037 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000037, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000037 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000036 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000036 in state: COMPLETED event:FINISHED
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000036
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000036 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 20:01:06,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000036, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000036 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000038 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000038
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0002_01_000038 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0002_000001 container=Container: [ContainerId: container_1585357059953_0002_01_000038, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=NODE_LOCAL requestedPartition=
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 20:01:06,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:06,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000038 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000038 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000034 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000034 in state: COMPLETED event:FINISHED
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000034
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000034 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 20:01:07,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000034, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:07,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:07,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:01:07,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000034 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 20:01:07,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0002
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585357059953_0002_000001 with final state: FINISHING, and exit status: -1000
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from RUNNING to FINAL_SAVING
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585357059953_0002 with final state: FINISHING
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585357059953_0002
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from FINAL_SAVING to FINISHING
2020-03-28 20:01:19,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000038 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000038 in state: COMPLETED event:FINISHED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000038
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000038 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000038, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000038 on node: host: dell:33751 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000009 in state: COMPLETED event:FINISHED
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000009
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 20:01:20,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000009 on node: host: dell:33751 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-28 20:01:20,631 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585357059953_0002 unregistered successfully. 
2020-03-28 20:01:21,187 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user xidian
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1585357059953_0003
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1585357059953_0003
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from NEW to NEW_SAVING on event=START
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1585357059953_0003
2020-03-28 20:01:21,667 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1585357059953_0003 user: xidian leaf-queue of parent: root #applications: 2
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1585357059953_0003 from user: xidian, in queue: default
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1585357059953_0003_000001
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from NEW to SUBMITTED
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: not starting application as amIfStarted exceeds amLimit
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1585357059953_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@d6ee1f6, leaf-queue: default #user-pending-applications: 1 #user-active-applications: 1 #queue-pending-applications: 1 #queue-active-applications: 1
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1585357059953_0003_000001 to scheduler from user xidian in queue default
2020-03-28 20:01:21,668 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from SUBMITTED to SCHEDULED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585357059953_0002_000001
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0002_01_000001 in state: COMPLETED event:FINISHED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585357059953_0002_000001
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0002	CONTAINERID=container_1585357059953_0002_01_000001
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0002_000001 State change from FINISHING to FINISHED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0002_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0002_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=2, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585357059953_0002
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=2, numContainers=0
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0002_000001 released container container_1585357059953_0002_01_000001 on node: host: dell:33751 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585357059953_0002_000001 is done. finalState=FINISHED
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585357059953_0002,name=job1,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585357059953_0002/,appMasterHost=dell,startTime=1585396621132,finishTime=1585396879622,finalStatus=SUCCEEDED,memorySeconds=2031645,vcoreSeconds=1690,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-28 20:01:31,001 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585357059953_0002_000001
2020-03-28 20:01:31,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585357059953_0002 requests cleared
2020-03-28 20:01:31,002 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 20:01:31,002 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2020-03-28 20:01:31,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1585357059953_0003 from user: xidian activated in queue: default
2020-03-28 20:01:31,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585357059953_0002 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-03-28 20:01:31,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585357059953_0002 user: xidian leaf-queue of parent: root #applications: 1
2020-03-28 20:01:32,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:32,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000001
2020-03-28 20:01:32,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2020-03-28 20:01:32,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:32,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 20:01:32,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:32,002 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0003_01_000001
2020-03-28 20:01:32,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:32,004 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1585357059953_0003_000001
2020-03-28 20:01:32,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1585357059953_0003 AttemptId: appattempt_1585357059953_0003_000001 MasterContainer: Container: [ContainerId: container_1585357059953_0003_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ]
2020-03-28 20:01:32,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-03-28 20:01:32,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-03-28 20:01:32,004 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1585357059953_0003_000001
2020-03-28 20:01:32,005 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1585357059953_0003_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0003_000001
2020-03-28 20:01:32,005 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1585357059953_0003_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2020-03-28 20:01:32,005 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1585357059953_0003_000001
2020-03-28 20:01:32,005 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1585357059953_0003_000001
2020-03-28 20:01:32,011 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1585357059953_0003_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] for AM appattempt_1585357059953_0003_000001
2020-03-28 20:01:32,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from ALLOCATED to LAUNCHED
2020-03-28 20:01:33,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:33,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 20:01:33,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 20:01:38,770 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1585357059953_0003_000001 (auth:SIMPLE)
2020-03-28 20:01:38,775 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1585357059953_0003_000001
2020-03-28 20:01:38,775 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1585357059953_0003	APPATTEMPTID=appattempt_1585357059953_0003_000001
2020-03-28 20:01:38,779 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from LAUNCHED to RUNNING
2020-03-28 20:01:38,779 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000002
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 20:01:40,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:40,890 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : dell:33751 for container : container_1585357059953_0003_01_000002
2020-03-28 20:01:40,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:41,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0003
2020-03-28 20:01:42,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000003
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:01:47,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000002 in state: COMPLETED event:FINISHED
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000002
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000002 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000002, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000002 on node: host: dell:33751 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000004 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000004
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:47,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:01:47,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:47,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:47,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:48,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000004 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000005 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000005
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available after allocation
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 20:01:48,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:48,923 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:49,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000005 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000006 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000006
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 20:01:49,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:49,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:50,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000006 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000007 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000007
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available after allocation
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:01:50,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:50,939 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:51,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000007 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000008 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000008
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which has 7 containers, <memory:8192, vCores:7> used and <memory:0, vCores:1> available after allocation
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:8192, vCores:7>, usedCapacity=1.0, absoluteUsedCapacity=1.0, numApps=1, numContainers=7
2020-03-28 20:01:51,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0 absoluteUsedCapacity=1.0 used=<memory:8192, vCores:7> cluster=<memory:8192, vCores:8>
2020-03-28 20:01:51,967 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:01:52,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000008 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:02:05,886 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000003 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,886 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000003
2020-03-28 20:02:05,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000003 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 6 containers, <memory:7168, vCores:6> used and <memory:1024, vCores:2> available, release resources=true
2020-03-28 20:02:05,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:7168, vCores:6> numContainers=6 user=xidian user-resources=<memory:7168, vCores:6>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000003, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.875 absoluteUsedCapacity=0.875 used=<memory:7168, vCores:6> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:6>, usedCapacity=0.875, absoluteUsedCapacity=0.875, numApps=1, numContainers=6
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000003 on node: host: dell:33751 #containers=6 available=<memory:1024, vCores:2> used=<memory:7168, vCores:6> with event: FINISHED
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000004 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000004 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000004
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000004 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available, release resources=true
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:6144, vCores:5> numContainers=5 user=xidian user-resources=<memory:6144, vCores:5>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000004, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 20:02:05,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000004 on node: host: dell:33751 #containers=5 available=<memory:2048, vCores:3> used=<memory:6144, vCores:5> with event: FINISHED
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000005 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000005 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000005
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000005 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000005, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000005 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000009 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000009
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which has 5 containers, <memory:6144, vCores:5> used and <memory:2048, vCores:3> available after allocation
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:5>, usedCapacity=0.75, absoluteUsedCapacity=0.75, numApps=1, numContainers=5
2020-03-28 20:02:05,888 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.75 absoluteUsedCapacity=0.75 used=<memory:6144, vCores:5> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000007 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000007 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000007
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000007 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 4 containers, <memory:5120, vCores:4> used and <memory:3072, vCores:4> available, release resources=true
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:5120, vCores:4> numContainers=4 user=xidian user-resources=<memory:5120, vCores:4>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000007, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.625 absoluteUsedCapacity=0.625 used=<memory:5120, vCores:4> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:4>, usedCapacity=0.625, absoluteUsedCapacity=0.625, numApps=1, numContainers=4
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000007 on node: host: dell:33751 #containers=4 available=<memory:3072, vCores:4> used=<memory:5120, vCores:4> with event: FINISHED
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000008 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000008 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000008
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000008 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available, release resources=true
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=xidian user-resources=<memory:4096, vCores:3>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000008, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000008 on node: host: dell:33751 #containers=3 available=<memory:4096, vCores:5> used=<memory:4096, vCores:3> with event: FINISHED
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000006 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000006 in state: COMPLETED event:FINISHED
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000006
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000006 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000006, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 20:02:05,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000006 on node: host: dell:33751 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-28 20:02:06,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:02:06,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000009 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:02:07,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0003
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000010 Container Transitioned from NEW to ALLOCATED
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000010
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1585357059953_0003_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1585357059953_0003_000001 container=Container: [ContainerId: container_1585357059953_0003_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.5, absoluteUsedCapacity=0.5, numApps=1, numContainers=3
2020-03-28 20:02:11,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5 absoluteUsedCapacity=0.5 used=<memory:4096, vCores:3> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:12,430 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2020-03-28 20:02:12,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000010 Container Transitioned from ACQUIRED to RUNNING
2020-03-28 20:02:13,433 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1585357059953_0003
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000009 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000009 in state: COMPLETED event:FINISHED
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000009
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000009 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=xidian user-resources=<memory:3072, vCores:2>
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000009, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2020-03-28 20:02:14,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000009 on node: host: dell:33751 #containers=2 available=<memory:5120, vCores:6> used=<memory:3072, vCores:2> with event: FINISHED
2020-03-28 20:02:18,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1585357059953_0003_000001 with final state: FINISHING, and exit status: -1000
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from RUNNING to FINAL_SAVING
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1585357059953_0003 with final state: FINISHING
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1585357059953_0003
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from FINAL_SAVING to FINISHING
2020-03-28 20:02:18,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-03-28 20:02:19,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000010 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:19,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000010 in state: COMPLETED event:FINISHED
2020-03-28 20:02:19,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000010
2020-03-28 20:02:19,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000010 of capacity <memory:1024, vCores:1> on host dell:33751, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2020-03-28 20:02:19,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=xidian user-resources=<memory:2048, vCores:1>
2020-03-28 20:02:19,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000010, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:19,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:19,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2020-03-28 20:02:19,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000010 on node: host: dell:33751 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2020-03-28 20:02:19,199 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1585357059953_0003 unregistered successfully. 
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1585357059953_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1585357059953_0003_000001
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1585357059953_0003_01_000001 in state: COMPLETED event:FINISHED
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1585357059953_0003_000001
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1585357059953_0003	CONTAINERID=container_1585357059953_0003_01_000001
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1585357059953_0003_000001 State change from FINISHING to FINISHED
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1585357059953_0003_01_000001 of capacity <memory:2048, vCores:1> on host dell:33751, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1585357059953_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=xidian user-resources=<memory:0, vCores:0>
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1585357059953_0003_01_000001, NodeId: dell:33751, NodeHttpAddress: dell:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:33751 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=xidian	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1585357059953_0003
2020-03-28 20:02:28,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1585357059953_0003_000001 released container container_1585357059953_0003_01_000001 on node: host: dell:33751 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1585357059953_0003_000001 is done. finalState=FINISHED
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1585357059953_0003,name=job2,user=xidian,queue=default,state=FINISHED,trackingUrl=http://dell:8088/proxy/application_1585357059953_0003/,appMasterHost=dell,startTime=1585396881667,finishTime=1585396938197,finalStatus=SUCCEEDED,memorySeconds=241349,vcoreSeconds=171,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1585357059953_0003 requests cleared
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1585357059953_0003_000001
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1585357059953_0003 user: xidian queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-03-28 20:02:28,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1585357059953_0003 user: xidian leaf-queue of parent: root #applications: 0
2020-03-28 20:02:30,470 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-03-28 22:23:21,821 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-03-28 22:23:21,827 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-28 22:23:21,839 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-03-28 22:23:21,939 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-03-28 22:23:21,943 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-03-28 22:23:21,945 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-03-28 22:23:21,945 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-28 22:23:21,949 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-03-28 22:23:21,950 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-28 22:23:21,951 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-03-28 22:23:21,952 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-03-28 22:23:21,953 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-03-28 22:23:21,957 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-03-28 22:23:21,958 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-28 22:23:21,958 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-03-28 22:23:21,960 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-03-28 22:23:21,960 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-03-28 22:23:21,961 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-03-28 22:23:21,961 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-03-28 22:23:21,961 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-28 22:23:21,961 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-28 22:23:21,962 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-03-28 22:23:21,961 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-03-28 22:23:21,970 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-03-28 22:23:21,971 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-03-28 22:23:21,975 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-03-28 22:23:21,975 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-03-28 22:23:21,975 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-03-28 22:23:21,976 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-03-28 22:23:21,976 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at dell/127.0.1.1
************************************************************/
